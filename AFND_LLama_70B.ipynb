{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3s7uxte9qcKu"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HkZUqFMtqcKw"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "40mAGPxdqcK1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.2.11-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.31-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langchain-core<0.3.0,>=0.2.23 (from langchain)\n",
      "  Downloading langchain_core-0.2.24-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.93-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.3)\n",
      "Collecting pydantic<3,>=1 (from langchain)\n",
      "  Downloading pydantic-2.8.2-py3-none-any.whl.metadata (125 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain)\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.23->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging<25,>=23.2 (from langchain-core<0.3.0,>=0.2.23->langchain)\n",
      "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.20.1 (from pydantic<3,>=1->langchain)\n",
      "  Downloading pydantic_core-2.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.23->langchain) (2.1)\n",
      "Downloading langchain-0.2.11-py3-none-any.whl (990 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.3/990.3 kB\u001b[0m \u001b[31m21.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m68.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading langchain_core-0.2.24-py3-none-any.whl (377 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.3/377.3 kB\u001b[0m \u001b[31m113.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
      "Downloading langsmith-0.1.93-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.8/139.8 kB\u001b[0m \u001b[31m65.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.8.2-py3-none-any.whl (423 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.9/423.9 kB\u001b[0m \u001b[31m117.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m159.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading SQLAlchemy-2.0.31-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m170.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m91.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (616 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m616.0/616.0 kB\u001b[0m \u001b[31m133.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m61.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m67.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m26.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.6/301.6 kB\u001b[0m \u001b[31m102.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tenacity, pydantic-core, packaging, orjson, multidict, jsonpatch, greenlet, frozenlist, async-timeout, annotated-types, yarl, SQLAlchemy, pydantic, aiosignal, langsmith, aiohttp, langchain-core, langchain-text-splitters, langchain\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.1\n",
      "    Uninstalling packaging-23.1:\n",
      "      Successfully uninstalled packaging-23.1\n",
      "  Attempting uninstall: jsonpatch\n",
      "    Found existing installation: jsonpatch 1.32\n",
      "    Uninstalling jsonpatch-1.32:\n",
      "      Successfully uninstalled jsonpatch-1.32\n",
      "Successfully installed SQLAlchemy-2.0.31 aiohttp-3.9.5 aiosignal-1.3.1 annotated-types-0.7.0 async-timeout-4.0.3 frozenlist-1.4.1 greenlet-3.0.3 jsonpatch-1.33 langchain-0.2.11 langchain-core-0.2.24 langchain-text-splitters-0.2.2 langsmith-0.1.93 multidict-6.0.5 orjson-3.10.6 packaging-24.1 pydantic-2.8.2 pydantic-core-2.20.1 tenacity-8.5.0 yarl-1.9.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting langchain_community\n",
      "  Downloading langchain_community-0.2.10-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (3.9.5)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.9 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.2.11)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.23 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.2.24)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.1.93)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (1.26.3)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (8.5.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.21.3-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from langchain<0.3.0,>=0.2.9->langchain_community) (0.2.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain<0.3.0,>=0.2.9->langchain_community) (2.8.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain_community) (24.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2024.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.9.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.23->langchain_community) (2.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.9->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.9->langchain_community) (2.20.1)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading langchain_community-0.2.10-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m24.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain_community\n",
      "Successfully installed dataclasses-json-0.6.7 langchain_community-0.2.10 marshmallow-3.21.3 mypy-extensions-1.0.0 typing-inspect-0.9.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: langchain in /opt/conda/lib/python3.10/site-packages (0.2.11)\n",
      "Requirement already satisfied: langchain_community in /opt/conda/lib/python3.10/site-packages (0.2.10)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.23 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.2.24)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.2.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.1.93)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain) (24.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.23->langchain) (2.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.26.3)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m79.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m108.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.1/41.1 MB\u001b[0m \u001b[31m124.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.1 scipy-1.14.0 threadpoolctl-3.5.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting ollama\n",
      "  Downloading ollama-0.3.0-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /opt/conda/lib/python3.10/site-packages (from ollama) (0.27.0)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (4.3.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.5)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.4)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<0.28.0,>=0.27.0->ollama) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<0.28.0,>=0.27.0->ollama) (4.9.0)\n",
      "Downloading ollama-0.3.0-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: ollama\n",
      "Successfully installed ollama-0.3.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting pandas\n",
      "  Downloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m128.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m86.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tzdata, pandas\n",
      "Successfully installed pandas-2.2.2 tzdata-2024.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.9/250.9 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# update or install the necessary libraries\n",
    "!pip install --upgrade langchain\n",
    "!pip install --upgrade python-dotenv\n",
    "!pip install langchain_community\n",
    "!pip install --upgrade langchain langchain_community\n",
    "!pip install -U scikit-learn\n",
    "!pip install --upgrade ollama\n",
    "!pip install pandas\n",
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oYQ1tLEjqcK4"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import IPython\n",
    "IPython.display.clear_output(wait=True)\n",
    "from langchain.llms import OpenAI\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import json\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "raRFI4yNBTjn"
   },
   "source": [
    "# LLama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'models': [{'name': 'falcon:latest',\n",
       "   'model': 'falcon:latest',\n",
       "   'modified_at': '2024-07-27T20:35:18.808927804Z',\n",
       "   'size': 4210994570,\n",
       "   'digest': '4280f7257e73108cddb43de89eb9fa28350a21aaaf997b5935719f9de0281563',\n",
       "   'details': {'parent_model': '',\n",
       "    'format': 'gguf',\n",
       "    'family': 'falcon',\n",
       "    'families': None,\n",
       "    'parameter_size': '7B',\n",
       "    'quantization_level': 'Q4_0'}},\n",
       "  {'name': 'llama3:70b',\n",
       "   'model': 'llama3:70b',\n",
       "   'modified_at': '2024-07-27T20:34:52.969050593Z',\n",
       "   'size': 39969745349,\n",
       "   'digest': '786f3184aec0e907952488b865362bdaa38180739a9881a8190d85bad8cab893',\n",
       "   'details': {'parent_model': '',\n",
       "    'format': 'gguf',\n",
       "    'family': 'llama',\n",
       "    'families': ['llama'],\n",
       "    'parameter_size': '70.6B',\n",
       "    'quantization_level': 'Q4_0'}}]}"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ollama.list()  # To check downloaded models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'success'}"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ollama.pull(\"llama3:70b\")\n",
    "ollama.pull(\"falcon:latest\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "N9aAmQWoqcK8"
   },
   "outputs": [],
   "source": [
    "def set_llama_params(model=\"llama3:70b\"):  # update model to your preference\n",
    "    \"\"\" set llama parameters\"\"\"\n",
    "    model_response = ollama.chat(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a llama assistant that talks like a llama, starting every word with 'll'.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Hi, happy llama day!\"},\n",
    "        ],\n",
    "        stream=False\n",
    "    )\n",
    "    return {\"model\": model_response.get(\"model\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "llama3:70b\n"
     ]
    }
   ],
   "source": [
    "model = \"llama3:70b\"\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'llama3:70b'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_llama_params(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "XxKH3yMcgkSL"
   },
   "outputs": [],
   "source": [
    "def get_completion(params, messages):\n",
    "    \"\"\" GET completion from llama model\"\"\"\n",
    "    response = None\n",
    "    payload = {\n",
    "        \"model\": params[\"model\"],\n",
    "        \"tools\": [\n",
    "            {\"functions\": [\n",
    "                {'name': 'fake_news_detection',\n",
    "                'description': 'Detect whether a given news is fake or not.',\n",
    "                'parameters': {\n",
    "                    'type': 'object',\n",
    "                    'properties': {\n",
    "                        'sentiment': {\n",
    "                            'title': 'sentiment',\n",
    "                            'type': 'string',\n",
    "                            'description': 'the sentiment encountered in the passage'\n",
    "                        },\n",
    "                        'is_fake': {\n",
    "                            'title': 'is fake',\n",
    "                            'type': 'integer',\n",
    "                            'description': 'Determine whether the text is real or fake. if real then output = 0 and if fake then output = 1. Output must be integer 0 or 1 alone.'\n",
    "                        },\n",
    "                        'language': {\n",
    "                            'title': 'language',\n",
    "                            'type': 'string',\n",
    "                            'description': 'the language of the passage'\n",
    "                        }\n",
    "                      },\n",
    "                      'required': ['sentiment', 'is_fake', 'language']\n",
    "                    },\n",
    "                    \"function_call\": {\"name\": \"fake_news_detection\"},\n",
    "                }\n",
    "            ],}\n",
    "        ],\n",
    "        \"stream\": False,\n",
    "        \"options\": {\n",
    "            \"max_tokens\": 1,\n",
    "            \"temperature\": 0.1,\n",
    "        },\n",
    "    }\n",
    "    payload[\"messages\"] = messages\n",
    "\n",
    "    model_response = ollama.chat(\n",
    "        model=payload[\"model\"],\n",
    "        messages=payload[\"messages\"],\n",
    "        #tools=payload[\"tools\"], # track this PR: https://github.com/ollama/ollama-python/pull/213\n",
    "        options=payload[\"options\"],\n",
    "        stream=False\n",
    "    )\n",
    "\n",
    "    return model_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D5Pp6v3Mf2k6",
    "outputId": "33298c12-efe8-445e-e7e1-975bf6a5924d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3:70b'}\n"
     ]
    }
   ],
   "source": [
    "params = set_llama_params()\n",
    "\n",
    "if not params:\n",
    "  raise Exception(\"llama exception\")\n",
    "\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0Buk1j7eHsd"
   },
   "source": [
    "## ANS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHkJYsjJeAuL"
   },
   "source": [
    "### Zero Shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "hOOcXbMudKpI"
   },
   "outputs": [],
   "source": [
    "df_ans_zs = pd.read_csv('./datasets/ANS/test.csv')\n",
    "\n",
    "# Initialize a list to store the prompts\n",
    "prompts = []\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in df_ans_zs.iterrows():\n",
    "    sentence = row['claim_s']\n",
    "    fake_flag = row['fake_flag']\n",
    "\n",
    "    # Generate prompt based on each row\n",
    "    prompt = f\"\"\"Determine whether the following text is real or fake. if real then output = 0 and if fake then output = 1. Output must be integer 0 or 1 alone. No text.\n",
    "\n",
    "Text: {sentence}\"\"\"\n",
    "\n",
    "    # Append the prompt along with sentence and fake flag to the list\n",
    "    prompts.append((sentence, fake_flag, prompt))\n",
    "\n",
    "# Convert the list of prompts into a new DataFrame\n",
    "prompts_df_ans_zs = pd.DataFrame(prompts, columns=['Sentence', 'Fake Flag', 'Prompt'])\n",
    "\n",
    "# Save the prompts DataFrame to a new CSV file\n",
    "prompts_df_ans_zs.to_csv('prompts_df_ans_zs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "UAjkJ5mLzdFU",
    "outputId": "075bd32c-257a-4c8d-9d7e-b9846f7d4c78"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Fake Flag</th>\n",
       "      <th>Prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>المبعوث الدولي يطالب تل أبيب وحماس بالتراجع حا...</td>\n",
       "      <td>0</td>\n",
       "      <td>Determine whether the following text is real o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>بورصات أوروبية تتعرض لضربة إيطالية</td>\n",
       "      <td>0</td>\n",
       "      <td>Determine whether the following text is real o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>بحسب وسائل إعلام أمريكية: تركيا تمتلك تسجيلات ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Determine whether the following text is real o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>حقائق عن رفع شركات السيارات لأسعار قطع الغيار</td>\n",
       "      <td>0</td>\n",
       "      <td>Determine whether the following text is real o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>من هو نبيل رجب الذي سُجن لأنه حطّ من هيبة البح...</td>\n",
       "      <td>0</td>\n",
       "      <td>Determine whether the following text is real o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>أسماء الأسد تخضع للعلاج من سرطان الثدي</td>\n",
       "      <td>0</td>\n",
       "      <td>Determine whether the following text is real o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>الرئيس الفرنسي أقنع ترامب ببقاء القوات الأمريك...</td>\n",
       "      <td>0</td>\n",
       "      <td>Determine whether the following text is real o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>في صحف عربية: جسد سوريا الممزق بين أمريكا وروسيا</td>\n",
       "      <td>0</td>\n",
       "      <td>Determine whether the following text is real o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>موسيقى صوفية جذورها أفريقية في لبنان</td>\n",
       "      <td>1</td>\n",
       "      <td>Determine whether the following text is real o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>تعرف على أردوغان الذى روّض العسكر و حكم ل16 عا...</td>\n",
       "      <td>0</td>\n",
       "      <td>Determine whether the following text is real o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>456 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence  Fake Flag  \\\n",
       "0    المبعوث الدولي يطالب تل أبيب وحماس بالتراجع حا...          0   \n",
       "1                   بورصات أوروبية تتعرض لضربة إيطالية          0   \n",
       "2    بحسب وسائل إعلام أمريكية: تركيا تمتلك تسجيلات ...          0   \n",
       "3        حقائق عن رفع شركات السيارات لأسعار قطع الغيار          0   \n",
       "4    من هو نبيل رجب الذي سُجن لأنه حطّ من هيبة البح...          0   \n",
       "..                                                 ...        ...   \n",
       "451             أسماء الأسد تخضع للعلاج من سرطان الثدي          0   \n",
       "452  الرئيس الفرنسي أقنع ترامب ببقاء القوات الأمريك...          0   \n",
       "453   في صحف عربية: جسد سوريا الممزق بين أمريكا وروسيا          0   \n",
       "454               موسيقى صوفية جذورها أفريقية في لبنان          1   \n",
       "455  تعرف على أردوغان الذى روّض العسكر و حكم ل16 عا...          0   \n",
       "\n",
       "                                                Prompt  \n",
       "0    Determine whether the following text is real o...  \n",
       "1    Determine whether the following text is real o...  \n",
       "2    Determine whether the following text is real o...  \n",
       "3    Determine whether the following text is real o...  \n",
       "4    Determine whether the following text is real o...  \n",
       "..                                                 ...  \n",
       "451  Determine whether the following text is real o...  \n",
       "452  Determine whether the following text is real o...  \n",
       "453  Determine whether the following text is real o...  \n",
       "454  Determine whether the following text is real o...  \n",
       "455  Determine whether the following text is real o...  \n",
       "\n",
       "[456 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts_df_ans_zs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "MjBNl3Tfk5yc"
   },
   "outputs": [],
   "source": [
    "# Define function to calculate metrics\n",
    "def calculate_metrics(test_set, params):\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in test_set.iterrows():\n",
    "        #sentence = row[\"claim_s\"]\n",
    "        sentence = re.sub(r'[\\W_]+', ' ', row[\"claim_s\"])\n",
    "        actual_label = row[\"fake_flag\"]\n",
    "\n",
    "        # Generate prompt based on each row\n",
    "        prompt = f\"\"\"Determine whether the following text is real or fake. if real then output = 0 and if fake then output = 1. Output must be integer 0 or 1 alone. No text.\n",
    "\n",
    "Text: {sentence}\"\"\"\n",
    "\n",
    "        # Call the get_completion function with prompt and params\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        response = get_completion(params, messages)\n",
    "        predicted_label = int(response.get(\"message\").get(\"content\"))\n",
    "        true_labels.append(actual_label)\n",
    "        predicted_labels.append(predicted_label)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels)\n",
    "    recall = recall_score(true_labels, predicted_labels)\n",
    "    f1 = f1_score(true_labels, predicted_labels)\n",
    "\n",
    "    return accuracy, precision, recall, f1, predicted_labels\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lmepSSKSwoXk",
    "outputId": "010e00f7-3c6b-4e90-90b6-e162d1c4e486"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6600877192982456\n",
      "Precision: 0.2727272727272727\n",
      "Recall: 0.02\n",
      "F1 Score: 0.037267080745341616\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "accuracy, precision, recall, f1, predicted_ans_zs_llama8b = calculate_metrics(df_ans_zs, params)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_ans_zs_llama8b)  # var name shoul've been 70b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ans_zs = [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MXKjbrRtjS6c"
   },
   "source": [
    "### Zero Shot CoT Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "GbRsJF0ejS6c"
   },
   "outputs": [],
   "source": [
    "df_ans_zs_cot = pd.read_csv('./datasets/ANS/test.csv')\n",
    "\n",
    "# Initialize a list to store the prompts\n",
    "prompts = []\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in df_ans_zs_cot.iterrows():\n",
    "    sentence = row['claim_s']\n",
    "    fake_flag = row['fake_flag']\n",
    "\n",
    "    # Generate prompt based on each row (CoT)\n",
    "    prompt = f\"\"\"The output of this prompt must at length 1 with two possible values 0 or 1:\n",
    "    \n",
    "              Analyze the following statement to determine its authenticity by considering these steps:\n",
    "              1. Content Verification: Check if the claims made in the content can be independently verified with other credible information available.\n",
    "              2. Logical Consistency: Assess whether the statement is logically consistent and whether it contains contradictions or implausible assertions.\n",
    "\n",
    "              After carefully considering these points, determine whether the following text is real or fake. if real then output = 0 and if fake then output = 1\n",
    "\n",
    "              Text: {sentence}\n",
    "\n",
    "              Answer:\"\"\"\n",
    "\n",
    "    # Append the prompt along with sentence and fake flag to the list\n",
    "    prompts.append((sentence, fake_flag, prompt))\n",
    "\n",
    "# Convert the list of prompts into a new DataFrame\n",
    "prompts_df_ans_zs_cot = pd.DataFrame(prompts, columns=['Sentence', 'Fake Flag', 'Prompt'])\n",
    "\n",
    "# Save the prompts DataFrame to a new CSV file\n",
    "prompts_df_ans_zs_cot.to_csv('prompts_df_ans_zs_cot.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "rdhNnXuejS6d",
    "outputId": "e339c1b5-ac99-4a14-96ee-f54449a75db0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Fake Flag</th>\n",
       "      <th>Prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>المبعوث الدولي يطالب تل أبيب وحماس بالتراجع حا...</td>\n",
       "      <td>0</td>\n",
       "      <td>The output of this prompt must at length 1 wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>بورصات أوروبية تتعرض لضربة إيطالية</td>\n",
       "      <td>0</td>\n",
       "      <td>The output of this prompt must at length 1 wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>بحسب وسائل إعلام أمريكية: تركيا تمتلك تسجيلات ...</td>\n",
       "      <td>0</td>\n",
       "      <td>The output of this prompt must at length 1 wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>حقائق عن رفع شركات السيارات لأسعار قطع الغيار</td>\n",
       "      <td>0</td>\n",
       "      <td>The output of this prompt must at length 1 wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>من هو نبيل رجب الذي سُجن لأنه حطّ من هيبة البح...</td>\n",
       "      <td>0</td>\n",
       "      <td>The output of this prompt must at length 1 wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>أسماء الأسد تخضع للعلاج من سرطان الثدي</td>\n",
       "      <td>0</td>\n",
       "      <td>The output of this prompt must at length 1 wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>الرئيس الفرنسي أقنع ترامب ببقاء القوات الأمريك...</td>\n",
       "      <td>0</td>\n",
       "      <td>The output of this prompt must at length 1 wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>في صحف عربية: جسد سوريا الممزق بين أمريكا وروسيا</td>\n",
       "      <td>0</td>\n",
       "      <td>The output of this prompt must at length 1 wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>موسيقى صوفية جذورها أفريقية في لبنان</td>\n",
       "      <td>1</td>\n",
       "      <td>The output of this prompt must at length 1 wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>تعرف على أردوغان الذى روّض العسكر و حكم ل16 عا...</td>\n",
       "      <td>0</td>\n",
       "      <td>The output of this prompt must at length 1 wit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>456 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence  Fake Flag  \\\n",
       "0    المبعوث الدولي يطالب تل أبيب وحماس بالتراجع حا...          0   \n",
       "1                   بورصات أوروبية تتعرض لضربة إيطالية          0   \n",
       "2    بحسب وسائل إعلام أمريكية: تركيا تمتلك تسجيلات ...          0   \n",
       "3        حقائق عن رفع شركات السيارات لأسعار قطع الغيار          0   \n",
       "4    من هو نبيل رجب الذي سُجن لأنه حطّ من هيبة البح...          0   \n",
       "..                                                 ...        ...   \n",
       "451             أسماء الأسد تخضع للعلاج من سرطان الثدي          0   \n",
       "452  الرئيس الفرنسي أقنع ترامب ببقاء القوات الأمريك...          0   \n",
       "453   في صحف عربية: جسد سوريا الممزق بين أمريكا وروسيا          0   \n",
       "454               موسيقى صوفية جذورها أفريقية في لبنان          1   \n",
       "455  تعرف على أردوغان الذى روّض العسكر و حكم ل16 عا...          0   \n",
       "\n",
       "                                                Prompt  \n",
       "0    The output of this prompt must at length 1 wit...  \n",
       "1    The output of this prompt must at length 1 wit...  \n",
       "2    The output of this prompt must at length 1 wit...  \n",
       "3    The output of this prompt must at length 1 wit...  \n",
       "4    The output of this prompt must at length 1 wit...  \n",
       "..                                                 ...  \n",
       "451  The output of this prompt must at length 1 wit...  \n",
       "452  The output of this prompt must at length 1 wit...  \n",
       "453  The output of this prompt must at length 1 wit...  \n",
       "454  The output of this prompt must at length 1 wit...  \n",
       "455  The output of this prompt must at length 1 wit...  \n",
       "\n",
       "[456 rows x 3 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts_df_ans_zs_cot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(content):\n",
    "    \"\"\"\n",
    "    Extracts the prediction (0 or 1) based on the content.\n",
    "\n",
    "    Parameters:\n",
    "    - content (str): The content from the LLM response.\n",
    "\n",
    "    Returns:\n",
    "    - int: 0 if the text is real, 1 if the text is fake.\n",
    "    \"\"\"\n",
    "    if re.search(r'\\b(fake|1)\\b', content, re.IGNORECASE):\n",
    "        return 1\n",
    "    elif re.search(r'\\b(real|0)\\b', content, re.IGNORECASE):\n",
    "        return 0\n",
    "    else:\n",
    "        # Default case if neither \"real\" nor \"fake\" is clearly indicated\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "sPjK0IL1jS6d"
   },
   "outputs": [],
   "source": [
    "# Define function to calculate metrics\n",
    "def calculate_metrics(test_set, params):\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in test_set.iterrows():\n",
    "        sentence = re.sub(r'[\\W_]+', ' ', row[\"claim_s\"])\n",
    "        actual_label = row[\"fake_flag\"]\n",
    "\n",
    "        # Generate prompt based on each row (CoT)\n",
    "        prompt = f\"\"\"The output of this prompt must at length 1 with two possible values 0 or 1:\n",
    "        \n",
    "        \n",
    "                  Analyze the following statement to determine its authenticity by considering these steps:\n",
    "                  1. Content Verification: Check if the claims made in the content can be independently verified with other credible information available.\n",
    "                  2. Logical Consistency: Assess whether the statement is logically consistent and whether it contains contradictions or implausible assertions.\n",
    "                  \n",
    "                  After carefully considering these points, determine whether the following text is real or fake. if real then output = 0 and if fake then output = 1\n",
    "                  \n",
    "                  Text: {sentence}\n",
    "\n",
    "                  Answer:\"\"\"\n",
    "\n",
    "        # Call the get_completion function with prompt and params\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        response = get_completion(params, messages)\n",
    "        print(response)\n",
    "        content = response.get(\"message\").get(\"content\")\n",
    "        predicted_label = get_prediction(content)\n",
    "        print(predicted_label)\n",
    "        none_count = 0\n",
    "        \n",
    "        if predicted_label is not None:\n",
    "            true_labels.append(actual_label)\n",
    "            predicted_labels.append(predicted_label)\n",
    "        else:\n",
    "            none_count += 1 \n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels)\n",
    "    recall = recall_score(true_labels, predicted_labels)\n",
    "    f1 = f1_score(true_labels, predicted_labels)\n",
    "\n",
    "    return accuracy, precision, recall, f1, predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "cLEh2WDojS6d",
    "outputId": "b8f58653-5b53-4172-f7f4-1b091548f1ee",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:13:40.421109198Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1007389807, 'load_duration': 31260472, 'prompt_eval_count': 164, 'prompt_eval_duration': 139061000, 'eval_count': 20, 'eval_duration': 790456000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:13:45.643004632Z', 'message': {'role': 'assistant', 'content': \"After analyzing the statement using the provided steps, I determined that the authenticity of the text is:\\n\\nOutput: 0 (Real)\\n\\nHere's my analysis:\\n\\n1. Content Verification: The claim made in the content can be independently verified with other credible information available. A quick search reveals that European stock markets have indeed been affected by Italian economic and political developments in the past.\\n2. Logical Consistency: The statement is logically consistent and does not contain contradictions or implausible assertions. It is a plausible and coherent claim.\\n\\nBased on these steps, I conclude that the text is real (output = 0).\"}, 'done_reason': 'stop', 'done': True, 'total_duration': 5217403987, 'load_duration': 24743780, 'prompt_eval_count': 153, 'prompt_eval_duration': 111938000, 'eval_count': 122, 'eval_duration': 5032149000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:13:46.659171535Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1012147944, 'load_duration': 38949850, 'prompt_eval_count': 169, 'prompt_eval_duration': 138344000, 'eval_count': 20, 'eval_duration': 789767000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:13:50.258832013Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified without additional context or information. The text appears to be a title or headline in Arabic, which translates to \"Facts about car companies raising spare parts prices.\" \\n\\nWithout further information or content to verify the claims made in this title, it is difficult to determine its authenticity. Therefore, I will output:\\n\\n1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3595863239, 'load_duration': 30139816, 'prompt_eval_count': 152, 'prompt_eval_duration': 109897000, 'eval_count': 83, 'eval_duration': 3406110000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:13:51.453733304Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is fake. Therefore, the output is:\\n\\n1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1191788519, 'load_duration': 28504000, 'prompt_eval_count': 156, 'prompt_eval_duration': 122313000, 'eval_count': 25, 'eval_duration': 996433000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:13:52.467460104Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1010590269, 'load_duration': 30455634, 'prompt_eval_count': 170, 'prompt_eval_duration': 146238000, 'eval_count': 20, 'eval_duration': 790326000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:13:57.236662547Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nThe text \"وفاة يوهان يوهانسون المؤلف الموسيقي الأيسلندي الشهير\" translates to \"The death of Jóhann Jóhannsson, the famous Icelandic musician and composer\". \\n\\nJóhann Jóhannsson was a real person, an Icelandic composer and musician who passed away on February 9, 2018. This information can be independently verified through credible sources.\\n\\nTherefore, the output is: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4767027550, 'load_duration': 72444417, 'prompt_eval_count': 159, 'prompt_eval_duration': 125155000, 'eval_count': 111, 'eval_duration': 4566711000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:14:01.870111103Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"هدوء بين إسرائيل و قطاع غزة\" translates to \"Calm between Israel and the Gaza Strip\".\\n\\nContent Verification: The claim of calm between Israel and the Gaza Strip can be independently verified through credible news sources and official reports.\\n\\nLogical Consistency: The statement appears logically consistent, as it does not contain contradictions or implausible assertions.\\n\\nBased on these assessments, I conclude that the text is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4630312885, 'load_duration': 31803801, 'prompt_eval_count': 150, 'prompt_eval_duration': 110526000, 'eval_count': 107, 'eval_duration': 4404054000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:14:02.736383689Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 863879433, 'load_duration': 69551585, 'prompt_eval_count': 159, 'prompt_eval_duration': 125385000, 'eval_count': 17, 'eval_duration': 666144000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:14:07.062100322Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text \"العالم في أسبوع بالصور\" cannot be verified as it appears to be a title or a headline in Arabic, which translates to \"The World in a Week in Pictures\". This title does not make any claims that can be independently verified with other credible information available.\\n\\nTherefore, based on the analysis, I conclude that the text is likely fake or unverifiable. Hence, my output is:\\n\\n1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4323023481, 'load_duration': 29569027, 'prompt_eval_count': 145, 'prompt_eval_duration': 101861000, 'eval_count': 101, 'eval_duration': 4149343000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:14:12.204783082Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified without more context or information. The text appears to be a headline or title in Arabic, which translates to \"Warnings from China about the American trade war.\"\\n\\nSince there is no specific claim or assertion made in the text, it\\'s challenging to verify its content independently. Additionally, the text does not contain any logical inconsistencies or implausible assertions.\\n\\nGiven the lack of information, I\\'m inclined to err on the side of caution and consider this text as potentially fake. Therefore, my output is:\\n\\n1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 5138233062, 'load_duration': 34669102, 'prompt_eval_count': 151, 'prompt_eval_duration': 110983000, 'eval_count': 120, 'eval_duration': 4945982000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:14:13.407917502Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL. Therefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1199017611, 'load_duration': 29820836, 'prompt_eval_count': 157, 'prompt_eval_duration': 124425000, 'eval_count': 25, 'eval_duration': 997970000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:14:14.608546279Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is fake. Therefore, the output is:\\n\\n1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1197774975, 'load_duration': 32191240, 'prompt_eval_count': 158, 'prompt_eval_duration': 124497000, 'eval_count': 25, 'eval_duration': 997205000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:14:19.096163563Z', 'message': {'role': 'assistant', 'content': \"After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nHere's my analysis:\\n\\n1. Content Verification: The claim made in the content can be independently verified with other credible information available. Jordan has been actively promoting its tourism sector, and there have been reports of significant economic growth in this area.\\n2. Logical Consistency: The statement is logically consistent and does not contain contradictions or implausible assertions.\\n\\nBased on my analysis, I conclude that the text is REAL.\\n\\nOutput: 0\"}, 'done_reason': 'stop', 'done': True, 'total_duration': 4482868497, 'load_duration': 29686816, 'prompt_eval_count': 156, 'prompt_eval_duration': 124866000, 'eval_count': 104, 'eval_duration': 4284255000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:14:22.83895727Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nThe translation of the text is \"Rodin\\'s kiss from Dante\\'s Hell to the British Museum\". This statement appears to be a factual description of a artwork by Auguste Rodin, titled \"The Kiss\", which was inspired by Dante\\'s Divine Comedy and is indeed housed in the British Museum. \\n\\nTherefore, my output is: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3739505167, 'load_duration': 34002845, 'prompt_eval_count': 155, 'prompt_eval_duration': 124415000, 'eval_count': 86, 'eval_duration': 3531574000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:14:24.706097766Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"لعبة الحوت الأزرق تثير إعجاب المصريين\" is real.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1863911895, 'load_duration': 38019003, 'prompt_eval_count': 154, 'prompt_eval_duration': 123459000, 'eval_count': 40, 'eval_duration': 1618281000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:14:29.936750797Z', 'message': {'role': 'assistant', 'content': \"After analyzing the statement using the provided steps, I determined that the authenticity of the text is:\\n\\n**Output: 0**\\n\\nHere's my analysis:\\n\\n1. Content Verification: The claim made in the content is about Erdogan failing during a time of economic crisis in Turkey. This can be independently verified with other credible information available, as there have been reports of economic struggles in Turkey during Erdogan's presidency.\\n2. Logical Consistency: The statement appears to be logically consistent and does not contain contradictions or implausible assertions.\\n\\nBased on these steps, I conclude that the text is real (Output = 0).\"}, 'done_reason': 'stop', 'done': True, 'total_duration': 5227946889, 'load_duration': 73256314, 'prompt_eval_count': 154, 'prompt_eval_duration': 124060000, 'eval_count': 122, 'eval_duration': 5028162000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:14:30.955249497Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1009677565, 'load_duration': 28536930, 'prompt_eval_count': 170, 'prompt_eval_duration': 146427000, 'eval_count': 20, 'eval_duration': 790094000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:14:32.153338843Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL. Therefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1195619663, 'load_duration': 29291498, 'prompt_eval_count': 158, 'prompt_eval_duration': 125031000, 'eval_count': 25, 'eval_duration': 997411000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:14:37.358716098Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text \"العالم في شهر بالصور\" cannot be verified as it appears to be a phrase in Arabic language and lacks any specific claims or information that can be independently verified.\\n\\nHowever, based on the content and structure of the phrase, it seems to be a legitimate title or headline that could be used in an article or news story. The phrase translates to \"The world in a month in pictures\" which appears to be a plausible and logically consistent statement.\\n\\nTherefore, I conclude that the text is real.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 5203271191, 'load_duration': 74652701, 'prompt_eval_count': 143, 'prompt_eval_duration': 102516000, 'eval_count': 122, 'eval_duration': 5023516000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:14:42.203861527Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified. The text appears to be in Arabic and translates to \"The Brent reaches its highest level and the eyes are turned to Iran.\" \\n\\nWithout additional context or information, it is difficult to verify the claims made in the content independently. Additionally, the statement seems to contain a metaphorical expression (\"the eyes are turned to Iran\"), which may not be literally true.\\n\\nTherefore, based on the analysis, I conclude that the text is likely fake.\\n\\nOutput: 1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4840423852, 'load_duration': 30623254, 'prompt_eval_count': 153, 'prompt_eval_duration': 112128000, 'eval_count': 113, 'eval_duration': 4652874000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:14:44.006784936Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"النفط ينخفض وسط مخاوف النمو\" is real. Therefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1799667008, 'load_duration': 28558540, 'prompt_eval_count': 150, 'prompt_eval_duration': 110642000, 'eval_count': 40, 'eval_duration': 1616946000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:14:45.013024432Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1001847498, 'load_duration': 31321352, 'prompt_eval_count': 163, 'prompt_eval_duration': 136816000, 'eval_count': 20, 'eval_duration': 789229000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:14:46.213643052Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL. Therefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1198037207, 'load_duration': 74460411, 'prompt_eval_count': 157, 'prompt_eval_duration': 124575000, 'eval_count': 25, 'eval_duration': 996527000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:14:52.40400276Z', 'message': {'role': 'assistant', 'content': \"After analyzing the statement using the provided steps, I determined that the text is fake.\\n\\nHere's my analysis:\\n\\n1. Content Verification: The claim made in the content is that the United Nations (شجعت الأمم المتحدة) has destroyed the Libyan capital completely. However, there is no credible information available to support this claim. In fact, a quick search reveals that the Libyan capital, Tripoli, is still intact and functioning.\\n2. Logical Consistency: The statement contains an implausible assertion. It is highly unlikely that the United Nations would engage in such a destructive act, especially considering its mandate to promote peace and stability.\\n\\nBased on this analysis, I conclude that the text is fake.\\n\\nOutput: 1\"}, 'done_reason': 'stop', 'done': True, 'total_duration': 6186558688, 'load_duration': 29853336, 'prompt_eval_count': 156, 'prompt_eval_duration': 124409000, 'eval_count': 145, 'eval_duration': 5988687000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:14:56.581203289Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text \"إنفوغرافيك صراع الخمسة الكبار\" cannot be verified as it appears to be a nonsensical phrase in Arabic.\\n\\nContent Verification: The claims made in the content cannot be independently verified with other credible information available.\\n\\nLogical Consistency: The statement is not logically consistent and contains implausible assertions.\\n\\nTherefore, I conclude that the text is fake.\\n\\nOutput: 1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4173390150, 'load_duration': 30672155, 'prompt_eval_count': 150, 'prompt_eval_duration': 110495000, 'eval_count': 97, 'eval_duration': 3987545000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:14:57.706078843Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1121241784, 'load_duration': 37572765, 'prompt_eval_count': 156, 'prompt_eval_duration': 124468000, 'eval_count': 22, 'eval_duration': 871875000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:15:01.096606141Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"أزمة إيطاليا تضرب بورصات أوروبية\" is real. The translation of this Arabic text to English is \"Italy\\'s crisis hits European stock markets\". This statement can be independently verified with other credible information available, and it does not contain contradictions or implausible assertions.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3388011125, 'load_duration': 77434583, 'prompt_eval_count': 151, 'prompt_eval_duration': 111477000, 'eval_count': 78, 'eval_duration': 3195992000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:15:01.957491296Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 857000286, 'load_duration': 24506941, 'prompt_eval_count': 159, 'prompt_eval_duration': 125315000, 'eval_count': 17, 'eval_duration': 665161000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:15:02.991778484Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is FAKE. Therefore, the output is:\\n\\n1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1028685414, 'load_duration': 29188478, 'prompt_eval_count': 161, 'prompt_eval_duration': 125350000, 'eval_count': 21, 'eval_duration': 831543000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:15:03.995878998Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 999395187, 'load_duration': 29254659, 'prompt_eval_count': 165, 'prompt_eval_duration': 134816000, 'eval_count': 20, 'eval_duration': 790216000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:15:08.310067207Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is FAKE.\\n\\nThe text translates to \"How chemical weapons helped Assad approach achieving victory.\" This claim cannot be independently verified with credible information available. In fact, the use of chemical weapons by the Syrian government has been widely condemned and denied by international organizations and governments.\\n\\nAdditionally, the statement contains implausible assertions, as there is no evidence to suggest that chemical weapons were used to achieve a military victory in Syria.\\n\\nTherefore, my output is: 1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4310922519, 'load_duration': 32293510, 'prompt_eval_count': 160, 'prompt_eval_duration': 125196000, 'eval_count': 100, 'eval_duration': 4110052000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:15:11.741702402Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified through independent credible sources (Content Verification). Additionally, the text appears to be a phrase in Arabic, but its meaning and context are unclear, making it difficult to assess its logical consistency.\\n\\nBased on this analysis, I conclude that the text is likely fake. Therefore, my output is:\\n\\n1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3426995069, 'load_duration': 31920361, 'prompt_eval_count': 149, 'prompt_eval_duration': 110970000, 'eval_count': 79, 'eval_duration': 3239647000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:15:12.815307591Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1069225281, 'load_duration': 30012175, 'prompt_eval_count': 156, 'prompt_eval_duration': 124270000, 'eval_count': 22, 'eval_duration': 872036000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:15:17.734303167Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified as it appears to be a phrase in Arabic language which translates to \"Lifting the curfew in Basra\". Without additional context or information, it is difficult to verify its claims independently.\\n\\nHowever, based on logical consistency, the statement does not contain any contradictions or implausible assertions. It appears to be a simple declaration of an event or action.\\n\\nGiven the lack of verifiable evidence, I would classify this text as potentially fake. Therefore, my output is:\\n\\n1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4916949102, 'load_duration': 68677638, 'prompt_eval_count': 147, 'prompt_eval_duration': 110427000, 'eval_count': 115, 'eval_duration': 4735420000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:15:18.822130717Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is FAKE. Therefore, the output is:\\n\\n1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1084757288, 'load_duration': 72706325, 'prompt_eval_count': 162, 'prompt_eval_duration': 136587000, 'eval_count': 21, 'eval_duration': 830725000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:15:20.02644207Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1201377601, 'load_duration': 35426940, 'prompt_eval_count': 158, 'prompt_eval_duration': 124898000, 'eval_count': 25, 'eval_duration': 998477000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:15:20.896495111Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 866213671, 'load_duration': 31642751, 'prompt_eval_count': 159, 'prompt_eval_duration': 124819000, 'eval_count': 17, 'eval_duration': 664824000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:15:21.901758952Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1000580525, 'load_duration': 29484338, 'prompt_eval_count': 162, 'prompt_eval_duration': 136834000, 'eval_count': 20, 'eval_duration': 789958000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:15:22.976348079Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1072386543, 'load_duration': 74071942, 'prompt_eval_count': 154, 'prompt_eval_duration': 123968000, 'eval_count': 22, 'eval_duration': 871717000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:15:28.79409076Z', 'message': {'role': 'assistant', 'content': \"After analyzing the statement using the provided steps, I determined that the text is fake.\\n\\nHere's my analysis:\\n\\n1. Content Verification: The claim made in the content appears to be about Israel failing to obtain something related to Eli Cohen. However, I couldn't find any credible information available to independently verify this claim.\\n2. Logical Consistency: The statement seems to be logically consistent at first glance, but upon closer inspection, it raises more questions than answers. Who is Eli Cohen, and what does he have to do with Israel? Without more context, the statement appears implausible.\\n\\nBased on my analysis, I conclude that the text is fake.\\n\\nOutput: 1\"}, 'done_reason': 'stop', 'done': True, 'total_duration': 5813951891, 'load_duration': 30524244, 'prompt_eval_count': 154, 'prompt_eval_duration': 121579000, 'eval_count': 135, 'eval_duration': 5573728000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:15:30.482858066Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"رفع الحظر عن الواردات المصرية في السعودية\" is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1685127827, 'load_duration': 76332777, 'prompt_eval_count': 150, 'prompt_eval_duration': 112472000, 'eval_count': 37, 'eval_duration': 1493226000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:15:33.345695471Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified with certainty. The text appears to be a claim or an opinion rather than a verifiable fact.\\n\\nHowever, based on my understanding of the content and logical consistency, I will provide an output.\\n\\nOutput: 1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 2860464601, 'load_duration': 72831705, 'prompt_eval_count': 155, 'prompt_eval_duration': 124350000, 'eval_count': 64, 'eval_duration': 2618307000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:15:34.307112627Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 959134852, 'load_duration': 32122480, 'prompt_eval_count': 163, 'prompt_eval_duration': 134472000, 'eval_count': 20, 'eval_duration': 790366000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:15:35.314253065Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1002543531, 'load_duration': 30408375, 'prompt_eval_count': 166, 'prompt_eval_duration': 137344000, 'eval_count': 20, 'eval_duration': 790069000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:15:36.226031309Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 907992676, 'load_duration': 30035997, 'prompt_eval_count': 161, 'prompt_eval_duration': 125380000, 'eval_count': 17, 'eval_duration': 665494000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:15:41.578688799Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"الذهب يتعافى رغم أزمة إيطاليا\" is REAL.\\n\\nHere\\'s my analysis:\\n\\n1. Content Verification: The claim made in the content can be independently verified with other credible information available. Gold prices have historically been affected by global economic events, including crises in countries like Italy.\\n2. Logical Consistency: The statement is logically consistent and does not contain contradictions or implausible assertions. It\\'s possible for gold prices to rise despite an economic crisis in Italy.\\n\\nBased on this analysis, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 5349612068, 'load_duration': 73242274, 'prompt_eval_count': 152, 'prompt_eval_duration': 113880000, 'eval_count': 125, 'eval_duration': 5159423000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:15:45.399032634Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nThe text translates to \"The United Nations announces a ceasefire in the Libyan capital.\" This claim can be independently verified with other credible information available. The UN has been involved in peacekeeping efforts in Libya and has made announcements about ceasefires in the past.\\n\\nAdditionally, the statement appears logically consistent and does not contain contradictions or implausible assertions.\\n\\nTherefore, my output is: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3816220117, 'load_duration': 31309662, 'prompt_eval_count': 159, 'prompt_eval_duration': 125652000, 'eval_count': 88, 'eval_duration': 3614340000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:15:47.12784257Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"زلزال ضعيف على الحدود الإيرانية العراقية\" is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1724848317, 'load_duration': 30110735, 'prompt_eval_count': 153, 'prompt_eval_duration': 109539000, 'eval_count': 38, 'eval_duration': 1535439000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:15:52.099642371Z', 'message': {'role': 'assistant', 'content': \"After analyzing the statement using the provided steps, I conclude that the text is REAL.\\n\\nHere's my analysis:\\n\\n1. Content Verification: The claim made in the content can be independently verified with other credible information available. It is a well-established fact that the stability of the Middle East region has a significant impact on the global oil market.\\n2. Logical Consistency: The statement is logically consistent and does not contain contradictions or implausible assertions. The idea that regional stability contributes to oil market stability is a coherent and reasonable claim.\\n\\nBased on this analysis, I output: 0\"}, 'done_reason': 'stop', 'done': True, 'total_duration': 4968272051, 'load_duration': 30305995, 'prompt_eval_count': 153, 'prompt_eval_duration': 111311000, 'eval_count': 116, 'eval_duration': 4781468000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:15:57.610402604Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified as it appears to be a phrase in Arabic language which translates to \"Around the world in a week\". \\n\\nThe content verification step is not possible without more context or information about the claim being made. The logical consistency assessment also does not reveal any contradictions or implausible assertions.\\n\\nTherefore, based on the available information, I conclude that the authenticity of the text cannot be determined with certainty. However, since you require an output of either 0 (real) or 1 (fake), I will provide a tentative answer.\\n\\nOutput: 1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 5506884684, 'load_duration': 30515745, 'prompt_eval_count': 146, 'prompt_eval_duration': 110309000, 'eval_count': 129, 'eval_duration': 5320840000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:15:58.688338015Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1074424400, 'load_duration': 31776130, 'prompt_eval_count': 156, 'prompt_eval_duration': 124821000, 'eval_count': 22, 'eval_duration': 872517000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:16:03.992539389Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified with credible information available. The text appears to be in Arabic and translates to \"Continuation of the luck of roaming in Basra.\" \\n\\nThe content seems to be a phrase or a sentence rather than a factual claim, making it difficult to verify its authenticity. Additionally, the statement does not contain any logical contradictions or implausible assertions.\\n\\nBased on this analysis, I conclude that the text is likely fake or, at the very least, lacks sufficient information to be verified as real. Therefore, my output is:\\n\\n1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 5300378695, 'load_duration': 73863884, 'prompt_eval_count': 149, 'prompt_eval_duration': 108723000, 'eval_count': 124, 'eval_duration': 5114681000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:16:07.212986751Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified with credible information available. The text appears to be a question or a phrase in Arabic, which translates to \"Who is Saleh Muslim, whom Turkey wants at any price?\"\\n\\nBased on the analysis, I conclude that the text is FAKE.\\n\\nOutput: 1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3216191673, 'load_duration': 26804924, 'prompt_eval_count': 153, 'prompt_eval_duration': 112047000, 'eval_count': 74, 'eval_duration': 3033879000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:16:10.621660596Z', 'message': {'role': 'assistant', 'content': \"After analyzing the statement, I determined that it is REAL.\\n\\nThe text claims that Kylie Jenner tops the list of Instagram's richest personalities in the world. This claim can be independently verified through various credible sources, including Forbes' lists and other reputable publications.\\n\\nAdditionally, the statement appears to be logically consistent and does not contain contradictions or implausible assertions.\\n\\nTherefore, my output is: 0\"}, 'done_reason': 'stop', 'done': True, 'total_duration': 3404567127, 'load_duration': 73070766, 'prompt_eval_count': 159, 'prompt_eval_duration': 125723000, 'eval_count': 78, 'eval_duration': 3202939000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:16:11.695595789Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1070508923, 'load_duration': 30164146, 'prompt_eval_count': 156, 'prompt_eval_duration': 124250000, 'eval_count': 22, 'eval_duration': 872241000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:16:16.787734652Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified with credible information available. The text appears to be a claim made in Arabic, which translates to \"Al-Assad refuses to use force against the Kurds.\" However, without additional context or evidence, it is difficult to verify the accuracy of this statement.\\n\\nConsidering the logical consistency of the statement, it does not contain any obvious contradictions or implausible assertions. Nevertheless, the lack of verifiable evidence leads me to conclude that the authenticity of the text cannot be confirmed.\\n\\nTherefore, my output is:\\n\\n1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 5089130681, 'load_duration': 28963628, 'prompt_eval_count': 150, 'prompt_eval_duration': 111273000, 'eval_count': 119, 'eval_duration': 4905618000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:16:17.658117475Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 866030385, 'load_duration': 31703471, 'prompt_eval_count': 161, 'prompt_eval_duration': 125838000, 'eval_count': 17, 'eval_duration': 665221000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:16:19.588612581Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"مضاعفة الحد الأدني للأجور في فنزويلا\" is real. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1926943766, 'load_duration': 31230753, 'prompt_eval_count': 153, 'prompt_eval_duration': 111015000, 'eval_count': 43, 'eval_duration': 1742811000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:16:20.789787508Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1198212285, 'load_duration': 32147419, 'prompt_eval_count': 158, 'prompt_eval_duration': 124555000, 'eval_count': 25, 'eval_duration': 998374000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:16:24.306562474Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified with certainty. The text appears to be in Arabic and translates to \"4 Russian forces fell east of Syria.\" However, without additional context or information, it is difficult to verify the claim independently.\\n\\nTherefore, based on the available information, I conclude that the statement is likely fake.\\n\\nOutput: 1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3514015414, 'load_duration': 32456430, 'prompt_eval_count': 153, 'prompt_eval_duration': 111356000, 'eval_count': 81, 'eval_duration': 3323873000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:16:25.17250373Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 861757328, 'load_duration': 28770110, 'prompt_eval_count': 160, 'prompt_eval_duration': 124959000, 'eval_count': 17, 'eval_duration': 664634000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:16:26.180751048Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1005487375, 'load_duration': 36777517, 'prompt_eval_count': 162, 'prompt_eval_duration': 136139000, 'eval_count': 20, 'eval_duration': 789811000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:16:27.377908198Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL. Therefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1194729597, 'load_duration': 31552562, 'prompt_eval_count': 157, 'prompt_eval_duration': 122323000, 'eval_count': 25, 'eval_duration': 996655000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:16:28.382576786Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1001261658, 'load_duration': 30158535, 'prompt_eval_count': 165, 'prompt_eval_duration': 137226000, 'eval_count': 20, 'eval_duration': 790300000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:16:29.498070814Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1112935656, 'load_duration': 29450998, 'prompt_eval_count': 154, 'prompt_eval_duration': 124717000, 'eval_count': 22, 'eval_duration': 872198000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:16:32.90454008Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that the authenticity of the text cannot be verified without additional context or information. The text appears to be in Arabic and translates to \"Egyptian medical sources behind the death of Father Zainoun El-Moqari\". \\n\\nWithout further evidence or credible sources to support this claim, I am unable to verify its authenticity. Therefore, my output is:\\n\\n1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3404277052, 'load_duration': 73734633, 'prompt_eval_count': 159, 'prompt_eval_duration': 125543000, 'eval_count': 78, 'eval_duration': 3202532000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:16:33.909642048Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1002198466, 'load_duration': 31219053, 'prompt_eval_count': 162, 'prompt_eval_duration': 136833000, 'eval_count': 20, 'eval_duration': 789965000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:16:38.893448292Z', 'message': {'role': 'assistant', 'content': \"After analyzing the statement using the provided steps, I determined that the authenticity of the text is:\\n\\n**REAL**\\n\\nOutput: **0**\\n\\nHere's my analysis:\\n\\n1. Content Verification: The claim made in the content can be independently verified with other credible information available. A quick search online reveals that Nestle and Starbucks did indeed sign a deal worth $7 billion.\\n2. Logical Consistency: The statement appears logically consistent, and there are no contradictions or implausible assertions.\\n\\nBased on these steps, I conclude that the text is real, hence the output is 0.\"}, 'done_reason': 'stop', 'done': True, 'total_duration': 4979402647, 'load_duration': 30220045, 'prompt_eval_count': 154, 'prompt_eval_duration': 123779000, 'eval_count': 116, 'eval_duration': 4782710000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:16:45.038909947Z', 'message': {'role': 'assistant', 'content': \"After analyzing the statement using the provided steps, I determined that the authenticity of the text is:\\n\\n**REAL**\\n\\nOutput: **0**\\n\\nHere's my analysis:\\n\\n1. Content Verification: The claim made in the content can be independently verified with other credible information available. A quick search reveals that Egypt has indeed experienced significant economic growth in recent years, with some reports indicating it achieved its highest growth rate in 10 years.\\n2. Logical Consistency: The statement is logically consistent and does not contain contradictions or implausible assertions. The claim is specific, measurable, and aligns with general knowledge about Egypt's economy.\\n\\nBased on these findings, I conclude that the text is real, hence the output is **0**.\"}, 'done_reason': 'stop', 'done': True, 'total_duration': 6142154815, 'load_duration': 35871840, 'prompt_eval_count': 152, 'prompt_eval_duration': 111648000, 'eval_count': 145, 'eval_duration': 5992458000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:16:49.114847194Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nThe text translates to \"Turkey will strike anyone who helps the Kurdish militia in Syria, no matter what.\" This statement appears to be a quote from a Turkish official or a news headline, and its content can be verified through various credible sources. The language used is consistent with the tone and rhetoric often employed by Turkish officials regarding their stance on the Kurdish militia in Syria.\\n\\nTherefore, my output is: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4071874478, 'load_duration': 31722921, 'prompt_eval_count': 161, 'prompt_eval_duration': 125301000, 'eval_count': 94, 'eval_duration': 3870719000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:16:50.12838709Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1010430374, 'load_duration': 80018956, 'prompt_eval_count': 162, 'prompt_eval_duration': 137260000, 'eval_count': 20, 'eval_duration': 789485000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:16:51.201585677Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1068356581, 'load_duration': 31574592, 'prompt_eval_count': 156, 'prompt_eval_duration': 122257000, 'eval_count': 22, 'eval_duration': 872335000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:16:53.008213274Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"الدولار يقفز من أدنى مستوى في 3 سنوات\" is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1802974517, 'load_duration': 29395358, 'prompt_eval_count': 153, 'prompt_eval_duration': 110986000, 'eval_count': 40, 'eval_duration': 1618377000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:16:55.331378636Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified with credible information available. The text appears to be a claim without any evidence or sources to support it.\\n\\nTherefore, my output is:\\n\\n1 (fake)'}, 'done_reason': 'stop', 'done': True, 'total_duration': 2320889479, 'load_duration': 28527211, 'prompt_eval_count': 154, 'prompt_eval_duration': 124509000, 'eval_count': 52, 'eval_duration': 2121404000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:16:56.203367727Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 869555618, 'load_duration': 76232427, 'prompt_eval_count': 160, 'prompt_eval_duration': 125616000, 'eval_count': 17, 'eval_duration': 665166000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:16:59.430311692Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text \"هروب ابن أبو بكر البغدادي\" cannot be verified with credible information available. The name appears to be in Arabic, but without more context or information, it is difficult to verify its accuracy.\\n\\nTherefore, based on the analysis, my output is:\\n\\n1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3224684951, 'load_duration': 72390137, 'prompt_eval_count': 148, 'prompt_eval_duration': 111238000, 'eval_count': 73, 'eval_duration': 2996316000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:17:03.120125983Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified without additional context or information. The text appears to be in Arabic and translates to \"Barclays faces a new judicial battle due to Qatar.\" \\n\\nWithout further information about Barclays\\' current legal situations or its connections to Qatar, it is difficult to verify the claim made in the content. Therefore, I will output:\\n\\n1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3685791003, 'load_duration': 31825921, 'prompt_eval_count': 153, 'prompt_eval_duration': 112672000, 'eval_count': 85, 'eval_duration': 3496102000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:17:07.14789777Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nThe text states \"مسؤول إماراتي بارز العلاقات العربية التركية ليست في أحسن حالاتها\" which translates to \"A prominent Emirati official says Arab-Turkish relations are not at their best\". This statement can be independently verified with other credible information available, and it does not contain any contradictions or implausible assertions.\\n\\nTherefore, the output is: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4023267700, 'load_duration': 32831018, 'prompt_eval_count': 159, 'prompt_eval_duration': 125655000, 'eval_count': 93, 'eval_duration': 3815355000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:17:12.290114782Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified without additional context. The text appears to be in Arabic and translates to \"The dollar rate is the best for three years.\" \\n\\nHowever, without knowing the specific context or timeframe referred to in the statement, it\\'s challenging to verify its claims independently. Additionally, the statement seems to lack logical consistency, as it doesn\\'t provide a clear basis for why the dollar rate is considered the best.\\n\\nGiven these points, I conclude that the text is likely fake. Therefore, my output is:\\n\\n1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 5138378983, 'load_duration': 33303997, 'prompt_eval_count': 151, 'prompt_eval_duration': 112348000, 'eval_count': 119, 'eval_duration': 4900636000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:17:13.158767053Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 865007661, 'load_duration': 72364837, 'prompt_eval_count': 159, 'prompt_eval_duration': 125365000, 'eval_count': 17, 'eval_duration': 664506000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:17:14.162462147Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 999884335, 'load_duration': 28685790, 'prompt_eval_count': 163, 'prompt_eval_duration': 136580000, 'eval_count': 20, 'eval_duration': 790854000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:17:16.387921385Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified with credible information available. The claim made in the content appears to be a sensational and unverifiable statement.\\n\\nTherefore, my output is:\\n\\n1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 2221582399, 'load_duration': 71767339, 'prompt_eval_count': 151, 'prompt_eval_duration': 111539000, 'eval_count': 50, 'eval_duration': 2035651000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:17:20.400721837Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text \"تحذيرات من الصين بشأن الحرب العالمية الثالثة\" (which translates to \"Warnings from China about World War III\") cannot be verified.\\n\\nThere is no credible information available to independently verify the claims made in the content. Additionally, the statement lacks logical consistency and contains implausible assertions.\\n\\nTherefore, I conclude that the text is fake.\\n\\nOutput: 1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4008985743, 'load_duration': 31640902, 'prompt_eval_count': 151, 'prompt_eval_duration': 111336000, 'eval_count': 93, 'eval_duration': 3822511000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:17:21.270945525Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 867765265, 'load_duration': 31273743, 'prompt_eval_count': 160, 'prompt_eval_duration': 125522000, 'eval_count': 17, 'eval_duration': 666628000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:17:22.342743488Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1068740742, 'load_duration': 28494330, 'prompt_eval_count': 154, 'prompt_eval_duration': 123797000, 'eval_count': 22, 'eval_duration': 871667000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:17:23.419974808Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1073693329, 'load_duration': 31894301, 'prompt_eval_count': 156, 'prompt_eval_duration': 124622000, 'eval_count': 22, 'eval_duration': 872231000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:17:24.538071803Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1114294756, 'load_duration': 31398702, 'prompt_eval_count': 155, 'prompt_eval_duration': 124380000, 'eval_count': 22, 'eval_duration': 872009000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:17:29.554040853Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"غناوة المغرب موسيقى صوفية جذورها أفريقية\" is REAL.\\n\\nHere\\'s my analysis:\\n\\n1. Content Verification: The claim made in the content can be independently verified with other credible information available. Gnawa music is a traditional Moroccan music style that originated from African roots, and it is indeed known for its Sufi influences.\\n2. Logical Consistency: The statement is logically consistent and does not contain contradictions or implausible assertions.\\n\\nTherefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 5013843617, 'load_duration': 65856456, 'prompt_eval_count': 155, 'prompt_eval_duration': 123091000, 'eval_count': 117, 'eval_duration': 4820617000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:17:33.943764565Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified without additional context or information. The text \"انخفاض إيرادات قناة السويس في مارس\" translates to \"A decrease in Suez Canal revenues in March\", which is a plausible and logically consistent statement.\\n\\nHowever, without access to credible information about the Suez Canal\\'s revenue data for March, I cannot independently verify the claim made in the content. Therefore, I will output:\\n\\n1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4386556031, 'load_duration': 34776763, 'prompt_eval_count': 151, 'prompt_eval_duration': 111611000, 'eval_count': 102, 'eval_duration': 4197068000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:17:37.330021952Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"بيبسي تشتري سلسلة كوستاكافيه\" is real. The translation of this Arabic text to English is \"Pepsi buys Costa Coffee\". This claim can be independently verified with credible information available online, as PepsiCo did acquire Costa Coffee in 2019.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3383814304, 'load_duration': 24684691, 'prompt_eval_count': 151, 'prompt_eval_duration': 111641000, 'eval_count': 78, 'eval_duration': 3199194000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:17:41.996633452Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"تيلرسون حزب الله جزء من العملية السياسية في لبنان\" is REAL.\\n\\nHere\\'s my analysis:\\n\\n1. Content Verification: The claim made in the content can be independently verified with other credible information available. Hassan Nasrallah (Hezbollah\\'s leader) has indeed been a part of Lebanon\\'s political process.\\n2. Logical Consistency: The statement is logically consistent and does not contain contradictions or implausible assertions.\\n\\nTherefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4663781628, 'load_duration': 30396775, 'prompt_eval_count': 152, 'prompt_eval_duration': 111564000, 'eval_count': 109, 'eval_duration': 4478114000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:17:43.019066216Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1017102808, 'load_duration': 30209955, 'prompt_eval_count': 174, 'prompt_eval_duration': 147900000, 'eval_count': 20, 'eval_duration': 792244000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:17:47.092510625Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified without more context or information. The text appears to be a title or headline in Arabic, which translates to \"Facts about mobile companies raising prices for spare parts.\"\\n\\nSince there is no specific claim or assertion made in the text, it\\'s challenging to verify its content using credible sources or assess its logical consistency.\\n\\nTherefore, I will output: 1 (fake)'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4069790980, 'load_duration': 34851143, 'prompt_eval_count': 154, 'prompt_eval_duration': 123904000, 'eval_count': 94, 'eval_duration': 3864844000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:17:48.293115281Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL. Therefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1196802466, 'load_duration': 73802353, 'prompt_eval_count': 157, 'prompt_eval_duration': 123163000, 'eval_count': 25, 'eval_duration': 997115000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:17:51.983706351Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified without additional context or information. The text appears to be a news headline in Arabic, but without further investigation, it is difficult to determine its accuracy.\\n\\nHowever, since I must provide an output of either 0 (real) or 1 (fake), I will err on the side of caution and output:\\n\\n1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3688129767, 'load_duration': 70487353, 'prompt_eval_count': 155, 'prompt_eval_duration': 124449000, 'eval_count': 84, 'eval_duration': 3448348000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:17:56.758105414Z', 'message': {'role': 'assistant', 'content': \"After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nHere's my analysis:\\n\\n1. Content Verification: The claim made in the content can be independently verified with other credible information available. A quick search online reveals that Bitcoin's value has indeed fluctuated and reached new highs within a 6-week period on several occasions.\\n2. Logical Consistency: The statement appears logically consistent, and there are no obvious contradictions or implausible assertions.\\n\\nBased on this analysis, I conclude that the text is REAL.\\n\\nOutput: 0\"}, 'done_reason': 'stop', 'done': True, 'total_duration': 4770130595, 'load_duration': 31766251, 'prompt_eval_count': 156, 'prompt_eval_duration': 124304000, 'eval_count': 111, 'eval_duration': 4570833000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:17:57.625738271Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 864158776, 'load_duration': 28549850, 'prompt_eval_count': 160, 'prompt_eval_duration': 125807000, 'eval_count': 17, 'eval_duration': 665030000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:17:58.635190411Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1006162809, 'load_duration': 35764070, 'prompt_eval_count': 168, 'prompt_eval_duration': 137557000, 'eval_count': 20, 'eval_duration': 791031000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:18:01.312673793Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified with credible information available. The claim made in the content appears to be a personal or private matter and lacks concrete evidence to support its validity.\\n\\nTherefore, based on the analysis, my output is:\\n\\n1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 2673482433, 'load_duration': 25095630, 'prompt_eval_count': 151, 'prompt_eval_duration': 111816000, 'eval_count': 61, 'eval_duration': 2493518000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:18:07.68006714Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is FAKE.\\n\\nThe text appears to be in Arabic, and when translated, it reads: \"Turkey is sinking and Erdogan\\'s bad plans to prevent economic collapse.\"\\n\\nUpon conducting content verification, I found no credible sources supporting the claim that Turkey is currently \"sinking\" or experiencing an economic collapse. While Turkey has faced economic challenges in the past, there is no recent evidence to suggest a catastrophic economic situation.\\n\\nAdditionally, assessing the logical consistency of the statement reveals that it contains implausible assertions. The phrase \"Erdogan\\'s bad plans\" is subjective and lacks concrete evidence to support its validity.\\n\\nTherefore, based on these steps, I conclude that the statement is fake.\\n\\nOutput: 1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 6363294078, 'load_duration': 38101643, 'prompt_eval_count': 160, 'prompt_eval_duration': 125247000, 'eval_count': 149, 'eval_duration': 6156070000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:18:09.405433152Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"أزمة كندا مع السعودية تزداد بسبب حقوق الإنسان\" is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1722300530, 'load_duration': 31485482, 'prompt_eval_count': 152, 'prompt_eval_duration': 111415000, 'eval_count': 38, 'eval_duration': 1535388000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:18:15.472465912Z', 'message': {'role': 'assistant', 'content': \"After analyzing the statement using the provided steps, I determined that the authenticity of the text is:\\n\\n**REAL**\\n\\nOutput: **0**\\n\\nHere's my analysis:\\n\\n1. Content Verification: The claim made in the content can be independently verified with other credible information available. Ethiopia has indeed been a topic of discussion regarding its share of Nile water, and there have been agreements and disputes between Egypt and Ethiopia on this matter.\\n2. Logical Consistency: The statement is logically consistent and does not contain contradictions or implausible assertions. It's a clear and concise statement about Ethiopia's stance on the Nile water issue.\\n\\nBased on these points, I conclude that the text is real, hence the output is 0.\"}, 'done_reason': 'stop', 'done': True, 'total_duration': 6060411888, 'load_duration': 38789162, 'prompt_eval_count': 153, 'prompt_eval_duration': 111824000, 'eval_count': 142, 'eval_duration': 5865389000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:18:19.194797968Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text \"أزمة إيطاليا تسند الذهب\" cannot be verified. The text appears to be in Arabic and translates to \"Italy\\'s gold crisis.\" However, without more context or information, it is difficult to verify the claim made in the content.\\n\\nTherefore, based on the analysis, I conclude that the output should be:\\n\\n1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3718894796, 'load_duration': 74215072, 'prompt_eval_count': 148, 'prompt_eval_duration': 108825000, 'eval_count': 86, 'eval_duration': 3530618000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:18:20.393716951Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1195701682, 'load_duration': 30751865, 'prompt_eval_count': 158, 'prompt_eval_duration': 124800000, 'eval_count': 25, 'eval_duration': 998075000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:18:26.780627221Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"استقرار الذهب مع استمرار ضعف الدولار\" is REAL.\\n\\nHere\\'s my analysis:\\n\\n1. Content Verification: The claim made in the content can be independently verified with other credible information available. The value of gold (الذهب) has historically been inversely related to the strength of the US dollar (الدولار). When the dollar weakens, the price of gold tends to rise.\\n2. Logical Consistency: The statement is logically consistent and does not contain contradictions or implausible assertions. It makes sense that if the dollar continues to weaken, the value of gold would stabilize or increase.\\n\\nBased on this analysis, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 6383973198, 'load_duration': 73336685, 'prompt_eval_count': 150, 'prompt_eval_duration': 111212000, 'eval_count': 150, 'eval_duration': 6196151000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:18:27.980659571Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1197420337, 'load_duration': 31586752, 'prompt_eval_count': 157, 'prompt_eval_duration': 124392000, 'eval_count': 25, 'eval_duration': 997451000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:18:29.175540606Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1192561911, 'load_duration': 71041452, 'prompt_eval_count': 157, 'prompt_eval_duration': 122373000, 'eval_count': 25, 'eval_duration': 996697000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:18:30.422075466Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1242591101, 'load_duration': 35401191, 'prompt_eval_count': 158, 'prompt_eval_duration': 124781000, 'eval_count': 25, 'eval_duration': 997816000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:18:35.14291048Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"منع التعامل بالعملات المعدنية في الهند\" is REAL.\\n\\nHere\\'s my analysis:\\n\\n1. Content Verification: The claim made in the content can be independently verified with other credible information available. India did indeed ban the use of metallic currencies in 2016, specifically the ₹500 and ₹1000 notes.\\n2. Logical Consistency: The statement is logically consistent and does not contain contradictions or implausible assertions.\\n\\nTherefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4718469180, 'load_duration': 73701564, 'prompt_eval_count': 150, 'prompt_eval_duration': 111218000, 'eval_count': 110, 'eval_duration': 4530746000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:18:36.153771578Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1008187226, 'load_duration': 37263476, 'prompt_eval_count': 165, 'prompt_eval_duration': 136976000, 'eval_count': 20, 'eval_duration': 789662000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:18:37.230967772Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1073405904, 'load_duration': 32852398, 'prompt_eval_count': 156, 'prompt_eval_duration': 124079000, 'eval_count': 22, 'eval_duration': 871981000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:18:38.436662967Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1203220392, 'load_duration': 31552082, 'prompt_eval_count': 157, 'prompt_eval_duration': 124275000, 'eval_count': 25, 'eval_duration': 997450000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:18:39.515379346Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1075400388, 'load_duration': 35383961, 'prompt_eval_count': 155, 'prompt_eval_duration': 124632000, 'eval_count': 22, 'eval_duration': 871642000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:18:42.372297643Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nThe text translates to \"Bill Cosby\\'s American actor was sentenced to sexual assault after being convicted.\" This statement can be independently verified with credible information available online. Bill Cosby was indeed convicted of sexual assault and sentenced to prison in 2018.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 2852900278, 'load_duration': 30080716, 'prompt_eval_count': 160, 'prompt_eval_duration': 124672000, 'eval_count': 65, 'eval_duration': 2652734000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:18:43.449987296Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1074402572, 'load_duration': 74486022, 'prompt_eval_count': 155, 'prompt_eval_duration': 124261000, 'eval_count': 22, 'eval_duration': 872382000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:18:49.628197866Z', 'message': {'role': 'assistant', 'content': \"After analyzing the statement using the provided steps, I determined that the authenticity of the text is:\\n\\n**REAL**\\n\\nOutput: **0**\\n\\nHere's my analysis:\\n\\n1. Content Verification: The claim made in the content can be independently verified with other credible information available. A quick search reveals that Egypt has indeed experienced significant economic growth in recent years, with some reports indicating it achieved its highest growth rate in 5 years.\\n2. Logical Consistency: The statement is logically consistent and does not contain contradictions or implausible assertions. The claim is specific, measurable, and aligns with general knowledge about Egypt's economy.\\n\\nBased on these steps, I conclude that the text is real, hence the output is **0**.\"}, 'done_reason': 'stop', 'done': True, 'total_duration': 6175918326, 'load_duration': 30987823, 'prompt_eval_count': 152, 'prompt_eval_duration': 109926000, 'eval_count': 145, 'eval_duration': 5991257000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:18:52.809830599Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"مارس ارتفاع إيرادات قناة السويس\" translates to \"March increase in Suez Canal revenues\". \\n\\nThis statement can be independently verified with credible information available, and it appears to be logically consistent. Therefore, I conclude that the statement is real.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3177705834, 'load_duration': 73994784, 'prompt_eval_count': 148, 'prompt_eval_duration': 112124000, 'eval_count': 73, 'eval_duration': 2988940000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:18:57.054322857Z', 'message': {'role': 'assistant', 'content': \"After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nHere's my analysis:\\n\\n1. Content Verification: The claim made in the content can be independently verified with other credible information available. In Saudi Arabia, there have been instances where individuals were punished with imprisonment for online activities deemed offensive or disrespectful.\\n2. Logical Consistency: The statement is logically consistent and does not contain contradictions or implausible assertions.\\n\\nTherefore, my output is:\\n\\n0\"}, 'done_reason': 'stop', 'done': True, 'total_duration': 4058898036, 'load_duration': 37215026, 'prompt_eval_count': 153, 'prompt_eval_duration': 112304000, 'eval_count': 94, 'eval_duration': 3867367000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:19:00.608322462Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified without additional context or information. The text appears to be in Arabic and translates to \"A decrease in school dropout rates.\" \\n\\nWithout further evidence or credible sources to support this claim, it is difficult to determine its authenticity. Therefore, based on the available information, I conclude that the output should be:\\n\\n1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3551051583, 'load_duration': 32225139, 'prompt_eval_count': 148, 'prompt_eval_duration': 110339000, 'eval_count': 82, 'eval_duration': 3363151000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:19:01.612855499Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 999861471, 'load_duration': 30115886, 'prompt_eval_count': 164, 'prompt_eval_duration': 135600000, 'eval_count': 20, 'eval_duration': 790279000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:19:02.526074032Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 909401993, 'load_duration': 73405975, 'prompt_eval_count': 160, 'prompt_eval_duration': 125405000, 'eval_count': 17, 'eval_duration': 664635000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:19:03.682094477Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1153801962, 'load_duration': 69810306, 'prompt_eval_count': 155, 'prompt_eval_duration': 124349000, 'eval_count': 22, 'eval_duration': 871276000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:19:07.644380544Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text \"5 أشياء جديدة عن كرواتيا\" cannot be verified as it appears to be a title or a headline in Arabic, which translates to \"5 new things about Croatia\". \\n\\nThe content does not make any claims that can be independently verified, and there are no logical inconsistencies or contradictions. Therefore, I conclude that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3959460285, 'load_duration': 30731594, 'prompt_eval_count': 149, 'prompt_eval_duration': 108871000, 'eval_count': 93, 'eval_duration': 3817968000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:19:08.844601316Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1196299053, 'load_duration': 30694235, 'prompt_eval_count': 157, 'prompt_eval_duration': 124425000, 'eval_count': 25, 'eval_duration': 997182000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:19:12.408910025Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"النفط يصعد بفعل توترات الشرق الأوسط\" is real. The translation of this Arabic sentence to English is \"Oil prices rise due to Middle East tensions.\" This statement can be independently verified with credible information available, and it does not contain contradictions or implausible assertions.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3560136610, 'load_duration': 32262830, 'prompt_eval_count': 154, 'prompt_eval_duration': 124204000, 'eval_count': 82, 'eval_duration': 3361625000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:19:13.411822848Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 999508323, 'load_duration': 25335879, 'prompt_eval_count': 167, 'prompt_eval_duration': 138304000, 'eval_count': 20, 'eval_duration': 790367000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:19:19.38459779Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified with certainty. The text appears to be a headline or title in Arabic, which translates to \"The American threat to Iran causes a catastrophe.\"\\n\\nContent Verification: Without more context or information about the specific event or situation being referred to, it is difficult to independently verify the claim.\\n\\nLogical Consistency: The statement does not contain any obvious contradictions or implausible assertions. However, without additional context, it is challenging to assess its logical consistency.\\n\\nGiven the limitations in verifying the authenticity of the text, I will output a value of 1, indicating that the text may be fake or unverifiable.'}, 'done_reason': 'stop', 'done': True, 'total_duration': 5970423089, 'load_duration': 71855790, 'prompt_eval_count': 151, 'prompt_eval_duration': 111489000, 'eval_count': 140, 'eval_duration': 5784919000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:19:20.588209594Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1200245373, 'load_duration': 30321045, 'prompt_eval_count': 157, 'prompt_eval_duration': 124729000, 'eval_count': 25, 'eval_duration': 996788000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:19:21.784528957Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL. Therefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1193707401, 'load_duration': 29842387, 'prompt_eval_count': 158, 'prompt_eval_duration': 125038000, 'eval_count': 25, 'eval_duration': 996666000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:19:22.98829194Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1201167050, 'load_duration': 74995751, 'prompt_eval_count': 157, 'prompt_eval_duration': 124676000, 'eval_count': 25, 'eval_duration': 998242000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:19:24.089987129Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1099483145, 'load_duration': 71469321, 'prompt_eval_count': 152, 'prompt_eval_duration': 111513000, 'eval_count': 22, 'eval_duration': 871493000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:19:27.527996622Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nThe text translates to \"Syria grants amnesty to draft dodgers and deserters from military service.\" This claim can be independently verified with credible information available. In 2019, Syria\\'s government indeed granted a general amnesty to all individuals who had evaded military service or deserted the army.\\n\\nTherefore, my output is: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3433891515, 'load_duration': 32055220, 'prompt_eval_count': 161, 'prompt_eval_duration': 124879000, 'eval_count': 79, 'eval_duration': 3232044000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:19:30.594432901Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified without additional context or information. The text appears to be a personal anecdote or testimony, and without further evidence or credible sources to support its claims, it is difficult to determine its authenticity.\\n\\nTherefore, my output is: 1 (fake)'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3062839740, 'load_duration': 29112529, 'prompt_eval_count': 154, 'prompt_eval_duration': 123973000, 'eval_count': 70, 'eval_duration': 2867567000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:19:31.667057101Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1068741820, 'load_duration': 29615237, 'prompt_eval_count': 155, 'prompt_eval_duration': 124312000, 'eval_count': 22, 'eval_duration': 871947000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:19:32.536894416Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 867450682, 'load_duration': 32074520, 'prompt_eval_count': 159, 'prompt_eval_duration': 124908000, 'eval_count': 17, 'eval_duration': 664393000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:19:39.130200634Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"استقرار معدلات النمو وارتفاع في أسعار النفط\" is a real statement.\\n\\nHere\\'s my analysis:\\n\\n1. Content Verification: The claim made in the content can be independently verified with other credible information available. The phrase \"استقرار معدلات النمو\" translates to \"stability of growth rates,\" and \"ارتفاع في أسعار النفط\" translates to \"increase in oil prices.\" These claims are plausible and can be verified through economic data and news articles.\\n2. Logical Consistency: The statement is logically consistent, and there are no contradictions or implausible assertions.\\n\\nBased on this analysis, I conclude that the text is real.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 6590856535, 'load_duration': 31453122, 'prompt_eval_count': 153, 'prompt_eval_duration': 111711000, 'eval_count': 155, 'eval_duration': 6403585000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:19:40.002530162Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 868979707, 'load_duration': 31895321, 'prompt_eval_count': 161, 'prompt_eval_duration': 125749000, 'eval_count': 17, 'eval_duration': 664978000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:19:43.965986833Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified without additional context or information. The text appears to be in Arabic and translates to \"Al-Sadr calls for re-elections again.\" \\n\\nWithout further information about who Al-Sadr is, what elections are being referred to, and when this statement was made, it\\'s challenging to verify its authenticity.\\n\\nTherefore, I will output: 1 (fake)'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3961333767, 'load_duration': 69392826, 'prompt_eval_count': 150, 'prompt_eval_duration': 109043000, 'eval_count': 92, 'eval_duration': 3780601000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:19:45.166644596Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1196429195, 'load_duration': 30253676, 'prompt_eval_count': 158, 'prompt_eval_duration': 126052000, 'eval_count': 25, 'eval_duration': 997945000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:19:46.36708223Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1198168160, 'load_duration': 73147266, 'prompt_eval_count': 158, 'prompt_eval_duration': 125319000, 'eval_count': 25, 'eval_duration': 997167000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:19:47.444615326Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1073513817, 'load_duration': 31725911, 'prompt_eval_count': 155, 'prompt_eval_duration': 124646000, 'eval_count': 22, 'eval_duration': 872517000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:19:48.452000692Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1003754618, 'load_duration': 73945461, 'prompt_eval_count': 165, 'prompt_eval_duration': 137318000, 'eval_count': 20, 'eval_duration': 789872000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:19:52.974410761Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"الحرب التجارية تنذر بكارثة للاقتصاد العالمي\" is REAL.\\n\\nThe translation of the text is \"Trade war threatens a catastrophe for the global economy.\" This statement can be independently verified with other credible information available, as trade wars have been known to have negative impacts on the global economy. The statement is also logically consistent and does not contain contradictions or implausible assertions.\\n\\nTherefore, my output is: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4519087010, 'load_duration': 78654986, 'prompt_eval_count': 153, 'prompt_eval_duration': 112055000, 'eval_count': 104, 'eval_duration': 4283438000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:19:56.62624054Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified without additional context or information. The text appears to be a news headline in Arabic, but without further research or evidence, it is difficult to confirm its accuracy.\\n\\nHowever, based on my analysis, I will provide an output of 1, indicating that the text may be fake or unverifiable without additional information.'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3647919432, 'load_duration': 31067949, 'prompt_eval_count': 154, 'prompt_eval_duration': 123806000, 'eval_count': 84, 'eval_duration': 3446906000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:20:03.577434149Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nThe text appears to be an Arabic sentence that translates to \"Celebration of the Giza Pyramids on the occasion of the 300th anniversary of Ober Ayda\". \\n\\nUpon content verification, I found that there is no notable figure or event by the name of \"Ober Ayda\" associated with the Giza Pyramids. Additionally, a quick search did not yield any credible information about a 300-year anniversary celebration related to the pyramids.\\n\\nHowever, considering logical consistency, the statement does not contain contradictions or implausible assertions. The sentence structure and language used are coherent and grammatically correct.\\n\\nGiven these points, I conclude that the text is likely fabricated for some purpose, possibly as an exercise or a fictional event.\\n\\nOutput: 1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 6947350081, 'load_duration': 31986256, 'prompt_eval_count': 160, 'prompt_eval_duration': 124545000, 'eval_count': 163, 'eval_duration': 6741935000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:20:04.581798048Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1001001950, 'load_duration': 29330405, 'prompt_eval_count': 165, 'prompt_eval_duration': 137029000, 'eval_count': 20, 'eval_duration': 790023000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:20:08.564520224Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"خفض الحد الأدنى للأجور في فنزويلا\" is REAL.\\n\\nThe translation of the text is \"Minimum wage decreased in Venezuela\". This claim can be independently verified with credible information available online. According to various news sources, Venezuela has indeed experienced a decrease in minimum wage due to economic crisis and hyperinflation.\\n\\nTherefore, my output is: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3980544973, 'load_duration': 31221759, 'prompt_eval_count': 154, 'prompt_eval_duration': 123644000, 'eval_count': 92, 'eval_duration': 3782139000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:20:10.387441591Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"تحالف الصدر يفوز بالانتخابات البرلمانية في العراق\" is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1820755634, 'load_duration': 75353078, 'prompt_eval_count': 154, 'prompt_eval_duration': 124387000, 'eval_count': 40, 'eval_duration': 1618147000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:20:11.632866889Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1243064306, 'load_duration': 72364827, 'prompt_eval_count': 157, 'prompt_eval_duration': 126767000, 'eval_count': 25, 'eval_duration': 999352000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:20:12.501025303Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 865228264, 'load_duration': 30358963, 'prompt_eval_count': 159, 'prompt_eval_duration': 125156000, 'eval_count': 17, 'eval_duration': 664944000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:20:14.453861457Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified. The claim made in the content is not supported by credible information available.\\n\\nOutput: 1 (fake)'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1947272002, 'load_duration': 71484000, 'prompt_eval_count': 156, 'prompt_eval_duration': 125004000, 'eval_count': 43, 'eval_duration': 1748421000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:20:15.328083503Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 870793798, 'load_duration': 32488166, 'prompt_eval_count': 161, 'prompt_eval_duration': 126215000, 'eval_count': 17, 'eval_duration': 666203000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:20:18.217307599Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified with credible information available. The claim \"عاد إلى الوطن بعد 130 عاما\" translates to \"He returned to his homeland after 130 years,\" which is an implausible assertion.\\n\\nTherefore, my output is: 1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 2887099043, 'load_duration': 32925844, 'prompt_eval_count': 147, 'prompt_eval_duration': 110940000, 'eval_count': 66, 'eval_duration': 2699520000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:20:19.334053339Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1113490940, 'load_duration': 30005713, 'prompt_eval_count': 155, 'prompt_eval_duration': 124006000, 'eval_count': 22, 'eval_duration': 874542000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:20:20.410647299Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1073081741, 'load_duration': 72419997, 'prompt_eval_count': 154, 'prompt_eval_duration': 126346000, 'eval_count': 22, 'eval_duration': 872163000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:20:21.610977412Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL. Therefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1196258086, 'load_duration': 27934150, 'prompt_eval_count': 158, 'prompt_eval_duration': 125243000, 'eval_count': 25, 'eval_duration': 998619000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:20:22.687908812Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1073053083, 'load_duration': 30064683, 'prompt_eval_count': 155, 'prompt_eval_duration': 124347000, 'eval_count': 22, 'eval_duration': 872205000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:20:23.696591002Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1006338947, 'load_duration': 75778016, 'prompt_eval_count': 167, 'prompt_eval_duration': 138095000, 'eval_count': 20, 'eval_duration': 789850000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:20:24.696420252Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 997102848, 'load_duration': 29494325, 'prompt_eval_count': 162, 'prompt_eval_duration': 134495000, 'eval_count': 20, 'eval_duration': 790856000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:20:27.968332862Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nThe text translates to \"A 6-Richter earthquake strikes the Iranian-Iraqi border.\" This claim can be independently verified with credible information available from seismic monitoring agencies and news outlets. The statement is also logically consistent and does not contain contradictions or implausible assertions.\\n\\nTherefore, my output is: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3269580647, 'load_duration': 75272408, 'prompt_eval_count': 161, 'prompt_eval_duration': 125680000, 'eval_count': 75, 'eval_duration': 3065557000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:20:32.856910299Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"أعلنت اليمن عن تحركها إلى سوريا\" is fake.\\n\\nHere\\'s my reasoning:\\n\\n* Content Verification: There is no credible information available to support the claim that Yemen has announced its transition to Syria. In fact, Yemen and Syria are two separate and independent countries with their own governments and territories.\\n* Logical Consistency: The statement contains an implausible assertion, as it is not possible for one country to \"transition\" into another country.\\n\\nTherefore, my output is:\\n\\n1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4884794219, 'load_duration': 30140613, 'prompt_eval_count': 149, 'prompt_eval_duration': 111865000, 'eval_count': 114, 'eval_duration': 4698105000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:20:33.861017442Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1000133466, 'load_duration': 29290806, 'prompt_eval_count': 167, 'prompt_eval_duration': 136838000, 'eval_count': 20, 'eval_duration': 789337000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:20:37.502069793Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified without additional context or information. The text appears to be in Arabic and translates to \"Economic experts support Trump\\'s orientations.\" \\n\\nWithout further evidence or credible sources to verify this claim, it is difficult to determine its authenticity. Therefore, based on the available information, I conclude that the output should be:\\n\\n1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3638696969, 'load_duration': 30996791, 'prompt_eval_count': 151, 'prompt_eval_duration': 110957000, 'eval_count': 83, 'eval_duration': 3408650000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:20:39.025988366Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified with credible information available. Therefore, my output is:\\n\\n1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1520285165, 'load_duration': 76421345, 'prompt_eval_count': 151, 'prompt_eval_duration': 112532000, 'eval_count': 33, 'eval_duration': 1328438000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:20:40.099353452Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1069942088, 'load_duration': 30465963, 'prompt_eval_count': 154, 'prompt_eval_duration': 124394000, 'eval_count': 22, 'eval_duration': 872016000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:20:41.102069745Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 999815062, 'load_duration': 30123553, 'prompt_eval_count': 163, 'prompt_eval_duration': 136698000, 'eval_count': 20, 'eval_duration': 790291000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:20:45.870498723Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"استقرار الاقتصادي العالمي جراء التوافق الاقتصادي\" translates to \"Global economic stability due to economic harmony\".\\n\\nContent Verification: The claim made in the content is plausible and can be independently verified with other credible information available. Economic harmony and cooperation among nations can lead to global economic stability.\\n\\nLogical Consistency: The statement is logically consistent and does not contain contradictions or implausible assertions.\\n\\nBased on these points, I conclude that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4764539291, 'load_duration': 76058187, 'prompt_eval_count': 150, 'prompt_eval_duration': 111730000, 'eval_count': 111, 'eval_duration': 4573726000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:20:49.182970846Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified without additional context or information. The text appears to be in Arabic and translates to \"4 survivors from the Russian forces from being killed.\" However, without further evidence or credible sources to support this claim, it is difficult to determine its authenticity.\\n\\nOutput: 1 (fake)'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3309245953, 'load_duration': 31506489, 'prompt_eval_count': 151, 'prompt_eval_duration': 111631000, 'eval_count': 76, 'eval_duration': 3120316000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:20:50.386400915Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL. Therefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1200246209, 'load_duration': 30923911, 'prompt_eval_count': 158, 'prompt_eval_duration': 125804000, 'eval_count': 25, 'eval_duration': 1001685000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:20:53.770295961Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"أغسطس الأعلى في صادرات النفط العراقي\" is real. The translation of this Arabic text to English is \"August is the highest in Iraqi oil exports\". This claim can be independently verified with credible information available from reliable sources such as OPEC or Iraqi government reports.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3381182725, 'load_duration': 29952895, 'prompt_eval_count': 149, 'prompt_eval_duration': 108845000, 'eval_count': 78, 'eval_duration': 3198527000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:20:58.401903519Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"إيطاليا تهوي بالذهب\" is fake.\\n\\nHere\\'s my reasoning:\\n\\n* Content Verification: The claim made in the content cannot be independently verified with other credible information available. Italy is not known to be overflowing with gold.\\n* Logical Consistency: The statement contains an implausible assertion, as it is highly unlikely that a country like Italy would be overflowing with gold without any evidence or records of such a phenomenon.\\n\\nTherefore, my output is:\\n\\n1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4628484468, 'load_duration': 68635521, 'prompt_eval_count': 146, 'prompt_eval_duration': 110430000, 'eval_count': 108, 'eval_duration': 4446342000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:21:03.295062862Z', 'message': {'role': 'assistant', 'content': \"After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nHere's my analysis:\\n\\n1. Content Verification: The claim made in the content can be independently verified with other credible information available. The value of gold is often inversely related to the strength of the US dollar, meaning that when the dollar rises, the value of gold tends to fall.\\n2. Logical Consistency: The statement is logically consistent and does not contain contradictions or implausible assertions.\\n\\nBased on this analysis, I conclude that the text is REAL.\\n\\nOutput: 0\"}, 'done_reason': 'stop', 'done': True, 'total_duration': 4890040932, 'load_duration': 32111767, 'prompt_eval_count': 152, 'prompt_eval_duration': 111778000, 'eval_count': 114, 'eval_duration': 4694871000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:21:04.367784279Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1068968649, 'load_duration': 28894918, 'prompt_eval_count': 156, 'prompt_eval_duration': 123845000, 'eval_count': 22, 'eval_duration': 873220000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:21:05.692376746Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text is:\\n\\n**REAL**\\n\\nOutput: **0**'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1320717399, 'load_duration': 29806735, 'prompt_eval_count': 154, 'prompt_eval_duration': 123394000, 'eval_count': 28, 'eval_duration': 1121101000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:21:06.606070621Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 910323226, 'load_duration': 34049672, 'prompt_eval_count': 159, 'prompt_eval_duration': 124541000, 'eval_count': 17, 'eval_duration': 664688000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:21:07.511374882Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is FAKE.\\n\\nOutput: 1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 902825890, 'load_duration': 69424050, 'prompt_eval_count': 159, 'prompt_eval_duration': 125095000, 'eval_count': 18, 'eval_duration': 706043000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:21:12.399321033Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text is:\\n\\nOutput: 1 (Fake)\\n\\nReasoning:\\n\\n* Content Verification: The claim made in the content cannot be independently verified with other credible information available. There is no evidence to suggest that Erdogan named a square after the Lira crisis.\\n* Logical Consistency: The statement contains an implausible assertion, as it is unlikely that a prominent figure like Erdogan would name a square after a currency crisis.\\n\\nBased on these points, I conclude that the text is likely fake.'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4885700158, 'load_duration': 72405790, 'prompt_eval_count': 153, 'prompt_eval_duration': 111251000, 'eval_count': 113, 'eval_duration': 4657230000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:21:16.302691593Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nThe text \"قانون 10 يعطي الأمل لللاجئين السوريين بالعودة إلى سوريا\" translates to \"Law 10 gives hope to Syrian refugees to return to Syria\". This statement can be independently verified with credible information available about Law 10 in Syria, which aims to facilitate the return of Syrian refugees.\\n\\nTherefore, my output is: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3900685289, 'load_duration': 31658300, 'prompt_eval_count': 159, 'prompt_eval_duration': 125160000, 'eval_count': 90, 'eval_duration': 3698702000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:21:17.305866751Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1000819295, 'load_duration': 29222497, 'prompt_eval_count': 167, 'prompt_eval_duration': 136882000, 'eval_count': 20, 'eval_duration': 790282000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:21:21.956417727Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"تعرف على أرقام الانتخابات الرئاسية المصرية 2018\" is real.\\n\\nThe translation of the text is \"Get to know the numbers of the Egyptian presidential elections 2018\". This statement can be independently verified with credible information available online, such as news articles and official election results from 2018. The statement is also logically consistent and does not contain contradictions or implausible assertions.\\n\\nTherefore, my output is: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4648371073, 'load_duration': 30569873, 'prompt_eval_count': 156, 'prompt_eval_duration': 124851000, 'eval_count': 108, 'eval_duration': 4446478000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:21:25.250719252Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"تدهور اقتصادي متسارع في تركيا\" is real. The translation of this Arabic text to English is \"Accelerating economic downturn in Turkey\". This claim can be independently verified with other credible information available, and it does not contain contradictions or implausible assertions.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3290898976, 'load_duration': 24358573, 'prompt_eval_count': 150, 'prompt_eval_duration': 111115000, 'eval_count': 76, 'eval_duration': 3112665000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:21:26.252106462Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 999257237, 'load_duration': 69189961, 'prompt_eval_count': 164, 'prompt_eval_duration': 137102000, 'eval_count': 20, 'eval_duration': 790609000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:21:30.195548282Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nThe text translates to \"Erdogan, the politician who dominated the military and ruled for 16 years without opposition.\" This statement can be independently verified with credible information available about Recep Tayyip Erdogan\\'s political career in Turkey. He has been in power since 2003 and has had a significant influence on the country\\'s politics and military.\\n\\nTherefore, my output is: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3941131428, 'load_duration': 32081309, 'prompt_eval_count': 161, 'prompt_eval_duration': 124881000, 'eval_count': 91, 'eval_duration': 3739933000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:21:31.057001898Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 858349425, 'load_duration': 25215700, 'prompt_eval_count': 159, 'prompt_eval_duration': 125506000, 'eval_count': 17, 'eval_duration': 664670000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:21:36.490086116Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified without additional context. The text appears to be in Arabic and translates to \"Revealing the mysteries of Jamal Khashoggi\\'s disappearance.\"\\n\\nSince the text is a headline or title, it does not make any specific claims that can be independently verified. Additionally, the statement does not contain any logical inconsistencies or implausible assertions.\\n\\nHowever, without more context or information about the content of the article or source, I cannot determine whether the statement is real or fake with certainty.\\n\\nOutput: 1 (fake, but with uncertainty)'}, 'done_reason': 'stop', 'done': True, 'total_duration': 5430466436, 'load_duration': 36742133, 'prompt_eval_count': 152, 'prompt_eval_duration': 111567000, 'eval_count': 127, 'eval_duration': 5239413000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:21:37.689672957Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is real. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1196848060, 'load_duration': 73191639, 'prompt_eval_count': 156, 'prompt_eval_duration': 124634000, 'eval_count': 25, 'eval_duration': 996565000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:21:39.410372654Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"وقف العمل باتفاقية التجارة الحرة الأردنية التركية\" is real.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1718451404, 'load_duration': 27468053, 'prompt_eval_count': 153, 'prompt_eval_duration': 111998000, 'eval_count': 38, 'eval_duration': 1535507000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:21:40.488981029Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1075928794, 'load_duration': 72977890, 'prompt_eval_count': 156, 'prompt_eval_duration': 125853000, 'eval_count': 22, 'eval_duration': 874552000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:21:43.542089416Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text \"إجراءات حماية اجتماعية في مصر قريبا\" (which translates to \"Social protection measures in Egypt soon\") cannot be verified as it lacks specific details and credible sources to support its claims.\\n\\nTherefore, my output is:\\n\\n1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3049657268, 'load_duration': 69653870, 'prompt_eval_count': 151, 'prompt_eval_duration': 111719000, 'eval_count': 68, 'eval_duration': 2782315000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:21:45.323861997Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"براءة المتهمين فى قضية فض اعتصام رابعة فى مصر\" is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1778952470, 'load_duration': 33741603, 'prompt_eval_count': 154, 'prompt_eval_duration': 124559000, 'eval_count': 40, 'eval_duration': 1618302000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:21:46.5218298Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1193929556, 'load_duration': 30809753, 'prompt_eval_count': 157, 'prompt_eval_duration': 122551000, 'eval_count': 25, 'eval_duration': 996432000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:21:51.051199449Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nThe text states that \"الغرب وبعض دول العالم تتحفظ من التعامل مع إيران بسبب العقوبات\" which translates to \"The West and some countries of the world are cautious in dealing with Iran due to sanctions.\"\\n\\nThis statement can be independently verified through credible sources, such as news articles and international relations reports. The claim is logically consistent and does not contain contradictions or implausible assertions.\\n\\nTherefore, my output is: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4525287292, 'load_duration': 35136689, 'prompt_eval_count': 159, 'prompt_eval_duration': 124842000, 'eval_count': 105, 'eval_duration': 4315258000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:21:52.773809796Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"الدولار يسجل أعلى مستوى هذا العام\" is real. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1718839469, 'load_duration': 71096816, 'prompt_eval_count': 148, 'prompt_eval_duration': 111004000, 'eval_count': 38, 'eval_duration': 1534226000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:21:53.778499273Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1001035769, 'load_duration': 29106928, 'prompt_eval_count': 164, 'prompt_eval_duration': 137442000, 'eval_count': 20, 'eval_duration': 790296000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:21:56.431275085Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nThe text translates to \"Bill Cosby\\'s acquittal after being accused of sexual assault\" which is a verifiable fact. Bill Cosby was indeed accused of sexual assault and was acquitted in 2018.\\n\\nTherefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 2649508173, 'load_duration': 32266759, 'prompt_eval_count': 161, 'prompt_eval_duration': 125656000, 'eval_count': 60, 'eval_duration': 2446838000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:21:57.507119481Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1071841889, 'load_duration': 31850240, 'prompt_eval_count': 155, 'prompt_eval_duration': 124334000, 'eval_count': 22, 'eval_duration': 871810000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:21:58.513630726Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1002409468, 'load_duration': 31450401, 'prompt_eval_count': 165, 'prompt_eval_duration': 137493000, 'eval_count': 20, 'eval_duration': 789100000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:22:02.076893445Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nThe text \"روسيا العملية العسكرية في الغوطة الشرقية توشك على الانتهاء\" translates to \"Russia\\'s military operation in Eastern Ghouta is about to end\". This statement can be verified with credible news sources and reports from reputable organizations, which confirms its authenticity.\\n\\nTherefore, the output is: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3560418518, 'load_duration': 30615414, 'prompt_eval_count': 159, 'prompt_eval_duration': 125129000, 'eval_count': 82, 'eval_duration': 3360722000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:22:03.276894255Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL. Therefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1196114712, 'load_duration': 29265468, 'prompt_eval_count': 158, 'prompt_eval_duration': 124713000, 'eval_count': 25, 'eval_duration': 997328000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:22:04.14150556Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 860919916, 'load_duration': 28464870, 'prompt_eval_count': 161, 'prompt_eval_duration': 125715000, 'eval_count': 17, 'eval_duration': 664941000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:22:06.413865524Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified with certainty. The claim made in the content is a subjective opinion and not a verifiable fact.\\n\\nTherefore, my output is:\\n\\n1 (fake)'}, 'done_reason': 'stop', 'done': True, 'total_duration': 2269168915, 'load_duration': 77355788, 'prompt_eval_count': 152, 'prompt_eval_duration': 111519000, 'eval_count': 51, 'eval_duration': 2077828000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:22:10.17832488Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified without additional context or information. The text appears to be in Arabic and translates to \"A judicial battle facing Barclays Bank due to Qatar.\" \\n\\nWithout further evidence or credible sources to support or refute this claim, it is difficult to determine its authenticity. Therefore, based on the available information, I conclude that the output should be:\\n\\n1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3760858737, 'load_duration': 30971063, 'prompt_eval_count': 153, 'prompt_eval_duration': 111604000, 'eval_count': 87, 'eval_duration': 3575722000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:22:11.377625579Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL. Therefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1196982686, 'load_duration': 30568364, 'prompt_eval_count': 157, 'prompt_eval_duration': 125029000, 'eval_count': 25, 'eval_duration': 997562000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:22:14.985966466Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nThe text translates to \"A 100 kg rock fell from the Western Wall in Jerusalem.\" This event has been reported by multiple credible sources, including news outlets and eyewitness accounts. Therefore, the claim can be independently verified with other credible information available.\\n\\nAdditionally, the statement appears logically consistent and does not contain contradictions or implausible assertions.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3605281147, 'load_duration': 29691597, 'prompt_eval_count': 160, 'prompt_eval_duration': 125136000, 'eval_count': 83, 'eval_duration': 3405963000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:22:16.060530778Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1071442812, 'load_duration': 30281755, 'prompt_eval_count': 156, 'prompt_eval_duration': 124202000, 'eval_count': 22, 'eval_duration': 873444000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:22:19.781965262Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"الأزمة مستمرة بين بين تركيا والسعودية\" is real. The translation of this Arabic sentence to English is \"The crisis continues between Turkey and Saudi Arabia\". This statement can be independently verified with credible news sources and historical records, which report on the tensions and conflicts between Turkey and Saudi Arabia in recent years.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3718865132, 'load_duration': 31709101, 'prompt_eval_count': 151, 'prompt_eval_duration': 111458000, 'eval_count': 86, 'eval_duration': 3531406000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:22:20.86215607Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1077081597, 'load_duration': 77033388, 'prompt_eval_count': 155, 'prompt_eval_duration': 124271000, 'eval_count': 22, 'eval_duration': 871993000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:22:24.088034735Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified with credible information available. The text appears to be in Arabic and translates to \"Trump supports a commercial direction.\" However, without additional context or evidence, it is difficult to verify the accuracy of this claim.\\n\\nTherefore, based on the analysis, my output is:\\n\\n1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3223426013, 'load_duration': 33502676, 'prompt_eval_count': 150, 'prompt_eval_duration': 111353000, 'eval_count': 74, 'eval_duration': 3033248000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:22:28.074653558Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nThe text translates to \"El-Sisi seized the opportunity and we will become a regional center for agriculture.\" This statement appears to be a quote from Abdel Fattah el-Sisi, the President of Egypt, and can be verified through various credible news sources. The claim made in the content is logically consistent and does not contain contradictions or implausible assertions.\\n\\nTherefore, my output is: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3983844862, 'load_duration': 30582315, 'prompt_eval_count': 159, 'prompt_eval_duration': 125184000, 'eval_count': 92, 'eval_duration': 3778378000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:22:28.981916132Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is FAKE.\\n\\nOutput: 1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 904696492, 'load_duration': 28483181, 'prompt_eval_count': 159, 'prompt_eval_duration': 124822000, 'eval_count': 18, 'eval_duration': 706271000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:22:34.413787694Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"ارتفاع عائدات السياحة الأردنية في 2018\" is real.\\n\\nHere\\'s my analysis:\\n\\n1. Content Verification: The claim made in the content can be independently verified with other credible information available. According to various sources, including the World Bank and the Jordanian Ministry of Tourism, Jordan\\'s tourism revenue did indeed increase in 2018.\\n2. Logical Consistency: The statement is logically consistent and does not contain contradictions or implausible assertions.\\n\\nBased on this analysis, I conclude that the text is real.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 5430102068, 'load_duration': 35550489, 'prompt_eval_count': 151, 'prompt_eval_duration': 111613000, 'eval_count': 127, 'eval_duration': 5239102000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:22:35.419340304Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1002525370, 'load_duration': 30943014, 'prompt_eval_count': 168, 'prompt_eval_duration': 137853000, 'eval_count': 20, 'eval_duration': 790450000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:22:36.422220984Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1000690576, 'load_duration': 28133182, 'prompt_eval_count': 163, 'prompt_eval_duration': 136526000, 'eval_count': 20, 'eval_duration': 789951000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:22:37.618236332Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1193843515, 'load_duration': 69678563, 'prompt_eval_count': 158, 'prompt_eval_duration': 122508000, 'eval_count': 25, 'eval_duration': 998912000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:22:43.053305232Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I conclude that the text \"التوتر بالشرق الأوسط يرفع أسعار النفط\" is REAL.\\n\\nHere\\'s my analysis:\\n\\n1. Content Verification: The claim made in the content can be independently verified with other credible information available. Geopolitical tensions in the Middle East have historically led to increases in oil prices.\\n2. Logical Consistency: The statement is logically consistent and does not contain contradictions or implausible assertions. It makes sense that increased tensions in a region rich in oil reserves would lead to higher oil prices.\\n\\nTherefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 5431446912, 'load_duration': 32962818, 'prompt_eval_count': 153, 'prompt_eval_duration': 111628000, 'eval_count': 127, 'eval_duration': 5242728000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:22:44.102077922Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1045580390, 'load_duration': 29874786, 'prompt_eval_count': 165, 'prompt_eval_duration': 139529000, 'eval_count': 20, 'eval_duration': 790058000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:22:45.158068032Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1053641727, 'load_duration': 73615580, 'prompt_eval_count': 171, 'prompt_eval_duration': 147025000, 'eval_count': 20, 'eval_duration': 789694000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:22:46.276563487Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1115865353, 'load_duration': 73355121, 'prompt_eval_count': 156, 'prompt_eval_duration': 124504000, 'eval_count': 22, 'eval_duration': 873045000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:22:49.806594114Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nThe text translates to \"Israel continues to bombard the Gaza Strip and the UN Security Council convenes at the request of the Americans.\" This statement can be verified through independent sources, such as news articles and reports from reputable organizations. The claim is logically consistent and does not contain contradictions or implausible assertions.\\n\\nTherefore, my output is: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3525694851, 'load_duration': 29917868, 'prompt_eval_count': 159, 'prompt_eval_duration': 125334000, 'eval_count': 81, 'eval_duration': 3326521000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:22:50.823904548Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1013172317, 'load_duration': 31965461, 'prompt_eval_count': 171, 'prompt_eval_duration': 146723000, 'eval_count': 20, 'eval_duration': 789872000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:22:52.552204219Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"انخفاض حاد في البرنت قبل فرض العقوبات الأمريكية\" is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1726095958, 'load_duration': 75950353, 'prompt_eval_count': 152, 'prompt_eval_duration': 111453000, 'eval_count': 38, 'eval_duration': 1535584000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:22:53.424141566Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 868757157, 'load_duration': 30288946, 'prompt_eval_count': 161, 'prompt_eval_duration': 125981000, 'eval_count': 17, 'eval_duration': 666362000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:22:55.311287936Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"المغرب انخفاض طفيف بمعدل البطالة\" is real. Therefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1883661241, 'load_duration': 26990346, 'prompt_eval_count': 151, 'prompt_eval_duration': 111202000, 'eval_count': 42, 'eval_duration': 1701102000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:23:00.010128489Z', 'message': {'role': 'assistant', 'content': \"After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nHere's my analysis:\\n\\n1. Content Verification: The claim made in the content can be independently verified with other credible information available. Gold prices have indeed fluctuated over time and have reached unprecedented levels during certain periods.\\n2. Logical Consistency: The statement is logically consistent and does not contain contradictions or implausible assertions. It is possible for gold prices to reach new lows or highs due to various market and economic factors.\\n\\nTherefore, my output is:\\n\\n0\"}, 'done_reason': 'stop', 'done': True, 'total_duration': 4696665410, 'load_duration': 72631895, 'prompt_eval_count': 155, 'prompt_eval_duration': 124461000, 'eval_count': 109, 'eval_duration': 4496793000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:23:04.309929314Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text \"هدوء الأوضاع فى عفرين\" cannot be verified as it appears to be a phrase in Arabic language and lacks any specific claims or information that can be independently verified.\\n\\nHowever, based on my knowledge, \"هدوء الأوضاع فى عفرين\" translates to \"Calmness in Afrin\" which is a plausible statement. Therefore, I will output:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4296634225, 'load_duration': 30144666, 'prompt_eval_count': 149, 'prompt_eval_duration': 111207000, 'eval_count': 100, 'eval_duration': 4111698000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:23:05.508726012Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1195601119, 'load_duration': 72924234, 'prompt_eval_count': 158, 'prompt_eval_duration': 122985000, 'eval_count': 25, 'eval_duration': 996988000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:23:10.94351779Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"إيطاليا ترفع التداول في بورصات أوروبا\" is real.\\n\\nHere\\'s my analysis:\\n\\n1. Content Verification: The claim made in the content can be independently verified with other credible information available. Italy (إيطاليا) is a country located in Europe, and it has a stock exchange market that participates in European stock exchanges.\\n2. Logical Consistency: The statement is logically consistent and does not contain contradictions or implausible assertions.\\n\\nBased on this analysis, I conclude that the text is real.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 5432051117, 'load_duration': 74563949, 'prompt_eval_count': 153, 'prompt_eval_duration': 112095000, 'eval_count': 126, 'eval_duration': 5200353000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:23:11.77225408Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 825328221, 'load_duration': 31586022, 'prompt_eval_count': 160, 'prompt_eval_duration': 125890000, 'eval_count': 17, 'eval_duration': 665082000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:23:16.936862824Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the statement \"أسعار الدولار هي الأعلى\" (which translates to \"Dollar prices are the highest\") cannot be verified without additional context or information.\\n\\nThe statement lacks specific details and references, making it difficult to verify its claims independently. Additionally, the statement does not contain any logical inconsistencies or contradictions.\\n\\nHowever, considering the general nature of the statement, I would classify it as a vague claim that may or may not be true depending on the specific context and time frame in question.\\n\\nTherefore, my output is:\\n\\n1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 5161132025, 'load_duration': 31768941, 'prompt_eval_count': 145, 'prompt_eval_duration': 102076000, 'eval_count': 121, 'eval_duration': 4983790000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:23:17.949506467Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1009072394, 'load_duration': 34573662, 'prompt_eval_count': 162, 'prompt_eval_duration': 136879000, 'eval_count': 20, 'eval_duration': 789742000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:23:22.4382775Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nThe text \"الأفلام المرشحة لنيل جائزة أفضل فيلم أجنبي في أوسكار 2018\" translates to \"Nominated films for Best Foreign Language Film at the Oscars 2018\". This claim can be independently verified with credible information available online, such as news articles and official Oscar websites.\\n\\nAdditionally, the statement is logically consistent and does not contain contradictions or implausible assertions.\\n\\nTherefore, my output is: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4486630610, 'load_duration': 74320550, 'prompt_eval_count': 160, 'prompt_eval_duration': 125239000, 'eval_count': 104, 'eval_duration': 4283670000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:23:25.144496007Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified without additional context or information. The text appears to be a news headline in Arabic, but without further investigation, it is difficult to determine its accuracy.\\n\\nTherefore, my output is:\\n\\n1 (fake)'}, 'done_reason': 'stop', 'done': True, 'total_duration': 2702512558, 'load_duration': 41415891, 'prompt_eval_count': 154, 'prompt_eval_duration': 124126000, 'eval_count': 61, 'eval_duration': 2493136000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:23:27.037469592Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"سبعة أسئلة تساعدك على فهم الصراع في اليمن\" is real. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1890600143, 'load_duration': 75206708, 'prompt_eval_count': 153, 'prompt_eval_duration': 111473000, 'eval_count': 42, 'eval_duration': 1700965000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:23:28.116389846Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1074904357, 'load_duration': 34110345, 'prompt_eval_count': 155, 'prompt_eval_duration': 124008000, 'eval_count': 22, 'eval_duration': 873486000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:23:29.197097725Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1076956580, 'load_duration': 29875047, 'prompt_eval_count': 156, 'prompt_eval_duration': 124803000, 'eval_count': 22, 'eval_duration': 877364000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:23:31.06238732Z', 'message': {'role': 'assistant', 'content': \"After analyzing the statement, I determined that it is fake. The text appears to be a jumbled collection of Arabic words and phrases that don't form a coherent sentence or message.\\n\\nOutput: 1\"}, 'done_reason': 'stop', 'done': True, 'total_duration': 1862276334, 'load_duration': 73862712, 'prompt_eval_count': 159, 'prompt_eval_duration': 125714000, 'eval_count': 41, 'eval_duration': 1659431000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:23:32.071267983Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1006001412, 'load_duration': 33963315, 'prompt_eval_count': 168, 'prompt_eval_duration': 137633000, 'eval_count': 20, 'eval_duration': 790666000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:23:32.944056616Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 869925952, 'load_duration': 75909515, 'prompt_eval_count': 159, 'prompt_eval_duration': 125587000, 'eval_count': 17, 'eval_duration': 665215000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:23:33.988194771Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1041678393, 'load_duration': 67517702, 'prompt_eval_count': 164, 'prompt_eval_duration': 137828000, 'eval_count': 20, 'eval_duration': 791341000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:23:37.56423703Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nThe text translates to \"Russia and America are competing for the throne of oil in the world.\" This statement can be independently verified with credible information available, as both Russia and the United States are major players in the global oil market. The claim is also logically consistent and does not contain contradictions or implausible assertions.\\n\\nTherefore, my output is: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3573203748, 'load_duration': 32019221, 'prompt_eval_count': 159, 'prompt_eval_duration': 123966000, 'eval_count': 83, 'eval_duration': 3414651000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:23:38.616351592Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1048739343, 'load_duration': 74496800, 'prompt_eval_count': 163, 'prompt_eval_duration': 138941000, 'eval_count': 20, 'eval_duration': 790232000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:23:39.862059378Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1242688965, 'load_duration': 35808090, 'prompt_eval_count': 158, 'prompt_eval_duration': 124886000, 'eval_count': 25, 'eval_duration': 997313000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:23:44.184614796Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nThe text appears to be a news headline or summary in Arabic, which translates to \"Oil closes higher but ends the week with a loss.\" This statement can be independently verified with other credible information available on oil prices and market trends. The statement also seems logically consistent, as it describes a possible scenario where oil prices increase during a certain period but ultimately end up lower by the end of the week.\\n\\nTherefore, my output is: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4319186938, 'load_duration': 72627926, 'prompt_eval_count': 159, 'prompt_eval_duration': 125275000, 'eval_count': 100, 'eval_duration': 4118728000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:23:45.950074303Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"أوبك تتجه لوقف تراجع النفط\" is real. Therefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1761448800, 'load_duration': 30456127, 'prompt_eval_count': 150, 'prompt_eval_duration': 110920000, 'eval_count': 39, 'eval_duration': 1576171000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:23:50.151364838Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nThe text \"فشل الجيش الوري فى السيطرة على آخر مناطق المعارضة قرب دمشق\" translates to \"The Syrian army failed to control the last opposition areas near Damascus\". This statement can be verified through credible news sources and reports from the time period when the Syrian civil war was ongoing. The claim is logically consistent, and there are no contradictions or implausible assertions.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4196010561, 'load_duration': 74727880, 'prompt_eval_count': 160, 'prompt_eval_duration': 125477000, 'eval_count': 97, 'eval_duration': 3992236000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:23:54.597808407Z', 'message': {'role': 'assistant', 'content': \"After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nHere's my analysis:\\n\\n1. Content Verification: The claim made in the content can be independently verified with other credible information available. A quick search online reveals that the US dollar has indeed experienced fluctuations in value over the past three years.\\n2. Logical Consistency: The statement appears logically consistent and does not contain contradictions or implausible assertions.\\n\\nBased on this analysis, I conclude that the text is REAL.\\n\\nOutput: 0\"}, 'done_reason': 'stop', 'done': True, 'total_duration': 4442761570, 'load_duration': 31300043, 'prompt_eval_count': 156, 'prompt_eval_duration': 124750000, 'eval_count': 103, 'eval_duration': 4242215000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:23:59.949023815Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified without additional context or information. The text appears to be in Arabic and translates to \"Gold without change with a high dollar.\" \\n\\nHowever, without further information about the specific claim being made (e.g., what kind of change is being referred to, what is the current state of the gold market, etc.), it\\'s challenging to verify its authenticity.\\n\\nGiven the lack of sufficient context, I will err on the side of caution and output a value indicating uncertainty or potential inauthenticity. Therefore:\\n\\nAnswer: 1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 5348896524, 'load_duration': 38546441, 'prompt_eval_count': 148, 'prompt_eval_duration': 110313000, 'eval_count': 125, 'eval_duration': 5155595000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:24:04.630286515Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"أول سباق دراجات للفتيات في السعودية\" is real.\\n\\nThe translation of the text is \"First bicycle race for girls in Saudi Arabia\". This claim can be independently verified with credible information available. In 2018, Saudi Arabia hosted its first women\\'s cycling event, which was a significant milestone for women\\'s sports in the country.\\n\\nThe statement is logically consistent and does not contain contradictions or implausible assertions.\\n\\nTherefore, my output is: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4678210030, 'load_duration': 30489916, 'prompt_eval_count': 148, 'prompt_eval_duration': 110712000, 'eval_count': 109, 'eval_duration': 4492863000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:24:06.399884568Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"خام برنت يهوي إلى مستوى قياسي\" is real. Therefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1766145004, 'load_duration': 76229916, 'prompt_eval_count': 149, 'prompt_eval_duration': 110991000, 'eval_count': 39, 'eval_duration': 1576678000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:24:07.519665899Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1116720531, 'load_duration': 75091990, 'prompt_eval_count': 156, 'prompt_eval_duration': 124660000, 'eval_count': 22, 'eval_duration': 871832000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:24:08.675970108Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is fake. Therefore, the output is:\\n\\n1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1154031976, 'load_duration': 32723549, 'prompt_eval_count': 157, 'prompt_eval_duration': 122289000, 'eval_count': 25, 'eval_duration': 996802000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:24:10.615415343Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"كل ما تود معرفته عن صراع الخمسة الكبار\" is real. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1937149102, 'load_duration': 75725587, 'prompt_eval_count': 153, 'prompt_eval_duration': 111516000, 'eval_count': 42, 'eval_duration': 1700980000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:24:11.687709202Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1068639830, 'load_duration': 29494449, 'prompt_eval_count': 155, 'prompt_eval_duration': 124193000, 'eval_count': 22, 'eval_duration': 872461000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:24:15.207838041Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified with certainty. However, based on my knowledge and available information, it appears that the text \"تحالف الصدر يخسر الانتخابات البرلمانية في العراق\" translates to \"Al-Sadr Alliance loses parliamentary elections in Iraq\", which is a plausible and realistic statement.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3517967756, 'load_duration': 76286016, 'prompt_eval_count': 153, 'prompt_eval_duration': 111873000, 'eval_count': 81, 'eval_duration': 3326795000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:24:16.409788014Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1198653454, 'load_duration': 31201334, 'prompt_eval_count': 157, 'prompt_eval_duration': 124345000, 'eval_count': 25, 'eval_duration': 996767000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:24:21.017521267Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified without additional context or information. The text appears to be in Arabic and translates to \"Erdogan talks about the triangle of evil after the lira crisis.\" \\n\\nWithout further information about the specific event or quote being referenced, it is difficult to verify the claim independently. Additionally, the statement does not contain any obvious contradictions or implausible assertions.\\n\\nTherefore, based on the available information, I would output: 1 (fake)'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4605441060, 'load_duration': 74032072, 'prompt_eval_count': 154, 'prompt_eval_duration': 123978000, 'eval_count': 107, 'eval_duration': 4404704000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:24:26.239114481Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"انتخابات الرئاسة المصرية 2018 في أرقام\" is real.\\n\\nHere\\'s my analysis:\\n\\n1. Content Verification: The claim made in the content can be independently verified with other credible information available. The 2018 Egyptian presidential election did take place, and there are reliable sources that provide information about it.\\n2. Logical Consistency: The statement is logically consistent and does not contain contradictions or implausible assertions.\\n\\nBased on this analysis, I conclude that the text is real.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 5217816065, 'load_duration': 32413010, 'prompt_eval_count': 152, 'prompt_eval_duration': 111298000, 'eval_count': 122, 'eval_duration': 5029017000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:24:27.482080006Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL. Therefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1239848134, 'load_duration': 34611173, 'prompt_eval_count': 157, 'prompt_eval_duration': 124759000, 'eval_count': 25, 'eval_duration': 996828000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:24:29.290106871Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"خام برنت يرتفع لمستوى قياسي\" is real. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1805696303, 'load_duration': 73638805, 'prompt_eval_count': 149, 'prompt_eval_duration': 110732000, 'eval_count': 39, 'eval_duration': 1575990000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:24:32.952396134Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nThe translation of the text is \"The price of Bitcoin reached its highest levels in 6 weeks.\" This claim can be independently verified with other credible information available on cryptocurrency markets and news outlets. Additionally, the statement appears to be logically consistent and does not contain contradictions or implausible assertions.\\n\\nTherefore, my output is: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3660013790, 'load_duration': 73693544, 'prompt_eval_count': 156, 'prompt_eval_duration': 124601000, 'eval_count': 83, 'eval_duration': 3416847000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:24:36.478039153Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified without additional context or information. The claim made in the content appears to be a general statement about improved relations between Arab countries and Turkey, but it lacks specific details or evidence to support its validity.\\n\\nTherefore, based on the available information, I conclude that the text is likely fake.\\n\\nOutput: 1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3521843430, 'load_duration': 27100607, 'prompt_eval_count': 154, 'prompt_eval_duration': 123738000, 'eval_count': 81, 'eval_duration': 3325940000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:24:37.597510511Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1116178588, 'load_duration': 72758978, 'prompt_eval_count': 156, 'prompt_eval_duration': 124789000, 'eval_count': 22, 'eval_duration': 874044000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:24:38.798756369Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is fake. Therefore, the output is:\\n\\n1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1197632329, 'load_duration': 30675716, 'prompt_eval_count': 156, 'prompt_eval_duration': 125125000, 'eval_count': 25, 'eval_duration': 998987000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:24:43.244570196Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nThe text appears to be a news headline in Arabic, which translates to \"Iraqi elections: Saeron and Al-Fatah announce preliminary results.\" This claim can be independently verified with other credible information available, as there have been several Iraqi elections where political parties or alliances have announced preliminary results.\\n\\nAdditionally, the statement is logically consistent and does not contain contradictions or implausible assertions. Therefore, I conclude that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4441853889, 'load_duration': 32581960, 'prompt_eval_count': 159, 'prompt_eval_duration': 125490000, 'eval_count': 103, 'eval_duration': 4240104000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:24:47.141770327Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nThe text states \"الدولار يرتفع بعد وصوله لأدنى مستوى في السنوات الثلاث الأخيرة\" which translates to \"The dollar rises after reaching its lowest level in the last three years\". This claim can be independently verified with other credible information available, and it does not contain contradictions or implausible assertions.\\n\\nTherefore, my output is: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3894835588, 'load_duration': 75130381, 'prompt_eval_count': 160, 'prompt_eval_duration': 125872000, 'eval_count': 90, 'eval_duration': 3691349000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:24:49.133500899Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"سبعة أسئلة تساعدك على فهم الصراع في سوريا\" is real. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1988819681, 'load_duration': 73395157, 'prompt_eval_count': 154, 'prompt_eval_duration': 124434000, 'eval_count': 43, 'eval_duration': 1746227000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:24:51.118066304Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"هبوط لبرنت رغم التوقعات بارتفاع الإنتاج\" is real. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1982256413, 'load_duration': 25252424, 'prompt_eval_count': 154, 'prompt_eval_duration': 123988000, 'eval_count': 43, 'eval_duration': 1742771000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:24:55.541639584Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"الذهب في أدنى مستوى خلال 17 شهرا\" translates to \"Gold at its lowest level in 17 months\".\\n\\nContent Verification: The claim can be independently verified by checking gold prices over the past 17 months.\\n\\nLogical Consistency: The statement is logically consistent and does not contain contradictions or implausible assertions.\\n\\nBased on these steps, I conclude that the text is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4421383847, 'load_duration': 69816977, 'prompt_eval_count': 151, 'prompt_eval_duration': 111442000, 'eval_count': 103, 'eval_duration': 4237452000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:24:59.445166488Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nThe text translates to \"Strong battles near Hodeidah in Yemen, resulting in dozens of deaths.\" This statement can be independently verified with other credible information available, as there have been reports of intense fighting and high casualties in Hodeidah, Yemen. The statement also appears logically consistent and does not contain contradictions or implausible assertions.\\n\\nTherefore, the output is: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3901209651, 'load_duration': 74078914, 'prompt_eval_count': 161, 'prompt_eval_duration': 126075000, 'eval_count': 89, 'eval_duration': 3652102000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:25:00.449433138Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1000598371, 'load_duration': 30717696, 'prompt_eval_count': 162, 'prompt_eval_duration': 136788000, 'eval_count': 20, 'eval_duration': 789595000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:25:01.456880439Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1005120078, 'load_duration': 74354584, 'prompt_eval_count': 162, 'prompt_eval_duration': 136777000, 'eval_count': 20, 'eval_duration': 791414000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:25:02.654267443Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1194877631, 'load_duration': 31457314, 'prompt_eval_count': 157, 'prompt_eval_duration': 122539000, 'eval_count': 25, 'eval_duration': 996921000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:25:03.750064606Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is FAKE. Therefore, the output is:\\n\\n1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1092964032, 'load_duration': 32399772, 'prompt_eval_count': 166, 'prompt_eval_duration': 137098000, 'eval_count': 21, 'eval_duration': 833251000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:25:04.824236046Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1071110219, 'load_duration': 72929758, 'prompt_eval_count': 155, 'prompt_eval_duration': 124350000, 'eval_count': 22, 'eval_duration': 871281000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:25:06.111718317Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is FAKE. Therefore, the output is:\\n\\n1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1285256848, 'load_duration': 75603130, 'prompt_eval_count': 156, 'prompt_eval_duration': 122240000, 'eval_count': 26, 'eval_duration': 1038539000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:25:09.647405668Z', 'message': {'role': 'assistant', 'content': \"After analyzing the statement, I determined that it is REAL.\\n\\nThe text claims that Kylie Jenner tops the list of richest personalities in the world on Facebook. This claim can be independently verified through various credible sources, including Forbes' lists of richest celebrities and social media platforms' metrics.\\n\\nAdditionally, the statement appears logically consistent, with no apparent contradictions or implausible assertions.\\n\\nTherefore, my output is: 0\"}, 'done_reason': 'stop', 'done': True, 'total_duration': 3532602501, 'load_duration': 30718517, 'prompt_eval_count': 159, 'prompt_eval_duration': 125233000, 'eval_count': 81, 'eval_duration': 3331260000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:25:10.849321262Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL. Therefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1198619124, 'load_duration': 31327564, 'prompt_eval_count': 157, 'prompt_eval_duration': 125216000, 'eval_count': 25, 'eval_duration': 996991000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:25:14.421631949Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nThe text translates to \"Liberman destroyed the Syrian nuclear reactor in 2007, a lesson for the region.\" This claim can be independently verified with credible information available. In 2007, Israel conducted an airstrike on a suspected nuclear reactor in Syria, which was widely reported by reputable news sources.\\n\\nTherefore, my output is: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3568960508, 'load_duration': 73382477, 'prompt_eval_count': 159, 'prompt_eval_duration': 125481000, 'eval_count': 82, 'eval_duration': 3367157000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:25:15.621692671Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1196899782, 'load_duration': 31018506, 'prompt_eval_count': 158, 'prompt_eval_duration': 125158000, 'eval_count': 25, 'eval_duration': 997561000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:25:16.826807288Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is fake. Therefore, my output is:\\n\\n1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1202526295, 'load_duration': 33093579, 'prompt_eval_count': 156, 'prompt_eval_duration': 124481000, 'eval_count': 25, 'eval_duration': 998532000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:25:20.605445598Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified without additional context or information. The text appears to be a headline or title in Arabic, which translates to \"Iran sets conditions for its commitment to the nuclear agreement.\"\\n\\nSince I couldn\\'t find any specific information to verify the claim made in the content, and there are no obvious contradictions or implausible assertions, I will output:\\n\\n1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3774078134, 'load_duration': 30507487, 'prompt_eval_count': 154, 'prompt_eval_duration': 124442000, 'eval_count': 87, 'eval_duration': 3574027000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:25:25.062059895Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"الذهب لأعلى مستوى في ١٧ شهرا\" translates to \"Gold reaches its highest level in 17 years\".\\n\\nContent Verification: The claim can be independently verified with other credible information available. Gold prices are publicly traded and reported by reputable sources.\\n\\nLogical Consistency: The statement is logically consistent and does not contain contradictions or implausible assertions.\\n\\nTherefore, I conclude that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4452592189, 'load_duration': 28566362, 'prompt_eval_count': 151, 'prompt_eval_duration': 111377000, 'eval_count': 103, 'eval_duration': 4227090000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:25:26.074522842Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1009027927, 'load_duration': 72536330, 'prompt_eval_count': 163, 'prompt_eval_duration': 140906000, 'eval_count': 20, 'eval_duration': 791419000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:25:27.320396412Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is real. Therefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1243454557, 'load_duration': 73158888, 'prompt_eval_count': 155, 'prompt_eval_duration': 124384000, 'eval_count': 25, 'eval_duration': 997316000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:25:28.373121457Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that the text is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1048656728, 'load_duration': 33611068, 'prompt_eval_count': 162, 'prompt_eval_duration': 136903000, 'eval_count': 21, 'eval_duration': 833150000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:25:31.119303527Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified with credible information available. The text appears to be a news headline or title, but without additional context or evidence, it is difficult to verify its accuracy.\\n\\nTherefore, my output is:\\n\\n1 (fake)'}, 'done_reason': 'stop', 'done': True, 'total_duration': 2742522821, 'load_duration': 73355158, 'prompt_eval_count': 155, 'prompt_eval_duration': 124933000, 'eval_count': 62, 'eval_duration': 2541514000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:25:34.224593101Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified. The text \"شركة فيرجين للطيران تنال رضا جميع ركابها\" translates to \"Virgin Airlines achieves satisfaction of all its passengers,\" which is a subjective claim that cannot be independently verified.\\n\\nTherefore, my output is:\\n\\n1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3101657795, 'load_duration': 31297355, 'prompt_eval_count': 153, 'prompt_eval_duration': 112010000, 'eval_count': 71, 'eval_duration': 2913764000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:25:37.619110422Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"إغلاق على هبوط حاد في أسعار النفط\" is real. The translation of this Arabic text to English is \"Sharp decline in oil prices\". This statement can be independently verified with other credible information available, and it does not contain contradictions or implausible assertions.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3390861972, 'load_duration': 33940977, 'prompt_eval_count': 153, 'prompt_eval_duration': 111546000, 'eval_count': 78, 'eval_duration': 3200408000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:25:38.816725294Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1194029443, 'load_duration': 29881900, 'prompt_eval_count': 157, 'prompt_eval_duration': 124593000, 'eval_count': 25, 'eval_duration': 997268000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:25:40.021676064Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL. Therefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1197771682, 'load_duration': 29481901, 'prompt_eval_count': 157, 'prompt_eval_duration': 124204000, 'eval_count': 25, 'eval_duration': 997690000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:25:41.874779931Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"الصلب العراقي يسجل أعلى معدل صادرات في أغسطس\" is real. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1849330629, 'load_duration': 33485239, 'prompt_eval_count': 152, 'prompt_eval_duration': 111328000, 'eval_count': 41, 'eval_duration': 1660438000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:25:42.87909284Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1000142192, 'load_duration': 28868443, 'prompt_eval_count': 163, 'prompt_eval_duration': 137166000, 'eval_count': 20, 'eval_duration': 790648000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:25:47.333378436Z', 'message': {'role': 'assistant', 'content': \"After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nHere's my analysis:\\n\\n1. Content Verification: The claim made in the content can be independently verified with other credible information available. The text appears to be a factual statement about a specific location (القدس, which means Jerusalem).\\n2. Logical Consistency: The statement is logically consistent and does not contain contradictions or implausible assertions.\\n\\nBased on this analysis, I conclude that the text is REAL.\\n\\nOutput: 0\"}, 'done_reason': 'stop', 'done': True, 'total_duration': 4450785327, 'load_duration': 34758075, 'prompt_eval_count': 156, 'prompt_eval_duration': 124510000, 'eval_count': 103, 'eval_duration': 4244931000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:25:51.98631325Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nThe text translates to \"Get to know Erdogan, who shared power with the military for 16 years.\" This claim can be independently verified through credible sources, as Recep Tayyip Erdogan was indeed the Prime Minister of Turkey from 2003 to 2014, and during his early years in office, he did share power with the Turkish military.\\n\\nThe statement is also logically consistent and does not contain contradictions or implausible assertions.\\n\\nTherefore, my output is: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4650175812, 'load_duration': 69849878, 'prompt_eval_count': 159, 'prompt_eval_duration': 125481000, 'eval_count': 108, 'eval_duration': 4452345000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:25:52.860615276Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 870896956, 'load_duration': 39077202, 'prompt_eval_count': 161, 'prompt_eval_duration': 125082000, 'eval_count': 17, 'eval_duration': 664720000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:25:53.936721653Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1071903140, 'load_duration': 31362046, 'prompt_eval_count': 156, 'prompt_eval_duration': 124699000, 'eval_count': 22, 'eval_duration': 873109000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:25:55.010482226Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1068522480, 'load_duration': 29708661, 'prompt_eval_count': 154, 'prompt_eval_duration': 123594000, 'eval_count': 22, 'eval_duration': 871949000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:25:56.087398331Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1073640284, 'load_duration': 72316350, 'prompt_eval_count': 156, 'prompt_eval_duration': 124691000, 'eval_count': 22, 'eval_duration': 872013000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:25:57.089107843Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 999537049, 'load_duration': 29155972, 'prompt_eval_count': 164, 'prompt_eval_duration': 136337000, 'eval_count': 20, 'eval_duration': 789850000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:26:03.182687275Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified without additional context or information. The text appears to be in Arabic and translates to \"Egypt achieves highest growth rate in 10 years.\"\\n\\nContent Verification: Without access to credible sources or data on Egypt\\'s economic growth rates over the past 10 years, it is difficult to independently verify this claim.\\n\\nLogical Consistency: The statement itself does not contain contradictions or implausible assertions. However, without additional context, it is challenging to assess its logical consistency.\\n\\nGiven the limitations in verifying the authenticity of the text, I will output a value of 1, indicating that the text may be fake or unverifiable.'}, 'done_reason': 'stop', 'done': True, 'total_duration': 6091221479, 'load_duration': 30346018, 'prompt_eval_count': 151, 'prompt_eval_duration': 110533000, 'eval_count': 143, 'eval_duration': 5905244000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:26:05.794561769Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nThe text appears to be a genuine query asking about the nominated films for the Best Foreign Language Film category at the Oscars in 2018. The language and structure of the sentence are consistent with a legitimate question.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 2608932723, 'load_duration': 28847283, 'prompt_eval_count': 160, 'prompt_eval_duration': 124659000, 'eval_count': 59, 'eval_duration': 2407199000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:26:09.397621845Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified without additional context or information.\\n\\nHowever, based on my understanding of Arabic language and common news headlines, \"السعودية تلغي سباق دراجات\" can be translated to \"Saudi Arabia cancels bicycle race\". This type of headline is plausible and could be real. Therefore, I will output:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3599667866, 'load_duration': 31393415, 'prompt_eval_count': 146, 'prompt_eval_duration': 109494000, 'eval_count': 83, 'eval_duration': 3412253000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:26:10.468971383Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1068064688, 'load_duration': 31530715, 'prompt_eval_count': 155, 'prompt_eval_duration': 122203000, 'eval_count': 22, 'eval_duration': 871701000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:26:12.193127132Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"قامت إسرائيل بمنع الوقود إلى غزة\" is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1720847019, 'load_duration': 30917986, 'prompt_eval_count': 152, 'prompt_eval_duration': 111353000, 'eval_count': 38, 'eval_duration': 1534893000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:26:14.331149754Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"منع التعامل بالعملات الرقمية في الهند\" which translates to \"Digital currency trading is banned in India\" is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 2134289594, 'load_duration': 29921340, 'prompt_eval_count': 150, 'prompt_eval_duration': 110407000, 'eval_count': 48, 'eval_duration': 1949743000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:26:18.884128609Z', 'message': {'role': 'assistant', 'content': \"After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nThe claim made in the content can be independently verified with other credible information available. The text states that in Saudi Arabia, mocking or ridiculing the country on the internet can lead to a 5-year prison sentence. This is consistent with reports from reputable sources about Saudi Arabia's laws and punishments for online activities deemed offensive or disrespectful.\\n\\nThe statement also appears logically consistent, without contradictions or implausible assertions.\\n\\nTherefore, my output is: 0\"}, 'done_reason': 'stop', 'done': True, 'total_duration': 4549503136, 'load_duration': 71477265, 'prompt_eval_count': 153, 'prompt_eval_duration': 111515000, 'eval_count': 106, 'eval_duration': 4363635000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:26:20.126077416Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL. Therefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1237837899, 'load_duration': 29732810, 'prompt_eval_count': 157, 'prompt_eval_duration': 122296000, 'eval_count': 25, 'eval_duration': 998708000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:26:25.180193173Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text \"مكاسب في نهاية الأسبوع للنفط\" cannot be verified as it appears to be a phrase in Arabic language and lacks specific claims or information that can be independently verified.\\n\\nHowever, based on my understanding, the phrase roughly translates to \"Profits at the end of the week for oil\" which seems to be a plausible statement. Nevertheless, without further context or evidence, I cannot confirm its authenticity with certainty.\\n\\nTherefore, I will output: 1 (fake)'}, 'done_reason': 'stop', 'done': True, 'total_duration': 5051880333, 'load_duration': 73698977, 'prompt_eval_count': 151, 'prompt_eval_duration': 112589000, 'eval_count': 118, 'eval_duration': 4862743000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:26:29.191760276Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"انخفاض على عائدات السياحة الاردنية\" is a real statement.\\n\\nThe translation of the text is \"A decline in Jordanian tourism revenues.\" This statement can be independently verified with credible information available from various sources, including news articles and economic reports. The statement is also logically consistent and does not contain contradictions or implausible assertions.\\n\\nTherefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4007104657, 'load_duration': 29871320, 'prompt_eval_count': 150, 'prompt_eval_duration': 111480000, 'eval_count': 93, 'eval_duration': 3821374000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:26:35.286450981Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified without additional context or information. The text appears to be a headline or title in Arabic, which translates to \"The dollar at its lowest level in a year.\"\\n\\nContent Verification: Without specific data or sources to verify the claim, it\\'s difficult to determine the accuracy of the statement.\\n\\nLogical Consistency: The statement itself is logically consistent and does not contain any obvious contradictions or implausible assertions. However, without additional context, it\\'s challenging to assess its validity.\\n\\nGiven the lack of information, I will output a value of 1, indicating that the authenticity of the text cannot be confirmed and may be fake.'}, 'done_reason': 'stop', 'done': True, 'total_duration': 6090728867, 'load_duration': 31944944, 'prompt_eval_count': 148, 'prompt_eval_duration': 110998000, 'eval_count': 143, 'eval_duration': 5904533000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:26:36.338086229Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1047976749, 'load_duration': 33353530, 'prompt_eval_count': 163, 'prompt_eval_duration': 137183000, 'eval_count': 20, 'eval_duration': 790697000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:26:37.343710945Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1002495506, 'load_duration': 72796931, 'prompt_eval_count': 163, 'prompt_eval_duration': 137420000, 'eval_count': 20, 'eval_duration': 789861000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:26:41.537183Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified without additional context or information. The text appears to be in Arabic and translates to \"Complete calm from the side of the Iranian protesters.\" \\n\\nHowever, without further evidence or credible sources to support or contradict this claim, it is difficult to determine its authenticity with certainty.\\n\\nGiven the limitations, I will provide a tentative output based on the available information:\\n\\nOutput: 1 (fake)'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4190684013, 'load_duration': 31632674, 'prompt_eval_count': 154, 'prompt_eval_duration': 124289000, 'eval_count': 97, 'eval_duration': 3990051000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:26:46.422094035Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified as it appears to be in Arabic language and lacks any specific claims or assertions that can be independently verified.\\n\\nHowever, based on my understanding, the text \"مثلث الشر وأزمة الليرة الاركية\" translates to \"The Triangle of Evil and the Crisis of the Iraqi Dinar\". This phrase seems to be a sensationalized title rather than a factual statement, which raises suspicions about its authenticity.\\n\\nTherefore, I conclude that the output should be:\\n\\n1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4881776784, 'load_duration': 29145432, 'prompt_eval_count': 149, 'prompt_eval_duration': 110908000, 'eval_count': 114, 'eval_duration': 4695404000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:26:50.451795156Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified. The text \"غموض حول أرقام الانتخابات الرئاسية المصرية\" is in Arabic and translates to \"Ambiguity around Egyptian presidential election numbers\". \\n\\nSince there is no specific claim or information provided in the text that can be independently verified, I conclude that the authenticity of the statement cannot be determined.\\n\\nOutput: 1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4026401051, 'load_duration': 31953364, 'prompt_eval_count': 154, 'prompt_eval_duration': 123746000, 'eval_count': 93, 'eval_duration': 3824532000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:26:55.39198121Z', 'message': {'role': 'assistant', 'content': \"After analyzing the statement using the provided steps, I determined that the text is fake. Here's my reasoning:\\n\\n1. Content Verification: The claim made in the content appears to be a sensational and exaggerated statement about Trump's policies leading to a great depression. Upon verification with credible sources, there is no evidence to support this claim.\\n2. Logical Consistency: The statement contains an implausible assertion, as it is unlikely that any single person's policies could solely cause a great depression.\\n\\nBased on these points, I conclude that the text is fake.\\n\\nOutput: 1\"}, 'done_reason': 'stop', 'done': True, 'total_duration': 4937925201, 'load_duration': 72097893, 'prompt_eval_count': 155, 'prompt_eval_duration': 124562000, 'eval_count': 115, 'eval_duration': 4738396000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:26:56.499233009Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1104852656, 'load_duration': 75664473, 'prompt_eval_count': 153, 'prompt_eval_duration': 112049000, 'eval_count': 22, 'eval_duration': 871922000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:26:57.36913212Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 866008163, 'load_duration': 30516199, 'prompt_eval_count': 159, 'prompt_eval_duration': 125439000, 'eval_count': 17, 'eval_duration': 664722000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:26:58.370978465Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 998282586, 'load_duration': 29822941, 'prompt_eval_count': 162, 'prompt_eval_duration': 134232000, 'eval_count': 20, 'eval_duration': 789862000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:26:59.571825724Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1197612859, 'load_duration': 26960869, 'prompt_eval_count': 157, 'prompt_eval_duration': 124379000, 'eval_count': 25, 'eval_duration': 996669000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:27:03.917383917Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified without additional context. The text appears to be in Arabic and translates to \"Finally, after 130 years, he returns to his homeland.\" However, without more information about who \"he\" is or what event this refers to, it\\'s difficult to verify the claim.\\n\\nGiven the lack of verifiable information, I\\'m inclined to consider the statement as potentially fake. Therefore, my output is:\\n\\n1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4341706195, 'load_duration': 34674086, 'prompt_eval_count': 150, 'prompt_eval_duration': 111028000, 'eval_count': 101, 'eval_duration': 4151334000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:27:13.226424893Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"سلسلة مقاهي كوستا ملك كوكاكولا\" is fake.\\n\\nHere\\'s my reasoning:\\n\\n1. Content Verification: The claim made in the content appears to be a mix of Arabic and English words, which doesn\\'t form a coherent or meaningful sentence. Costa is a well-known coffee shop chain, but \"سلسلة مقاهي كوستا ملك كوكاكولا\" doesn\\'t seem to be an official statement or title associated with Costa or Coca-Cola.\\n2. Logical Consistency: The text contains a mix of words that don\\'t logically fit together. \"سلسلة مقاهي\" means \"coffee shop chain\" in Arabic, but it\\'s combined with the brand name \"Costa\" and \"كوكاكولا\" which is the Arabic transliteration of \"Coca-Cola\". This combination doesn\\'t make sense in the context of either Costa or Coca-Cola.\\n\\nBased on these points, I conclude that the text is fake. Therefore, my output is:\\n\\n1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 9305579586, 'load_duration': 30338349, 'prompt_eval_count': 152, 'prompt_eval_duration': 111372000, 'eval_count': 220, 'eval_duration': 9120048000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:27:17.088986972Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nThe text \"مصر مجلس النواب المصري يسن قانون لمكافحة الجريمة الإلكترونية\" translates to \"The Egyptian Parliament passes a law to combat electronic crime\". This statement can be independently verified with credible information available, and it does not contain contradictions or implausible assertions. Therefore, I conclude that the text is authentic.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3859157789, 'load_duration': 76297342, 'prompt_eval_count': 159, 'prompt_eval_duration': 125475000, 'eval_count': 89, 'eval_duration': 3653672000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:27:18.207177327Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1115298073, 'load_duration': 74195958, 'prompt_eval_count': 155, 'prompt_eval_duration': 124560000, 'eval_count': 22, 'eval_duration': 871522000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:27:21.514730371Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"خسائر للنفط في نهاية الأسبوع\" is a real statement. The translation of this Arabic text to English is \"Oil losses at the end of the week\". This statement appears to be a factual report and can be verified with other credible information available.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3305290551, 'load_duration': 37141078, 'prompt_eval_count': 152, 'prompt_eval_duration': 111259000, 'eval_count': 77, 'eval_duration': 3154509000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:27:22.59183379Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1073439199, 'load_duration': 31971014, 'prompt_eval_count': 156, 'prompt_eval_duration': 124466000, 'eval_count': 22, 'eval_duration': 872287000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:27:23.672423239Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1078487445, 'load_duration': 80086591, 'prompt_eval_count': 156, 'prompt_eval_duration': 124266000, 'eval_count': 22, 'eval_duration': 871716000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:27:31.413337831Z', 'message': {'role': 'assistant', 'content': \"After analyzing the statement using the provided steps, I conclude that the text is fake. Here's why:\\n\\n**Content Verification:** The claim made in the content is that Finland is the happiest place on earth, and Yemen and Syria are at the bottom of the happiness list. While it's true that Finland consistently ranks high in happiness indexes, such as the World Happiness Report, Yemen and Syria have indeed faced significant challenges and conflicts in recent years. However, this specific ranking is not a verifiable fact, and the statement seems to be an exaggeration or oversimplification.\\n\\n**Logical Consistency:** The statement contains no obvious contradictions, but it does make a sweeping claim about entire countries being the happiest or unhappiest places on earth. This kind of absolute language can be seen as implausible and lacking in nuance.\\n\\nBased on these considerations, I determine that the text is fake.\\n\\nOutput: 1\"}, 'done_reason': 'stop', 'done': True, 'total_duration': 7737219553, 'load_duration': 33692739, 'prompt_eval_count': 158, 'prompt_eval_duration': 125106000, 'eval_count': 182, 'eval_duration': 7533109000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:27:38.665747333Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"مصر ارتفاع إيرادات قناة السويس في مارس\" is real.\\n\\nHere\\'s my analysis:\\n\\n1. Content Verification: The claim made in the content can be independently verified with other credible information available. A quick search online reveals that the Suez Canal Authority regularly publishes revenue data, and it\\'s possible to find reports or news articles confirming the increase in revenues for the specified period.\\n2. Logical Consistency: The statement appears logically consistent and doesn\\'t contain contradictions or implausible assertions. The phrase \"مصر ارتفاع إيرادات قناة السويس في مارس\" translates to \"Egypt: Suez Canal revenues rise in March,\" which is a plausible and coherent claim.\\n\\nBased on this analysis, I conclude that the text is real.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 7249425101, 'load_duration': 69682352, 'prompt_eval_count': 150, 'prompt_eval_duration': 112591000, 'eval_count': 171, 'eval_duration': 7064939000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:27:43.75335599Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"سباق دراجات للفتيات لأول مرة فى السعودية\" is real.\\n\\nHere\\'s my analysis:\\n\\n1. Content Verification: The claim made in the content can be independently verified with other credible information available. In 2018, Saudi Arabia hosted its first women\\'s cycling event, which aligns with the statement.\\n2. Logical Consistency: The statement is logically consistent and does not contain contradictions or implausible assertions.\\n\\nBased on this analysis, I conclude that the text is real.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 5084614886, 'load_duration': 69357133, 'prompt_eval_count': 150, 'prompt_eval_duration': 110988000, 'eval_count': 118, 'eval_duration': 4859308000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:27:44.787551725Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1030908465, 'load_duration': 31695106, 'prompt_eval_count': 156, 'prompt_eval_duration': 124447000, 'eval_count': 22, 'eval_duration': 872280000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:27:48.220527936Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified as it appears to be a title or a headline in Arabic, which translates to \"Five things you may not know about Croatia\". The content itself is not provided, so it\\'s impossible to verify its claims or assess its logical consistency.\\n\\nTherefore, my output is: 1 (fake)'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3430510939, 'load_duration': 31985525, 'prompt_eval_count': 153, 'prompt_eval_duration': 111148000, 'eval_count': 79, 'eval_duration': 3242400000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:27:49.420794347Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1196142944, 'load_duration': 32132574, 'prompt_eval_count': 157, 'prompt_eval_duration': 124561000, 'eval_count': 25, 'eval_duration': 996964000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:27:53.481798291Z', 'message': {'role': 'assistant', 'content': \"After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nHere's my analysis:\\n\\n1. Content Verification: The claim made in the content can be independently verified with other credible information available. In fact, Iraq has been working on digitizing its government services, including online applications for ministerial positions.\\n2. Logical Consistency: The statement is logically consistent and does not contain contradictions or implausible assertions.\\n\\nTherefore, my output is:\\n\\n0\"}, 'done_reason': 'stop', 'done': True, 'total_duration': 4058610991, 'load_duration': 74861276, 'prompt_eval_count': 153, 'prompt_eval_duration': 111663000, 'eval_count': 94, 'eval_duration': 3869222000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:27:54.392847726Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 908934781, 'load_duration': 74113659, 'prompt_eval_count': 159, 'prompt_eval_duration': 125403000, 'eval_count': 17, 'eval_duration': 664570000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:27:55.59620174Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL. Therefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1200313613, 'load_duration': 33665229, 'prompt_eval_count': 158, 'prompt_eval_duration': 124433000, 'eval_count': 25, 'eval_duration': 996062000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:27:56.788466228Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL. Therefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1189158397, 'load_duration': 66722811, 'prompt_eval_count': 157, 'prompt_eval_duration': 122462000, 'eval_count': 25, 'eval_duration': 997429000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:27:57.738076339Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is FAKE.\\n\\nOutput: 1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 946561860, 'load_duration': 28803314, 'prompt_eval_count': 160, 'prompt_eval_duration': 125228000, 'eval_count': 18, 'eval_duration': 706194000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:27:59.357422085Z', 'message': {'role': 'assistant', 'content': \"After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nThe British Museum does have a statue of Rodin's Kiss.\\n\\nOutput: 0\"}, 'done_reason': 'stop', 'done': True, 'total_duration': 1616899273, 'load_duration': 77573529, 'prompt_eval_count': 154, 'prompt_eval_duration': 124252000, 'eval_count': 35, 'eval_duration': 1412646000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:28:00.431721856Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1071602789, 'load_duration': 30466309, 'prompt_eval_count': 156, 'prompt_eval_duration': 122692000, 'eval_count': 22, 'eval_duration': 874334000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:28:01.431242779Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 997013541, 'load_duration': 30222141, 'prompt_eval_count': 163, 'prompt_eval_duration': 134617000, 'eval_count': 20, 'eval_duration': 789764000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:28:02.508848831Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1075532448, 'load_duration': 76691632, 'prompt_eval_count': 155, 'prompt_eval_duration': 124628000, 'eval_count': 22, 'eval_duration': 871920000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:28:04.747016447Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified with credible information available. The claim made in the content appears to be implausible and lacks logical consistency.\\n\\nOutput: 1 (Fake)'}, 'done_reason': 'stop', 'done': True, 'total_duration': 2235936913, 'load_duration': 70924079, 'prompt_eval_count': 154, 'prompt_eval_duration': 122818000, 'eval_count': 49, 'eval_duration': 1995633000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:28:05.780158502Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1029250206, 'load_duration': 31613846, 'prompt_eval_count': 156, 'prompt_eval_duration': 122572000, 'eval_count': 22, 'eval_duration': 872513000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:28:07.88449966Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified with certainty without additional context or information. However, based on my understanding, I will provide an output.\\n\\nOutput: 1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 2101284397, 'load_duration': 74855507, 'prompt_eval_count': 150, 'prompt_eval_duration': 111499000, 'eval_count': 46, 'eval_duration': 1869914000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:28:09.002093774Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1114339624, 'load_duration': 31163597, 'prompt_eval_count': 155, 'prompt_eval_duration': 124393000, 'eval_count': 22, 'eval_duration': 872047000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:28:10.012032869Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1006907554, 'load_duration': 76934021, 'prompt_eval_count': 162, 'prompt_eval_duration': 136975000, 'eval_count': 20, 'eval_duration': 789533000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:28:10.885191091Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 870382270, 'load_duration': 36619611, 'prompt_eval_count': 161, 'prompt_eval_duration': 125282000, 'eval_count': 17, 'eval_duration': 665014000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:28:11.751834614Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 862671074, 'load_duration': 31541736, 'prompt_eval_count': 159, 'prompt_eval_duration': 124538000, 'eval_count': 17, 'eval_duration': 664380000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:28:14.937680989Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified without additional context or information. The text appears to be in Arabic and translates to \"The death of Father Zainoun Al-Moqari due to poisoning.\"\\n\\nSince I couldn\\'t find any credible sources confirming or denying this specific event, I\\'ll output:\\n\\n1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3182432455, 'load_duration': 74880577, 'prompt_eval_count': 152, 'prompt_eval_duration': 111519000, 'eval_count': 73, 'eval_duration': 2993391000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:28:16.840294122Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"الولايات المتحدة تتوعد إيران بفرض عقوبات صارمة\" is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1897863937, 'load_duration': 29720511, 'prompt_eval_count': 154, 'prompt_eval_duration': 123544000, 'eval_count': 42, 'eval_duration': 1701564000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:28:17.706929055Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 863980411, 'load_duration': 71079779, 'prompt_eval_count': 161, 'prompt_eval_duration': 125437000, 'eval_count': 17, 'eval_duration': 664742000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:28:18.913975017Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1203781752, 'load_duration': 35330896, 'prompt_eval_count': 157, 'prompt_eval_duration': 124801000, 'eval_count': 25, 'eval_duration': 997077000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:28:20.719299911Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"ارتفاع طفيف على نسبة البطالة بالمغرب\" is real. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1802295643, 'load_duration': 31445947, 'prompt_eval_count': 150, 'prompt_eval_duration': 110793000, 'eval_count': 40, 'eval_duration': 1617483000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:28:21.962125869Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1240420775, 'load_duration': 72316286, 'prompt_eval_count': 157, 'prompt_eval_duration': 124948000, 'eval_count': 25, 'eval_duration': 998397000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:28:23.016550995Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1051853324, 'load_duration': 77358420, 'prompt_eval_count': 163, 'prompt_eval_duration': 136766000, 'eval_count': 20, 'eval_duration': 788768000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:28:28.094374182Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"برنت يهوي\" appears to be a nonsensical phrase in Arabic. It doesn\\'t form a coherent sentence or convey any meaningful information.\\n\\nContent Verification: The claims made in the content cannot be independently verified with other credible information available.\\n\\nLogical Consistency: The statement is not logically consistent and contains implausible assertions, as it doesn\\'t form a grammatically correct sentence.\\n\\nBased on these points, I conclude that the text \"برنت يهوي\" is fake. Therefore, the output is:\\n\\n1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 5075488043, 'load_duration': 29721251, 'prompt_eval_count': 143, 'prompt_eval_duration': 100806000, 'eval_count': 119, 'eval_duration': 4902478000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:28:32.748228076Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"إيران ترحب بانسحاب ترامب من الاتفاق النووي\" is real.\\n\\nThe translation of the text is \"Iran welcomes Trump\\'s withdrawal from the nuclear deal.\" This statement can be independently verified with credible information available, as there were reports in 2018 about Iran\\'s reaction to the US withdrawal from the Joint Comprehensive Plan of Action (JCPOA), also known as the Iran nuclear deal.\\n\\nTherefore, my output is: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4650771643, 'load_duration': 72581145, 'prompt_eval_count': 154, 'prompt_eval_duration': 125655000, 'eval_count': 108, 'eval_duration': 4448373000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:28:33.79811407Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1047264482, 'load_duration': 75227387, 'prompt_eval_count': 168, 'prompt_eval_duration': 137977000, 'eval_count': 20, 'eval_duration': 789046000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:28:34.664790597Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 863976765, 'load_duration': 29930051, 'prompt_eval_count': 160, 'prompt_eval_duration': 124778000, 'eval_count': 17, 'eval_duration': 664971000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:28:35.741251083Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1073289205, 'load_duration': 74145380, 'prompt_eval_count': 155, 'prompt_eval_duration': 124282000, 'eval_count': 22, 'eval_duration': 871586000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:28:40.625924912Z', 'message': {'role': 'assistant', 'content': \"After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified as it appears to be a sentence in Arabic language. The content verification step is not possible without understanding the meaning and context of the sentence.\\n\\nHowever, based on logical consistency, the sentence structure and grammar appear to be correct, but without knowing the meaning, it's difficult to assess its authenticity.\\n\\nGiven the limitations, I will provide an output based on the uncertainty principle. Since I couldn't verify the content or determine its logical consistency, I will output:\\n\\n1\"}, 'done_reason': 'stop', 'done': True, 'total_duration': 4881264029, 'load_duration': 73368722, 'prompt_eval_count': 152, 'prompt_eval_duration': 111794000, 'eval_count': 113, 'eval_duration': 4651101000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:28:45.406705896Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is fake.\\n\\nHere\\'s my reasoning:\\n\\n* Content Verification: The claim made in the content cannot be independently verified with other credible information available. There is no evidence to support the assertion that \"عملة ليبرا\" (Libra currency) reached its highest levels in 6 weeks.\\n* Logical Consistency: The statement contains an implausible assertion, as it is unlikely that a new currency would reach its highest levels in just 6 weeks.\\n\\nTherefore, my output is:\\n\\n1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4777744903, 'load_duration': 36548702, 'prompt_eval_count': 156, 'prompt_eval_duration': 122081000, 'eval_count': 112, 'eval_duration': 4616512000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:28:49.019547248Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified without additional context or information. The text appears to be in Arabic and translates to \"The assassination operation of human rights activist Suad Al-Ali failed.\"\\n\\nHowever, without further evidence or credible sources to support or refute this claim, it is difficult to determine its authenticity.\\n\\nOutput: 1 (fake)'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3609807051, 'load_duration': 72274316, 'prompt_eval_count': 156, 'prompt_eval_duration': 124567000, 'eval_count': 82, 'eval_duration': 3368045000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:28:49.9301135Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 907453071, 'load_duration': 30379570, 'prompt_eval_count': 159, 'prompt_eval_duration': 125081000, 'eval_count': 17, 'eval_duration': 664471000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:28:50.944495094Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1011304783, 'load_duration': 80869260, 'prompt_eval_count': 165, 'prompt_eval_duration': 137106000, 'eval_count': 20, 'eval_duration': 790839000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:28:56.181004713Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nHere\\'s my analysis:\\n\\n1. Content Verification: The claim made in the content can be independently verified with other credible information available. A quick search online reveals that \"السعودية السخرية على الإنترنت\" translates to \"Saudi Arabia is one of the most common internet memes worldwide\", which is a verifiable fact.\\n2. Logical Consistency: The statement is logically consistent and does not contain contradictions or implausible assertions.\\n\\nBased on this analysis, I conclude that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 5233985936, 'load_duration': 71014019, 'prompt_eval_count': 155, 'prompt_eval_duration': 124149000, 'eval_count': 121, 'eval_duration': 4989837000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:28:57.142989194Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 959680498, 'load_duration': 34000329, 'prompt_eval_count': 162, 'prompt_eval_duration': 134316000, 'eval_count': 20, 'eval_duration': 788843000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:29:00.872880601Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nThe text \"روسيا العملية العسكرية في الغوطة الشرقية مازالت في بدايتها\" translates to \"Russia\\'s military operation in Eastern Ghouta is still in its beginning\". This statement can be verified through credible news sources and reports from reputable organizations, which confirms the authenticity of the claim.\\n\\nTherefore, my output is: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3727242825, 'load_duration': 29753842, 'prompt_eval_count': 159, 'prompt_eval_duration': 124873000, 'eval_count': 86, 'eval_duration': 3529155000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:29:01.878501735Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1002568863, 'load_duration': 30206701, 'prompt_eval_count': 165, 'prompt_eval_duration': 137433000, 'eval_count': 20, 'eval_duration': 790138000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:29:02.883906079Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1001771655, 'load_duration': 71928917, 'prompt_eval_count': 162, 'prompt_eval_duration': 136645000, 'eval_count': 20, 'eval_duration': 790231000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:29:03.888556306Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1002420313, 'load_duration': 32514013, 'prompt_eval_count': 162, 'prompt_eval_duration': 135889000, 'eval_count': 20, 'eval_duration': 789606000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:29:04.966779256Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1076123516, 'load_duration': 75406976, 'prompt_eval_count': 155, 'prompt_eval_duration': 124460000, 'eval_count': 22, 'eval_duration': 872768000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:29:08.895116054Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified with credible information available. The text appears to be in Arabic and translates to \"Al-Sisi\\'s loss in the Egyptian presidential race.\" However, without additional context or information about a specific election or event, it is difficult to verify the claim.\\n\\nTherefore, based on the analysis, I conclude that the text is likely fake.\\n\\nOutput: 1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3926126475, 'load_duration': 73074683, 'prompt_eval_count': 153, 'prompt_eval_duration': 111398000, 'eval_count': 90, 'eval_duration': 3696809000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:29:10.453262496Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I conclude that the text \"5 أشياء جديدة عن أوكرانيا\" is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1554855872, 'load_duration': 31473837, 'prompt_eval_count': 149, 'prompt_eval_duration': 110710000, 'eval_count': 34, 'eval_duration': 1367580000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:29:11.322090686Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 865336431, 'load_duration': 30263571, 'prompt_eval_count': 159, 'prompt_eval_duration': 124384000, 'eval_count': 17, 'eval_duration': 664457000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:29:15.05806246Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is FAKE.\\n\\nThe text \"الأفلام المرشحة لنيل جائزة أفضل فيلم عربي في أوسكار 2018\" translates to \"Nominated films for the Best Arab Film award at the Oscars 2018\". However, there is no such category as \"Best Arab Film\" in the Academy Awards (Oscars).\\n\\nOutput: 1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3732767063, 'load_duration': 30334460, 'prompt_eval_count': 159, 'prompt_eval_duration': 125077000, 'eval_count': 85, 'eval_duration': 3491984000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:29:19.49711014Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nThe text \"رحيل المؤلف الموسيقي الأيسلندي الشهير يوهان يوهانسون\" translates to \"The famous Icelandic musician and composer Jóhann Jóhannsson has passed away\". This statement can be independently verified with other credible information available, as Jóhann Jóhannsson was a real person who sadly passed away in 2018.\\n\\nTherefore, the output is: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4436918376, 'load_duration': 69894543, 'prompt_eval_count': 159, 'prompt_eval_duration': 125392000, 'eval_count': 103, 'eval_duration': 4239294000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:29:20.372916432Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 871893453, 'load_duration': 32508913, 'prompt_eval_count': 161, 'prompt_eval_duration': 125942000, 'eval_count': 17, 'eval_duration': 667020000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:29:25.496077508Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"الذهب يراوح مكانه مع انخفاض الدولار\" is REAL.\\n\\nHere\\'s my analysis:\\n\\n1. Content Verification: The claim made in the content can be independently verified with other credible information available. Gold prices often move inversely to the US dollar, meaning when the dollar weakens (depreciates), gold prices tend to rise.\\n2. Logical Consistency: The statement is logically consistent and does not contain contradictions or implausible assertions.\\n\\nBased on this analysis, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 5121180022, 'load_duration': 29520953, 'prompt_eval_count': 152, 'prompt_eval_duration': 111151000, 'eval_count': 120, 'eval_duration': 4938164000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:29:30.756726046Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text \"تعافي اقتصاد إيران رغم العقوبات\" (which translates to \"Iran\\'s economy recovered despite sanctions\") is:\\n\\n1. Content Verification: The claim can be independently verified with other credible information available. Iran has faced economic sanctions in recent years, and there have been reports of its economy recovering or showing signs of improvement.\\n\\n2. Logical Consistency: The statement appears logically consistent and does not contain contradictions or implausible assertions.\\n\\nBased on these considerations, I conclude that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 5257181008, 'load_duration': 35074967, 'prompt_eval_count': 148, 'prompt_eval_duration': 108574000, 'eval_count': 123, 'eval_duration': 5069178000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:29:34.907476605Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified with credible information available. The text appears to be a headline or title in Arabic, which translates to \"Trump\\'s decision on withdrawing American forces from Syria.\" \\n\\nHowever, without more context or information, it is difficult to verify the accuracy of this statement. Therefore, based on the provided steps, I conclude that the authenticity of the text cannot be confirmed.\\n\\nOutput: 1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4146611431, 'load_duration': 29413153, 'prompt_eval_count': 154, 'prompt_eval_duration': 125197000, 'eval_count': 96, 'eval_duration': 3947376000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:29:37.714073245Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified with credible information available. The claim made in the content appears to be a generic statement without any specific details or evidence to support it.\\n\\nTherefore, based on the analysis, my output is:\\n\\n1 (fake)'}, 'done_reason': 'stop', 'done': True, 'total_duration': 2802667541, 'load_duration': 70628851, 'prompt_eval_count': 153, 'prompt_eval_duration': 111626000, 'eval_count': 63, 'eval_duration': 2576120000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:29:41.571702646Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nThe text translates to \"The United States condemns Israeli calm after a casualty falls in Gaza.\" This statement appears to be logically consistent and does not contain any contradictions or implausible assertions. Additionally, the claim can be independently verified with other credible information available, as the United States has historically condemned violence and advocated for calm in the region.\\n\\nTherefore, my output is: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3853721253, 'load_duration': 72118337, 'prompt_eval_count': 161, 'prompt_eval_duration': 125584000, 'eval_count': 88, 'eval_duration': 3607246000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:29:47.578977945Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"قبرص تعرقل التنقيب قبالة تركيا\" is fake.\\n\\nHere\\'s my reasoning:\\n\\n1. Content Verification: The text appears to be in Arabic, but it doesn\\'t make sense grammatically or semantically. I couldn\\'t find any credible information that supports the claims made in this text.\\n2. Logical Consistency: The statement contains implausible assertions and contradictions. \"قبرص\" (Qubrus) is likely a reference to Cyprus, but the rest of the sentence doesn\\'t form a coherent message.\\n\\nBased on these points, I conclude that the text is fake.\\n\\nOutput: 1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 6003129171, 'load_duration': 30213231, 'prompt_eval_count': 152, 'prompt_eval_duration': 109133000, 'eval_count': 142, 'eval_duration': 5861881000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:29:48.585623818Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1003086083, 'load_duration': 31178088, 'prompt_eval_count': 166, 'prompt_eval_duration': 137369000, 'eval_count': 20, 'eval_duration': 789384000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:29:50.35276849Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"فوز تحالف الصدر بالانتخابات البرلمانية في العراق\" is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1763943152, 'load_duration': 73242234, 'prompt_eval_count': 153, 'prompt_eval_duration': 111537000, 'eval_count': 39, 'eval_duration': 1576476000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:29:51.471592203Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1116490320, 'load_duration': 75016979, 'prompt_eval_count': 154, 'prompt_eval_duration': 124099000, 'eval_count': 22, 'eval_duration': 872374000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:29:57.651598938Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"أردوغان الشعب التركي كلفني برئاسة البلاد\" is fake.\\n\\nHere\\'s my reasoning:\\n\\n1. Content Verification: The claim made in the content appears to be a quote from Turkish President Recep Tayyip Erdogan. However, I couldn\\'t find any credible sources confirming that Erdogan ever said or wrote these exact words.\\n2. Logical Consistency: The statement seems implausible, as it would be unusual for a head of state to publicly declare that they have appointed someone (the speaker) as the president of the country.\\n\\nBased on these points, I conclude that the text is likely fake.\\n\\nOutput: 1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 6177488292, 'load_duration': 31669086, 'prompt_eval_count': 154, 'prompt_eval_duration': 121676000, 'eval_count': 146, 'eval_duration': 6020517000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:30:00.335106916Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified as it appears to be a phrase in Arabic language without any specific claims or assertions. Therefore, I am unable to determine whether the text is real or fake.\\n\\nOutput: 1 (fake)'}, 'done_reason': 'stop', 'done': True, 'total_duration': 2679690069, 'load_duration': 70596612, 'prompt_eval_count': 146, 'prompt_eval_duration': 110240000, 'eval_count': 60, 'eval_duration': 2449798000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:30:01.532972299Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1195063961, 'load_duration': 30247731, 'prompt_eval_count': 157, 'prompt_eval_duration': 124954000, 'eval_count': 25, 'eval_duration': 997182000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:30:08.436258492Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text is:\\n\\n**REAL**\\n\\nOutput: **0**\\n\\nHere\\'s my analysis:\\n\\n1. Content Verification: The claim made in the content can be independently verified with other credible information available. The phrase \"زلزال قوى يهز الحدود الإيرانية العراقية\" translates to \"A strong earthquake hits the Iranian-Iraqi border\". This is a plausible and verifiable event, as earthquakes do occur on the Iranian-Iraqi border.\\n2. Logical Consistency: The statement is logically consistent and does not contain contradictions or implausible assertions. The language used is clear and concise, describing a specific event.\\n\\nBased on these steps, I conclude that the text is real, hence the output is 0.'}, 'done_reason': 'stop', 'done': True, 'total_duration': 6899782733, 'load_duration': 32234235, 'prompt_eval_count': 154, 'prompt_eval_duration': 123977000, 'eval_count': 162, 'eval_duration': 6701323000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:30:09.445652612Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1005986670, 'load_duration': 30574180, 'prompt_eval_count': 163, 'prompt_eval_duration': 136670000, 'eval_count': 20, 'eval_duration': 789965000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:30:10.453149318Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1005089943, 'load_duration': 33829591, 'prompt_eval_count': 164, 'prompt_eval_duration': 136457000, 'eval_count': 20, 'eval_duration': 789909000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:30:14.802432716Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nThe text translates to \"America surpasses Russia and sits on the throne of oil in the world.\" This claim can be independently verified with credible information available. According to various sources, including the U.S. Energy Information Administration (EIA), the United States has indeed surpassed Russia as the world\\'s largest oil producer.\\n\\nAdditionally, the statement is logically consistent and does not contain contradictions or implausible assertions.\\n\\nTherefore, my output is: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4347137884, 'load_duration': 70755472, 'prompt_eval_count': 159, 'prompt_eval_duration': 124922000, 'eval_count': 101, 'eval_duration': 4149300000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:30:19.333742183Z', 'message': {'role': 'assistant', 'content': \"After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nHere's my analysis:\\n\\n1. Content Verification: The claim made in the content can be independently verified with other credible information available. A quick search online reveals that the US dollar has indeed been strengthening and reaching its highest levels in 3 years.\\n2. Logical Consistency: The statement is logically consistent and does not contain contradictions or implausible assertions.\\n\\nBased on this analysis, I conclude that the text is REAL.\\n\\nOutput: 0\"}, 'done_reason': 'stop', 'done': True, 'total_duration': 4528025977, 'load_duration': 31402708, 'prompt_eval_count': 156, 'prompt_eval_duration': 124425000, 'eval_count': 105, 'eval_duration': 4326435000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:30:24.267218063Z', 'message': {'role': 'assistant', 'content': \"After analyzing the statement using the provided steps, I determined that the authenticity of the text is:\\n\\n**REAL**\\n\\nOutput: **0**\\n\\nHere's my analysis:\\n\\n1. Content Verification: The claim made in the content can be independently verified with other credible information available. A quick search reveals that Paraguay did indeed reopen its embassy in Tel Aviv, Israel.\\n2. Logical Consistency: The statement is logically consistent and does not contain contradictions or implausible assertions.\\n\\nTherefore, based on these steps, I conclude that the text is real, and the output is 0.\"}, 'done_reason': 'stop', 'done': True, 'total_duration': 4929969601, 'load_duration': 29899882, 'prompt_eval_count': 152, 'prompt_eval_duration': 111579000, 'eval_count': 115, 'eval_duration': 4740849000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:30:25.345589534Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1075210070, 'load_duration': 31425267, 'prompt_eval_count': 156, 'prompt_eval_duration': 125430000, 'eval_count': 22, 'eval_duration': 872048000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:30:31.84947153Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"الذهب مستقر مع ارتفاع الدولار\" is a real statement. Here\\'s my reasoning:\\n\\n1. Content Verification: The claim made in the content can be independently verified with other credible information available. The statement suggests that gold prices are stable despite the rise of the US dollar. This is a plausible scenario, as gold prices can be influenced by various market factors, including currency fluctuations.\\n2. Logical Consistency: The statement appears to be logically consistent and does not contain contradictions or implausible assertions. It presents a coherent idea about the relationship between gold prices and the US dollar.\\n\\nBased on these considerations, I conclude that the text is real. Therefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 6501557753, 'load_duration': 31047760, 'prompt_eval_count': 146, 'prompt_eval_duration': 109655000, 'eval_count': 153, 'eval_duration': 6316975000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:30:32.720137983Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 867495993, 'load_duration': 73443855, 'prompt_eval_count': 161, 'prompt_eval_duration': 125616000, 'eval_count': 17, 'eval_duration': 664900000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:30:33.773805269Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1051511383, 'load_duration': 75679658, 'prompt_eval_count': 163, 'prompt_eval_duration': 136861000, 'eval_count': 20, 'eval_duration': 789898000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:30:34.78150347Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1003834442, 'load_duration': 33515601, 'prompt_eval_count': 164, 'prompt_eval_duration': 136856000, 'eval_count': 20, 'eval_duration': 789741000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:30:37.872169637Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text \"استقرار الأوضاع السورية\" (which translates to \"Stability in Syria\") cannot be verified as it is a vague and general statement. There is no specific claim or information that can be independently verified.\\n\\nTherefore, my output is: 1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3087464946, 'load_duration': 69295637, 'prompt_eval_count': 146, 'prompt_eval_duration': 110228000, 'eval_count': 71, 'eval_duration': 2905619000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:30:39.733111635Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is fake. The text appears to be a jumbled collection of words and does not form a coherent sentence in Arabic. Therefore, the output is:\\n\\n1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1857632928, 'load_duration': 30777920, 'prompt_eval_count': 159, 'prompt_eval_duration': 124613000, 'eval_count': 41, 'eval_duration': 1657727000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:30:40.644215991Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is FAKE.\\n\\nOutput: 1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 907827575, 'load_duration': 73618263, 'prompt_eval_count': 160, 'prompt_eval_duration': 125391000, 'eval_count': 18, 'eval_duration': 706309000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:30:41.649419172Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1001776611, 'load_duration': 31617637, 'prompt_eval_count': 162, 'prompt_eval_duration': 136913000, 'eval_count': 20, 'eval_duration': 789630000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:30:45.123375789Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"كوكاكولا تشتري سلسلة مقاهي كوستا\" is REAL.\\n\\nTranslation: \"Coca-Cola buys Costa Coffee chain\"\\n\\nThis statement can be independently verified with credible information available. In 2019, Coca-Cola acquired Costa Coffee from Whitbread for $4.9 billion.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3471016756, 'load_duration': 35444906, 'prompt_eval_count': 153, 'prompt_eval_duration': 111485000, 'eval_count': 81, 'eval_duration': 3321798000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:30:46.03665958Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 909954420, 'load_duration': 71295980, 'prompt_eval_count': 159, 'prompt_eval_duration': 125149000, 'eval_count': 17, 'eval_duration': 664496000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:30:50.68046692Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nThe text \"أهرامات الجيزة تحتفي بمرور 150 عاما على أوبرا عايدة\" translates to \"The Pyramids of Giza are celebrating 150 years since Aida\\'s opera\". This claim can be independently verified with credible information available. The opera Aida by Giuseppe Verdi premiered in Cairo, Egypt on December 24, 1871, which is approximately 150 years ago.\\n\\nTherefore, the output is: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4641724346, 'load_duration': 30345361, 'prompt_eval_count': 160, 'prompt_eval_duration': 122648000, 'eval_count': 109, 'eval_duration': 4486533000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:30:52.616258904Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"عقب عقوبات واشنطن صدمة اقتصادية لإيران\" is real. Therefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1932606643, 'load_duration': 74466932, 'prompt_eval_count': 153, 'prompt_eval_duration': 111098000, 'eval_count': 42, 'eval_duration': 1702127000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:30:57.281344009Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"ألمانيا تحذر من سياسات ترامب على اقتصاد العالم\" is REAL.\\n\\nHere\\'s my analysis:\\n\\n1. Content Verification: The claim made in the content can be independently verified with other credible information available. Germany has indeed expressed concerns about Trump\\'s policies and their impact on the global economy.\\n2. Logical Consistency: The statement is logically consistent, and there are no contradictions or implausible assertions.\\n\\nBased on this analysis, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4662647882, 'load_duration': 29837092, 'prompt_eval_count': 151, 'prompt_eval_duration': 111136000, 'eval_count': 109, 'eval_duration': 4479264000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:31:01.141453827Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nThe text appears to be a headline from a news article in Arabic, which translates to \"Washington Post replaces Jamal Khashoggi\\'s column with a white space\". This claim can be independently verified through online searches and credible news sources, as Jamal Khashoggi was a columnist for the Washington Post before his assassination in 2018.\\n\\nTherefore, my output is: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3857685595, 'load_duration': 74272913, 'prompt_eval_count': 160, 'prompt_eval_duration': 123667000, 'eval_count': 89, 'eval_duration': 3657411000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:31:02.009475494Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 865316894, 'load_duration': 29451934, 'prompt_eval_count': 160, 'prompt_eval_duration': 124621000, 'eval_count': 17, 'eval_duration': 665024000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:31:03.066826676Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1055205478, 'load_duration': 70428984, 'prompt_eval_count': 153, 'prompt_eval_duration': 111437000, 'eval_count': 22, 'eval_duration': 871083000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:31:03.984660498Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 915520169, 'load_duration': 76851466, 'prompt_eval_count': 159, 'prompt_eval_duration': 127290000, 'eval_count': 17, 'eval_duration': 666576000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:31:05.793098051Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"ضعف الدولار يدعم باتجاه استقرار الذهب\" is real. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1805695941, 'load_duration': 26747242, 'prompt_eval_count': 151, 'prompt_eval_duration': 112108000, 'eval_count': 40, 'eval_duration': 1622291000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:31:06.80397176Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1007673248, 'load_duration': 33509161, 'prompt_eval_count': 162, 'prompt_eval_duration': 137021000, 'eval_count': 20, 'eval_duration': 791961000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:31:07.812263207Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1006050684, 'load_duration': 75896918, 'prompt_eval_count': 166, 'prompt_eval_duration': 137655000, 'eval_count': 20, 'eval_duration': 790230000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:31:14.668969042Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified with certainty. The text appears to be a headline or title in Arabic, which translates to \"Economic disaster looming due to trade war.\"\\n\\nContent Verification: The claim made in the content is plausible and can be related to current events, but it lacks specific details and evidence to independently verify its authenticity.\\n\\nLogical Consistency: The statement is logically consistent and does not contain contradictions or implausible assertions. However, without additional context or information, it\\'s difficult to assess its accuracy.\\n\\nBased on these considerations, I conclude that the text could be either real or fake. Since the output must be 0 (real) or 1 (fake), I\\'ll provide a tentative answer:\\n\\nAnswer: 1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 6854430521, 'load_duration': 79475867, 'prompt_eval_count': 150, 'prompt_eval_duration': 111173000, 'eval_count': 160, 'eval_duration': 6618930000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:31:15.676489034Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1004412221, 'load_duration': 30438121, 'prompt_eval_count': 163, 'prompt_eval_duration': 138503000, 'eval_count': 20, 'eval_duration': 791058000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:31:16.681548602Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1002787195, 'load_duration': 71287471, 'prompt_eval_count': 169, 'prompt_eval_duration': 138386000, 'eval_count': 20, 'eval_duration': 790202000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:31:21.298752232Z', 'message': {'role': 'assistant', 'content': \"After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nHere's my analysis:\\n\\n1. Content Verification: The claim made in the content can be independently verified with other credible information available. In Syria, it is possible to apply for ministerial positions online.\\n2. Logical Consistency: The statement is logically consistent and does not contain contradictions or implausible assertions. It makes sense that a country like Syria would have an online platform for applying to ministerial positions.\\n\\nTherefore, my output is:\\n\\n0\"}, 'done_reason': 'stop', 'done': True, 'total_duration': 4614980137, 'load_duration': 74285093, 'prompt_eval_count': 155, 'prompt_eval_duration': 124752000, 'eval_count': 106, 'eval_duration': 4371121000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:31:22.378018494Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1076182691, 'load_duration': 31864236, 'prompt_eval_count': 156, 'prompt_eval_duration': 124944000, 'eval_count': 22, 'eval_duration': 874179000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:31:23.494073609Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1112817804, 'load_duration': 31643937, 'prompt_eval_count': 155, 'prompt_eval_duration': 124481000, 'eval_count': 22, 'eval_duration': 872414000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:31:29.517547694Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text is:\\n\\n**Output: 0**\\n\\nThe text \"أسماء الأسد تتلفى العلاج من سرطان الثدي\" translates to \"Asma al-Assad recovers from breast cancer treatment\". This statement can be independently verified with credible information available online. Asma al-Assad, the wife of Syrian President Bashar al-Assad, was diagnosed with breast cancer in 2019 and underwent treatment. Reports from reputable news sources confirm her recovery.\\n\\nThe statement is logically consistent, and there are no contradictions or implausible assertions. Therefore, I conclude that the text is real, and the output is 0.'}, 'done_reason': 'stop', 'done': True, 'total_duration': 6021278481, 'load_duration': 69769316, 'prompt_eval_count': 154, 'prompt_eval_duration': 124476000, 'eval_count': 141, 'eval_duration': 5824397000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:31:32.912857337Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nThe text translates to \"Yemen school bus bombing victims frustrated by international inaction.\" This statement can be independently verified with credible news sources and reports from organizations such as the United Nations and human rights groups. The statement is also logically consistent and does not contain contradictions or implausible assertions.\\n\\nTherefore, my output is: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3390945026, 'load_duration': 28224028, 'prompt_eval_count': 161, 'prompt_eval_duration': 125747000, 'eval_count': 78, 'eval_duration': 3192278000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:31:33.919390165Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1003144428, 'load_duration': 34411680, 'prompt_eval_count': 164, 'prompt_eval_duration': 134658000, 'eval_count': 20, 'eval_duration': 789984000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:31:34.997004196Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1073500023, 'load_duration': 29958543, 'prompt_eval_count': 156, 'prompt_eval_duration': 124466000, 'eval_count': 22, 'eval_duration': 872527000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:31:37.207114417Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. The text claims that \"Avengers: Infinity War\" broke box office records, which can be independently verified with credible sources such as Box Office Mojo or IMDb.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 2206589931, 'load_duration': 29832193, 'prompt_eval_count': 162, 'prompt_eval_duration': 137302000, 'eval_count': 49, 'eval_duration': 1994750000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:31:43.057492924Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"تقارب وجهات النظر بين الولايات المتحدة و إيران\" is REAL.\\n\\nHere\\'s my analysis:\\n\\n1. Content Verification: The claim made in the content can be independently verified with other credible information available. There have been several instances of diplomatic efforts and agreements between the United States and Iran, such as the Joint Comprehensive Plan of Action (JCPOA) in 2015.\\n2. Logical Consistency: The statement is logically consistent and does not contain contradictions or implausible assertions. It is possible for the two countries to have converging views on certain issues.\\n\\nTherefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 5848017064, 'load_duration': 72482648, 'prompt_eval_count': 150, 'prompt_eval_duration': 111686000, 'eval_count': 137, 'eval_duration': 5661940000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:31:44.862130793Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"مصر تعلن عن إجراءات حماية اجتماعية هذا العام\" is real.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1801109759, 'load_duration': 27160221, 'prompt_eval_count': 153, 'prompt_eval_duration': 112017000, 'eval_count': 40, 'eval_duration': 1619101000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:31:46.102122222Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1237537466, 'load_duration': 69442217, 'prompt_eval_count': 157, 'prompt_eval_duration': 125154000, 'eval_count': 25, 'eval_duration': 998967000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:31:48.942856647Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. The text appears to be a news headline in Arabic, and a quick search online reveals that Gary Oldman did win the Best Actor award at the 2018 Cannes Film Festival, while McDormand won the Best Actress award.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 2837642244, 'load_duration': 72836397, 'prompt_eval_count': 168, 'prompt_eval_duration': 137988000, 'eval_count': 63, 'eval_duration': 2582020000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:31:49.990083929Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1043978342, 'load_duration': 29089515, 'prompt_eval_count': 165, 'prompt_eval_duration': 137326000, 'eval_count': 20, 'eval_duration': 790312000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:31:54.935509413Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text is:\\n\\n**Fake**\\n\\nOutput: **1**\\n\\nReasoning:\\n\\n* Content Verification: The claim made in the content cannot be independently verified with other credible information available. There is no historical record of a significant event or agreement between Europe and Japan to help Trump.\\n* Logical Consistency: The statement contains an implausible assertion, as it is unlikely that Europe and Japan would collaborate on a historic event solely to assist Trump.\\n\\nBased on these points, I conclude that the text is fake.'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4942844282, 'load_duration': 73388697, 'prompt_eval_count': 154, 'prompt_eval_duration': 124050000, 'eval_count': 115, 'eval_duration': 4743031000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:31:57.92085211Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nThe text translates to \"El-Sisi took the constitutional oath as president of the country for a second term.\" This claim can be independently verified with credible information available, and the statement is logically consistent without any contradictions or implausible assertions.\\n\\nTherefore, the output is: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 2981984577, 'load_duration': 29917893, 'prompt_eval_count': 160, 'prompt_eval_duration': 125268000, 'eval_count': 68, 'eval_duration': 2784637000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:31:59.818076435Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"مصر ترحب بعودة السوداني الصادق المهدي\" is real. Therefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1893652145, 'load_duration': 29106575, 'prompt_eval_count': 151, 'prompt_eval_duration': 111246000, 'eval_count': 41, 'eval_duration': 1659991000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:32:01.000081046Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is real. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1179434449, 'load_duration': 69461597, 'prompt_eval_count': 152, 'prompt_eval_duration': 111358000, 'eval_count': 25, 'eval_duration': 996016000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:32:02.005634842Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1002285385, 'load_duration': 31316448, 'prompt_eval_count': 163, 'prompt_eval_duration': 136532000, 'eval_count': 20, 'eval_duration': 790220000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:32:05.603875447Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified without additional context or information. The text appears to be in Arabic and translates to \"Saudi Arabia lifts ban on Egyptian imports.\" \\n\\nWithout further evidence or credible sources to support this claim, it is difficult to determine its authenticity. Therefore, based on the available information, I conclude that the output should be:\\n\\n1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3595581473, 'load_duration': 73740076, 'prompt_eval_count': 149, 'prompt_eval_duration': 110842000, 'eval_count': 83, 'eval_duration': 3407778000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:32:06.603704731Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 996554034, 'load_duration': 28817526, 'prompt_eval_count': 165, 'prompt_eval_duration': 134706000, 'eval_count': 20, 'eval_duration': 790127000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:32:11.170452374Z', 'message': {'role': 'assistant', 'content': \"After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nHere's my analysis:\\n\\n1. Content Verification: The claim made in the content can be independently verified with other credible information available. There have been reports of clashes and casualties near Hodeidah in Yemen from various news sources.\\n2. Logical Consistency: The statement appears to be logically consistent, and there are no apparent contradictions or implausible assertions.\\n\\nBased on this analysis, I conclude that the text is REAL.\\n\\nOutput: 0\"}, 'done_reason': 'stop', 'done': True, 'total_duration': 4564561710, 'load_duration': 72123020, 'prompt_eval_count': 156, 'prompt_eval_duration': 124481000, 'eval_count': 106, 'eval_duration': 4365798000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:32:12.238345211Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL.\\n\\nOutput: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1065054715, 'load_duration': 31951977, 'prompt_eval_count': 153, 'prompt_eval_duration': 111609000, 'eval_count': 22, 'eval_duration': 871968000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:32:13.435430022Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL. Therefore, the output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1194011290, 'load_duration': 30157843, 'prompt_eval_count': 157, 'prompt_eval_duration': 124145000, 'eval_count': 25, 'eval_duration': 996564000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:32:17.334278708Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nThe text translates to \"The United States threatens to impose the harshest sanctions in history on Iran.\" This claim can be independently verified with other credible information available, as there have been numerous reports and statements from US officials threatening to impose severe sanctions on Iran.\\n\\nAdditionally, the statement is logically consistent and does not contain contradictions or implausible assertions.\\n\\nTherefore, my output is: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3895455676, 'load_duration': 28880396, 'prompt_eval_count': 159, 'prompt_eval_duration': 124637000, 'eval_count': 90, 'eval_duration': 3698913000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:32:22.266053318Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified as it appears to be a phrase in Arabic with no specific claims or assertions that can be independently verified.\\n\\nHowever, based on my understanding, the text \"مشاركة كبيرة فى الانتخاب الرئاسية المصرية\" translates to \"Large participation in the Egyptian presidential election\". This statement seems logically consistent and does not contain any obvious contradictions or implausible assertions.\\n\\nGiven this analysis, I conclude that the text is likely real. Therefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4928880959, 'load_duration': 31269799, 'prompt_eval_count': 149, 'prompt_eval_duration': 112003000, 'eval_count': 114, 'eval_duration': 4700606000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:32:25.624161705Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified without additional context or information. The text appears to be a news headline in Arabic, but without further investigation, it is difficult to determine its accuracy.\\n\\nHowever, based on the language and structure of the sentence, it seems plausible and logically consistent. Therefore, I will output:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3355865804, 'load_duration': 69698877, 'prompt_eval_count': 154, 'prompt_eval_duration': 124366000, 'eval_count': 77, 'eval_duration': 3159502000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:32:29.399902809Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL.\\n\\nThe text translates to \"El-Sisi seized the opportunity and we will become a regional energy hub.\" This statement appears to be a quote from Abdel Fattah el-Sisi, the President of Egypt, and can be verified through various credible news sources. The claim is logically consistent and does not contain contradictions or implausible assertions.\\n\\nTherefore, my output is: 0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3772517383, 'load_duration': 30969800, 'prompt_eval_count': 159, 'prompt_eval_duration': 125597000, 'eval_count': 87, 'eval_duration': 3571442000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:32:34.533989341Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text \"موسيقى صوفية جذورها أفريقية في المغرب\" is REAL.\\n\\nHere\\'s my analysis:\\n\\n1. Content Verification: The claim made in the content can be independently verified with other credible information available. Sufi music has a rich history and cultural significance in Morocco, and it is widely acknowledged that African influences have shaped Moroccan music.\\n2. Logical Consistency: The statement is logically consistent and does not contain contradictions or implausible assertions.\\n\\nBased on this analysis, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 5130931241, 'load_duration': 29614054, 'prompt_eval_count': 152, 'prompt_eval_duration': 111509000, 'eval_count': 119, 'eval_duration': 4905962000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:32:37.752082564Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified without more context or information. The text appears to be in Arabic and translates to \"American warning about Germany\\'s economic policies.\" However, without additional context or evidence, it is difficult to determine whether this statement is real or fake.\\n\\nOutput: 1 (fake)'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3215624270, 'load_duration': 65584289, 'prompt_eval_count': 151, 'prompt_eval_duration': 111550000, 'eval_count': 74, 'eval_duration': 3033860000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:32:39.285283892Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text cannot be verified with credible information available. Therefore, my output is:\\n\\n1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1530253056, 'load_duration': 30273541, 'prompt_eval_count': 154, 'prompt_eval_duration': 124325000, 'eval_count': 33, 'eval_duration': 1329211000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:32:40.357111403Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is fake.\\n\\nOutput: 1'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1069648507, 'load_duration': 70521815, 'prompt_eval_count': 156, 'prompt_eval_duration': 124558000, 'eval_count': 22, 'eval_duration': 872426000}\n",
      "1\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:32:41.594034094Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the text is REAL. Therefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1234843467, 'load_duration': 27699269, 'prompt_eval_count': 157, 'prompt_eval_duration': 124728000, 'eval_count': 25, 'eval_duration': 996740000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:32:45.478078194Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement using the provided steps, I determined that the authenticity of the text is:\\n\\n**Real**\\n\\nThe claim made in the content can be independently verified with other credible information available. The statement \"موسيقى صوفية جذورها أفريقية في لبنان\" translates to \"Sufi music has African roots in Lebanon\", which is a plausible and consistent assertion.\\n\\nTherefore, my output is:\\n\\n**0**'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3882034016, 'load_duration': 70007487, 'prompt_eval_count': 153, 'prompt_eval_duration': 111501000, 'eval_count': 89, 'eval_duration': 3657183000}\n",
      "0\n",
      "{'model': 'llama3:70b', 'created_at': '2024-07-26T01:32:46.526493724Z', 'message': {'role': 'assistant', 'content': 'After analyzing the statement, I determined that it is REAL. Therefore, my output is:\\n\\n0'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1046369206, 'load_duration': 73913845, 'prompt_eval_count': 162, 'prompt_eval_duration': 136990000, 'eval_count': 20, 'eval_duration': 790584000}\n",
      "0\n",
      "Accuracy: 0.618421052631579\n",
      "Precision: 0.4154929577464789\n",
      "Recall: 0.3933333333333333\n",
      "F1 Score: 0.4041095890410959\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "accuracy, precision, recall, f1, predicted_ans_zs_cot = calculate_metrics(df_ans_zs_cot, params)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UqFTHoAut2C3",
    "outputId": "4bf1c3da-d0d2-4d47-c861-79f3dbc86087"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_ans_zs_cot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "VPaLYD-Ut7GQ"
   },
   "outputs": [],
   "source": [
    "predicted_ans_zs_cot = [0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZjxOsyVwxJS"
   },
   "source": [
    "### Few Shots Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "YiR6OWMNxYwh"
   },
   "outputs": [],
   "source": [
    "df_ans_fs = pd.read_csv('./datasets/ANS/train.csv')\n",
    "\n",
    "# Initialize a list to store the prompts\n",
    "prompts = []\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in df_ans_fs.iterrows():\n",
    "    sentence = row['claim_s']\n",
    "    fake_flag = row['fake_flag']\n",
    "\n",
    "    # Generate prompt based on each row\n",
    "    prompt = f\"\"\"Text: {sentence}\n",
    "\n",
    "Answer: {fake_flag}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    # Append the prompt along with sentence and fake flag to the list\n",
    "    prompts.append((sentence, fake_flag, prompt))\n",
    "\n",
    "# Convert the list of prompts into a new DataFrame\n",
    "prompts_df_ans_fs = pd.DataFrame(prompts, columns=['Sentence', 'Fake Flag', 'Prompt'])\n",
    "\n",
    "# Save the prompts DataFrame to a new CSV file\n",
    "prompts_df_ans_fs.to_csv('prompts_df_ans_fs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "nGo7yppizZEO",
    "outputId": "43ce1fc8-0f16-4693-ffe9-dcf29a06062f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Fake Flag</th>\n",
       "      <th>Prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>تراجع التضخم النصف سنوي في الجزائر</td>\n",
       "      <td>1</td>\n",
       "      <td>Text: تراجع التضخم النصف سنوي في الجزائر\\n\\nAn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>صكوك من الكويت بملياري دولار</td>\n",
       "      <td>1</td>\n",
       "      <td>Text: صكوك من الكويت بملياري دولار\\n\\nAnswer: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>الحرب في سوريا: قافلة الإغاثة المرتقبة لن تتمك...</td>\n",
       "      <td>0</td>\n",
       "      <td>Text: الحرب في سوريا: قافلة الإغاثة المرتقبة ل...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>الأساطير المحيطة بالممثلين المجوس في مصر تتحطم...</td>\n",
       "      <td>1</td>\n",
       "      <td>Text: الأساطير المحيطة بالممثلين المجوس في مصر...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>مصر: مجلس النواب يقر حصانة قضائية لضباط كبار ب...</td>\n",
       "      <td>0</td>\n",
       "      <td>Text: مصر: مجلس النواب يقر حصانة قضائية لضباط ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3180</th>\n",
       "      <td>رسّامة جزائرية: لا أرسم خيالا، بل حقيقة</td>\n",
       "      <td>0</td>\n",
       "      <td>Text: رسّامة جزائرية: لا أرسم خيالا، بل حقيقة\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3181</th>\n",
       "      <td>مصر.. ارتفاع قياسي جديد للاحتياطي الأجنبي</td>\n",
       "      <td>0</td>\n",
       "      <td>Text: مصر.. ارتفاع قياسي جديد للاحتياطي الأجنب...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3182</th>\n",
       "      <td>السعودية تُسارع بشراء  إيرباص</td>\n",
       "      <td>1</td>\n",
       "      <td>Text: السعودية تُسارع بشراء  إيرباص\\n\\nAnswer:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3183</th>\n",
       "      <td>الأسهم الخليجية ترتفع</td>\n",
       "      <td>0</td>\n",
       "      <td>Text: الأسهم الخليجية ترتفع\\n\\nAnswer: 0\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3184</th>\n",
       "      <td>السغودية: بدء تشغيل قطار الحرمين</td>\n",
       "      <td>0</td>\n",
       "      <td>Text: السغودية: بدء تشغيل قطار الحرمين\\n\\nAnsw...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3185 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence  Fake Flag  \\\n",
       "0                    تراجع التضخم النصف سنوي في الجزائر          1   \n",
       "1                          صكوك من الكويت بملياري دولار          1   \n",
       "2     الحرب في سوريا: قافلة الإغاثة المرتقبة لن تتمك...          0   \n",
       "3     الأساطير المحيطة بالممثلين المجوس في مصر تتحطم...          1   \n",
       "4     مصر: مجلس النواب يقر حصانة قضائية لضباط كبار ب...          0   \n",
       "...                                                 ...        ...   \n",
       "3180            رسّامة جزائرية: لا أرسم خيالا، بل حقيقة          0   \n",
       "3181          مصر.. ارتفاع قياسي جديد للاحتياطي الأجنبي          0   \n",
       "3182                      السعودية تُسارع بشراء  إيرباص          1   \n",
       "3183                              الأسهم الخليجية ترتفع          0   \n",
       "3184                   السغودية: بدء تشغيل قطار الحرمين          0   \n",
       "\n",
       "                                                 Prompt  \n",
       "0     Text: تراجع التضخم النصف سنوي في الجزائر\\n\\nAn...  \n",
       "1     Text: صكوك من الكويت بملياري دولار\\n\\nAnswer: ...  \n",
       "2     Text: الحرب في سوريا: قافلة الإغاثة المرتقبة ل...  \n",
       "3     Text: الأساطير المحيطة بالممثلين المجوس في مصر...  \n",
       "4     Text: مصر: مجلس النواب يقر حصانة قضائية لضباط ...  \n",
       "...                                                 ...  \n",
       "3180  Text: رسّامة جزائرية: لا أرسم خيالا، بل حقيقة\\...  \n",
       "3181  Text: مصر.. ارتفاع قياسي جديد للاحتياطي الأجنب...  \n",
       "3182  Text: السعودية تُسارع بشراء  إيرباص\\n\\nAnswer:...  \n",
       "3183       Text: الأسهم الخليجية ترتفع\\n\\nAnswer: 0\\n\\n  \n",
       "3184  Text: السغودية: بدء تشغيل قطار الحرمين\\n\\nAnsw...  \n",
       "\n",
       "[3185 rows x 3 columns]"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts_df_ans_fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WCD8_L291Pdb"
   },
   "source": [
    "#### 8 Shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RmtfzEBV3Waw",
    "outputId": "24c98d14-32e3-4cc4-ff6c-454c222dc190"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: تراجع التضخم النصف سنوي في الجزائر\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: صكوك من الكويت بملياري دولار\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: الحرب في سوريا: قافلة الإغاثة المرتقبة لن تتمكن من دخول الغوطة الشرقية\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: الأساطير المحيطة بالممثلين المجوس في مصر تتحطم على يد المؤرخ السينمائي أشرف غريب\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: مصر: مجلس النواب يقر حصانة قضائية لضباط كبار بالجيش بعد عزل مرسي\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: بتكوين تخسر مجدداً\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: الليرة التركية تنحدر مجدداً\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: هل استطاع الموساد اختراق أسرار إيران النووية؟\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shots_8 = '\\n'.join(prompts_df_ans_fs.iloc[:8, 2].astype(str))\n",
    "print(shots_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "3x1F6158xD3b"
   },
   "outputs": [],
   "source": [
    "# Define function to calculate metrics\n",
    "def calculate_metrics(test_set, params):\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    passed = 0\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in test_set.iterrows():\n",
    "        sentence = row[\"claim_s\"]\n",
    "        actual_label = row[\"fake_flag\"]\n",
    "\n",
    "        # Generate prompt based on each row\n",
    "        prompt = f\"\"\"Determine whether the following text is real or fake. if real then output = 0 and if fake then output = 1. Output must be integer 0 or 1 alone. No text.\n",
    "\n",
    "{shots_8}\n",
    "\n",
    "Text: {sentence}\n",
    "\n",
    "Answer:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "        # Call the get_completion function with prompt and params\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        response = get_completion(params, messages)\n",
    "        content = response.get(\"message\").get(\"content\")\n",
    "        predicted_label = get_prediction(content)\n",
    "        none_count = 0\n",
    "        \n",
    "        if predicted_label is not None:\n",
    "            true_labels.append(actual_label)\n",
    "            predicted_labels.append(predicted_label)\n",
    "        else:\n",
    "            none_count += 1 \n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels)\n",
    "    recall = recall_score(true_labels, predicted_labels)\n",
    "    f1 = f1_score(true_labels, predicted_labels)\n",
    "\n",
    "    return accuracy, precision, recall, f1, predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ljiQndG806MK",
    "outputId": "28cc46e3-a763-4b38-905f-37cce9111a83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6140350877192983\n",
      "Precision: 0.4155844155844156\n",
      "Recall: 0.4266666666666667\n",
      "F1 Score: 0.42105263157894735\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "accuracy, precision, recall, f1, predicted_ans_fs_8 = calculate_metrics(df_ans_zs, params)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_ans_fs_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ans_fs_8 = [0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LOSyELDH1eVT"
   },
   "source": [
    "#### 16 Shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9phvaGGU2ASB",
    "outputId": "5c2e317f-1c76-4da7-dc1c-588d4e5efdb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: تراجع التضخم النصف سنوي في الجزائر\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: صكوك من الكويت بملياري دولار\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: الحرب في سوريا: قافلة الإغاثة المرتقبة لن تتمكن من دخول الغوطة الشرقية\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: الأساطير المحيطة بالممثلين المجوس في مصر تتحطم على يد المؤرخ السينمائي أشرف غريب\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: مصر: مجلس النواب يقر حصانة قضائية لضباط كبار بالجيش بعد عزل مرسي\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: بتكوين تخسر مجدداً\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: الليرة التركية تنحدر مجدداً\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: هل استطاع الموساد اختراق أسرار إيران النووية؟\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: أسواق إيران توقف إضرابها\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: مفتشو منظمة حظر الأسلحة الكيمياوية في دوما السورية\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: انفجار في مصنع للكيماويات قرب مطار القاهرة بالعاصمة المصرية\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: الوكالة الكورية للغاز توقع مذكرة تفاهم مع شركة إماراتية\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: أوسكار تضيف جائزة جديدة لأفضل فيلم جماهيري\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: أسواق النفط تتفادى المونديال\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: محطة تلفزيون تتهم مسؤولا يابانيا كبيرا بالتحرش بإحدى صحفياتها\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: افتتاح مهرجان لندن السينمائي من قبل بناتستيف ماكوين\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shots_16 = '\\n'.join(prompts_df_ans_fs.iloc[:16, 2].astype(str))\n",
    "print(shots_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "y9djJ5gd1dhr"
   },
   "outputs": [],
   "source": [
    "# Define function to calculate metrics\n",
    "def calculate_metrics(test_set, params):\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    passed = 0\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in test_set.iterrows():\n",
    "        sentence = row[\"claim_s\"]\n",
    "        actual_label = row[\"fake_flag\"]\n",
    "\n",
    "        # Generate prompt based on each row\n",
    "        prompt = f\"\"\"Determine whether the following text is real or fake. if real then output = 0 and if fake then output = 1. Output must be integer 0 or 1 alone. No text.\n",
    "\n",
    "{shots_16}\n",
    "\n",
    "Text: {sentence}\n",
    "\n",
    "Answer:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "        # Call the get_completion function with prompt and params\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        response = get_completion(params, messages)\n",
    "        content = response.get(\"message\").get(\"content\")\n",
    "        predicted_label = get_prediction(content)\n",
    "        none_count = 0\n",
    "        \n",
    "        if predicted_label is not None:\n",
    "            true_labels.append(actual_label)\n",
    "            predicted_labels.append(predicted_label)\n",
    "        else:\n",
    "            none_count += 1 \n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels)\n",
    "    recall = recall_score(true_labels, predicted_labels)\n",
    "    f1 = f1_score(true_labels, predicted_labels)\n",
    "\n",
    "    return accuracy, precision, recall, f1, predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0YuXN7Lg1lvD",
    "outputId": "aac18190-93da-4de7-f891-213de6fcb09b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5482456140350878\n",
      "Precision: 0.36792452830188677\n",
      "Recall: 0.52\n",
      "F1 Score: 0.430939226519337\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "accuracy, precision, recall, f1, predicted_ans_fs_16 = calculate_metrics(df_ans_zs, params)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_ans_fs_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ans_fs_16 = [0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uGppidLd1n_b"
   },
   "source": [
    "#### 32 Shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SC6kE4Ma1niR",
    "outputId": "14efaeb8-bef3-4dc3-9a08-f43d82842202"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: تراجع التضخم النصف سنوي في الجزائر\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: صكوك من الكويت بملياري دولار\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: الحرب في سوريا: قافلة الإغاثة المرتقبة لن تتمكن من دخول الغوطة الشرقية\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: الأساطير المحيطة بالممثلين المجوس في مصر تتحطم على يد المؤرخ السينمائي أشرف غريب\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: مصر: مجلس النواب يقر حصانة قضائية لضباط كبار بالجيش بعد عزل مرسي\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: بتكوين تخسر مجدداً\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: الليرة التركية تنحدر مجدداً\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: هل استطاع الموساد اختراق أسرار إيران النووية؟\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: أسواق إيران توقف إضرابها\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: مفتشو منظمة حظر الأسلحة الكيمياوية في دوما السورية\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: انفجار في مصنع للكيماويات قرب مطار القاهرة بالعاصمة المصرية\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: الوكالة الكورية للغاز توقع مذكرة تفاهم مع شركة إماراتية\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: أوسكار تضيف جائزة جديدة لأفضل فيلم جماهيري\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: أسواق النفط تتفادى المونديال\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: محطة تلفزيون تتهم مسؤولا يابانيا كبيرا بالتحرش بإحدى صحفياتها\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: افتتاح مهرجان لندن السينمائي من قبل بناتستيف ماكوين\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: مكاسب في وول ستريت في الاسابيع الستة الاخيرة\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: السيطرة على عفرين الكردية عن طريق الحكومة السورية\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: بريطانيا تخرج من الاتحاد الجمركي الأوروبي\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: استهداف مطار في طرابلس بهجوم صاورخى و اجبار ليبيا على تغيير مسار الرحلات الجوية\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: تنديد فلسطيني بالإفراج عن جندي إسرائيلي قتل جريحا\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: اقتنصت المخابرات التركية مهاجم ريحانلى\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: صعود لليرة قبل محاكمة برونسون\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: إثر إضراب النقابات في الأردن.. الملك يأمر بتجميد زيادات أسعار الوقود\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: إيران تفرج عن مواطنة بعد اتهامها بخلع حجابها\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: ما سر اعتراف إسرائيل فى هذا الوقت بتدمير المفاعل النووي السوري؟\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: تظاهر الآلاف في المغرب تنديدا بسجن قادة الحراك الشعبي\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: زوجة نتنياهو متهم بالاحتيال وإهدار المال العام\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: جيرار ديبارديو الممثل الفرنسي الشهير يُتهم باغتصاب ممثلة شابة\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: 250 ألف جنيه إسترليني مقابل الصور الجديدة للبيتلز\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: فشل أزمة إيران في تحفيز المشتريات يؤدي إلى انخفاض الذهب\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: المسلسل الأمريكي الكوميديروزان يتوقف بعد تغريدة عن مساعدة أوباما\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shots_all = '\\n'.join(prompts_df_ans_fs.iloc[:32, 2].astype(str))\n",
    "print(shots_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "atU6KlR55o3r"
   },
   "outputs": [],
   "source": [
    "# Define function to calculate metrics\n",
    "def calculate_metrics(test_set, params):\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    passed = 0\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in test_set.iterrows():\n",
    "        sentence = row[\"claim_s\"]\n",
    "        actual_label = row[\"fake_flag\"]\n",
    "\n",
    "        # Generate prompt based on each row\n",
    "        prompt = f\"\"\"Determine whether the following text is real or fake. if real then output = 0 and if fake then output = 1. Output must be integer 0 or 1 alone. No text.\n",
    "\n",
    "{shots_all}\n",
    "\n",
    "Text: {sentence}\n",
    "\n",
    "Answer:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "        # Call the get_completion function with prompt and params\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        response = get_completion(params, messages)\n",
    "        content = response.get(\"message\").get(\"content\")\n",
    "        predicted_label = get_prediction(content)\n",
    "        none_count = 0\n",
    "        \n",
    "        if predicted_label is not None:\n",
    "            true_labels.append(actual_label)\n",
    "            predicted_labels.append(predicted_label)\n",
    "        else:\n",
    "            none_count += 1 \n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels)\n",
    "    recall = recall_score(true_labels, predicted_labels)\n",
    "    f1 = f1_score(true_labels, predicted_labels)\n",
    "\n",
    "    return accuracy, precision, recall, f1, predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qFhSgxW85tbV",
    "outputId": "8ac81d76-1d06-43b6-e951-7586ba8c78d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.34868421052631576\n",
      "Precision: 0.3318077803203661\n",
      "Recall: 0.9666666666666667\n",
      "F1 Score: 0.4940374787052811\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "accuracy, precision, recall, f1, predicted_ans_fs_32 = calculate_metrics(df_ans_zs, params)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_ans_fs_32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ans_fs_32 = [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PSvzwiSgqjIQ"
   },
   "source": [
    "# LLama (ArAiEval Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "id": "8h6fPST3qjIb"
   },
   "outputs": [],
   "source": [
    "def set_llama_params(model=\"llama3:70b\"):  # update model to your preference\n",
    "    \"\"\" set llama parameters\"\"\"\n",
    "    model_response = ollama.chat(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a llama assistant that talks like a llama, starting every word with 'll'.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Hi, happy llama day!\"},\n",
    "        ],\n",
    "        stream=False\n",
    "    )\n",
    "    return {\"model\": model_response.get(\"model\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "WWZUiGHFqjIb"
   },
   "outputs": [],
   "source": [
    "def get_completion(params, messages):\n",
    "    \"\"\" GET completion from llama model\"\"\"\n",
    "    response = None\n",
    "    payload = {\n",
    "        \"model\": params[\"model\"],\n",
    "        \"tools\": [\n",
    "            {\"functions\": [\n",
    "                {'name': 'fake_news_detection',\n",
    "                'description': 'Detect whether a given news is fake or not.',\n",
    "                'parameters': {\n",
    "                    'type': 'object',\n",
    "                    'properties': {\n",
    "                        'sentiment': {\n",
    "                            'title': 'sentiment',\n",
    "                            'type': 'string',\n",
    "                            'description': 'the sentiment encountered in the passage'\n",
    "                        },\n",
    "                        'is_fake': {\n",
    "                            'title': 'is fake',\n",
    "                            'type': 'integer',\n",
    "                            'description': 'Determine whether the text is real or fake. if real then output = 0 and if fake then output = 1. Output must be integer 0 or 1 alone.'\n",
    "                        },\n",
    "                        'language': {\n",
    "                            'title': 'language',\n",
    "                            'type': 'string',\n",
    "                            'description': 'the language of the passage'\n",
    "                        }\n",
    "                      },\n",
    "                      'required': ['sentiment', 'is_fake', 'language']\n",
    "                    },\n",
    "                    \"function_call\": {\"name\": \"fake_news_detection\"},\n",
    "                }\n",
    "            ],}\n",
    "        ],\n",
    "        \"stream\": False,\n",
    "        \"options\": {\n",
    "            \"max_tokens\": 1,\n",
    "            \"temperature\": 0.1,\n",
    "        },\n",
    "    }\n",
    "    payload[\"messages\"] = messages\n",
    "\n",
    "    model_response = ollama.chat(\n",
    "        model=payload[\"model\"],\n",
    "        messages=payload[\"messages\"],\n",
    "        #tools=payload[\"tools\"], # track this PR: https://github.com/ollama/ollama-python/pull/213\n",
    "        options=payload[\"options\"],\n",
    "        stream=False\n",
    "    )\n",
    "\n",
    "    return model_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S6qmN4GXqjIb",
    "outputId": "574773b8-b323-4ba6-b5df-6818b15c2806"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'llama3:70b'}\n"
     ]
    }
   ],
   "source": [
    "params = set_llama_params()\n",
    "\n",
    "if not params:\n",
    "  raise Exception(\"llama exception\")\n",
    "\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQIQ6tMeqjIb"
   },
   "source": [
    "## ArAiEval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DiLn7UgjqjIc"
   },
   "source": [
    "### Zero Shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "oX1WI9d1qjIc"
   },
   "outputs": [],
   "source": [
    "df_ans_zs = pd.read_excel('./datasets/ArAiEval23Excel/ArAiEval23_disinfo_subtask2A_test.xlsx')\n",
    "\n",
    "# Initialize a list to store the prompts\n",
    "prompts = []\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in df_ans_zs.iterrows():\n",
    "    sentence = row['claim_s']\n",
    "    fake_flag = row['fake_flag']\n",
    "\n",
    "    # Generate prompt based on each row\n",
    "    prompt = f\"\"\"Determine whether the following text is real or fake. If real, then output 0. If fake, then output 1. Respond with only the integer 0 or 1 and nothing else.\n",
    "\n",
    "Text: {sentence}\"\"\"\n",
    "\n",
    "    # Append the prompt along with sentence and fake flag to the list\n",
    "    prompts.append((sentence, fake_flag, prompt))\n",
    "\n",
    "# Convert the list of prompts into a new DataFrame\n",
    "prompts_df_ans_zs = pd.DataFrame(prompts, columns=['Sentence', 'Fake Flag', 'Prompt'])\n",
    "\n",
    "# Save the prompts DataFrame to a new CSV file\n",
    "prompts_df_ans_zs.to_csv('prompts_df_ans_zs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "Ze-o8JuXqjIc",
    "outputId": "075bd32c-257a-4c8d-9d7e-b9846f7d4c78"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Fake Flag</th>\n",
       "      <th>Prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>أ.د.عبدالله الفوزان : “ التباعد المؤقت بين الز...</td>\n",
       "      <td>0</td>\n",
       "      <td>Determine whether the following text is real o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>الدكتور / طلال عيسى السحل الفدعاني العنزي أحد ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Determine whether the following text is real o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#حديث_مسؤول  معالي الرئيس العام لشؤون المسجد ا...</td>\n",
       "      <td>0</td>\n",
       "      <td>Determine whether the following text is real o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#ممكن_بدايه_الحر_ينتهي_كورونا _تفريج كربه_  .....</td>\n",
       "      <td>0</td>\n",
       "      <td>Determine whether the following text is real o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#ممكن_بدايه_الحر_ينتهي_كورونا ﴿وأنفقوا من ما ر...</td>\n",
       "      <td>0</td>\n",
       "      <td>Determine whether the following text is real o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3724</th>\n",
       "      <td>يا بغلونة الصحة مسؤولية ذاتية مكانش على بالو ه...</td>\n",
       "      <td>1</td>\n",
       "      <td>Determine whether the following text is real o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3725</th>\n",
       "      <td>RT @USER التعليم الخاص، و الطب الخاص، و المهند...</td>\n",
       "      <td>0</td>\n",
       "      <td>Determine whether the following text is real o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3726</th>\n",
       "      <td>استخدم الان نون Less20💎 Luck64 Luck65 Luck66 💢...</td>\n",
       "      <td>1</td>\n",
       "      <td>Determine whether the following text is real o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3727</th>\n",
       "      <td>RT @USER ماذا تعلمت من فيروس #كورونا؟ LINK</td>\n",
       "      <td>0</td>\n",
       "      <td>Determine whether the following text is real o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3728</th>\n",
       "      <td>كورونا (كوفيد-19) يكتسح أوروبا ويواصل حصد أروا...</td>\n",
       "      <td>0</td>\n",
       "      <td>Determine whether the following text is real o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3729 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence  Fake Flag  \\\n",
       "0     أ.د.عبدالله الفوزان : “ التباعد المؤقت بين الز...          0   \n",
       "1     الدكتور / طلال عيسى السحل الفدعاني العنزي أحد ...          0   \n",
       "2     #حديث_مسؤول  معالي الرئيس العام لشؤون المسجد ا...          0   \n",
       "3     #ممكن_بدايه_الحر_ينتهي_كورونا _تفريج كربه_  .....          0   \n",
       "4     #ممكن_بدايه_الحر_ينتهي_كورونا ﴿وأنفقوا من ما ر...          0   \n",
       "...                                                 ...        ...   \n",
       "3724  يا بغلونة الصحة مسؤولية ذاتية مكانش على بالو ه...          1   \n",
       "3725  RT @USER التعليم الخاص، و الطب الخاص، و المهند...          0   \n",
       "3726  استخدم الان نون Less20💎 Luck64 Luck65 Luck66 💢...          1   \n",
       "3727         RT @USER ماذا تعلمت من فيروس #كورونا؟ LINK          0   \n",
       "3728  كورونا (كوفيد-19) يكتسح أوروبا ويواصل حصد أروا...          0   \n",
       "\n",
       "                                                 Prompt  \n",
       "0     Determine whether the following text is real o...  \n",
       "1     Determine whether the following text is real o...  \n",
       "2     Determine whether the following text is real o...  \n",
       "3     Determine whether the following text is real o...  \n",
       "4     Determine whether the following text is real o...  \n",
       "...                                                 ...  \n",
       "3724  Determine whether the following text is real o...  \n",
       "3725  Determine whether the following text is real o...  \n",
       "3726  Determine whether the following text is real o...  \n",
       "3727  Determine whether the following text is real o...  \n",
       "3728  Determine whether the following text is real o...  \n",
       "\n",
       "[3729 rows x 3 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts_df_ans_zs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "id": "IDoGy9PdqjIc"
   },
   "outputs": [],
   "source": [
    "# Define function to calculate metrics\n",
    "def calculate_metrics(test_set, params):\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in test_set.iterrows():\n",
    "        #sentence = row[\"claim_s\"]\n",
    "        sentence = re.sub(r'[\\W_]+', ' ', row[\"claim_s\"])\n",
    "        actual_label = row[\"fake_flag\"]\n",
    "\n",
    "        # Generate prompt based on each row\n",
    "        prompt = f\"\"\"Determine whether the following text is real or fake. if real then output = 0 and if fake then output = 1. Output must be integer 0 or 1 alone. No text.\n",
    "\n",
    "Text: {sentence}\"\"\"\n",
    "\n",
    "        # Call the get_completion function with prompt and params\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        response = get_completion(params, messages)\n",
    "        content = response.get(\"message\").get(\"content\")\n",
    "        predicted_label = get_prediction(content)\n",
    "        none_count = 0\n",
    "        \n",
    "        if predicted_label is not None:\n",
    "            true_labels.append(actual_label)\n",
    "            predicted_labels.append(predicted_label)\n",
    "        else:\n",
    "            none_count += 1 \n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels)\n",
    "    recall = recall_score(true_labels, predicted_labels)\n",
    "    f1 = f1_score(true_labels, predicted_labels)\n",
    "\n",
    "    return accuracy, precision, recall, f1, predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gNDhOwhbqjIc",
    "outputId": "b1aac761-9fcc-44d0-d5e2-8ef67c44be9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7200321802091714\n",
      "Precision: 0.43823529411764706\n",
      "Recall: 0.680365296803653\n",
      "F1 Score: 0.5330948121645797\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "accuracy_zs, precision_zs, recall_zs, f1_zs, predicted_ara_zs = calculate_metrics(df_ans_zs, params)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_zs)\n",
    "print(\"Precision:\", precision_zs)\n",
    "print(\"Recall:\", recall_zs)\n",
    "print(\"F1 Score:\", f1_zs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_ara_zs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ara_zs = [0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yfo7dITORp-H"
   },
   "source": [
    "### Zero Shot CoT Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "DJwi5uy3Rp-R"
   },
   "outputs": [],
   "source": [
    "df_ara_zs_cot = pd.read_excel('./datasets/ArAiEval23Excel/ArAiEval23_disinfo_subtask2A_test.xlsx')\n",
    "\n",
    "# Initialize a list to store the prompts\n",
    "prompts = []\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in df_ara_zs_cot.iterrows():\n",
    "    sentence = row['claim_s']\n",
    "    fake_flag = row['fake_flag']\n",
    "\n",
    "    # Generate prompt based on each row (CoT)\n",
    "    prompt = f\"\"\"Analyze the following statement to determine its authenticity by considering these steps:\n",
    "              1. Content Verification: Check if the claims made in the content can be independently verified with other credible information available.\n",
    "              2. Logical Consistency: Assess whether the statement is logically consistent and whether it contains contradictions or implausible assertions.\n",
    "\n",
    "              After carefully considering these points, conclude whether the statement is more likely true or false. If you determine the statement is true, output '0'. If you determine it is false, output '1'. Provide the output as a single integer, without additional explanation.\n",
    "\n",
    "              Text: {sentence}\n",
    "\n",
    "              Answer:\"\"\"\n",
    "\n",
    "    # Append the prompt along with sentence and fake flag to the list\n",
    "    prompts.append((sentence, fake_flag, prompt))\n",
    "\n",
    "# Convert the list of prompts into a new DataFrame\n",
    "prompts_df_ara_zs_cot = pd.DataFrame(prompts, columns=['Sentence', 'Fake Flag', 'Prompt'])\n",
    "\n",
    "# Save the prompts DataFrame to a new CSV file\n",
    "prompts_df_ara_zs_cot.to_csv('prompts_df_ara_zs_cot.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "349Bdkw-Rp-S",
    "outputId": "c6a11613-6594-4598-f4da-2aa6ae212746"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Fake Flag</th>\n",
       "      <th>Prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>أ.د.عبدالله الفوزان : “ التباعد المؤقت بين الز...</td>\n",
       "      <td>0</td>\n",
       "      <td>Analyze the following statement to determine i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>الدكتور / طلال عيسى السحل الفدعاني العنزي أحد ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Analyze the following statement to determine i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#حديث_مسؤول  معالي الرئيس العام لشؤون المسجد ا...</td>\n",
       "      <td>0</td>\n",
       "      <td>Analyze the following statement to determine i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#ممكن_بدايه_الحر_ينتهي_كورونا _تفريج كربه_  .....</td>\n",
       "      <td>0</td>\n",
       "      <td>Analyze the following statement to determine i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#ممكن_بدايه_الحر_ينتهي_كورونا ﴿وأنفقوا من ما ر...</td>\n",
       "      <td>0</td>\n",
       "      <td>Analyze the following statement to determine i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3724</th>\n",
       "      <td>يا بغلونة الصحة مسؤولية ذاتية مكانش على بالو ه...</td>\n",
       "      <td>1</td>\n",
       "      <td>Analyze the following statement to determine i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3725</th>\n",
       "      <td>RT @USER التعليم الخاص، و الطب الخاص، و المهند...</td>\n",
       "      <td>0</td>\n",
       "      <td>Analyze the following statement to determine i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3726</th>\n",
       "      <td>استخدم الان نون Less20💎 Luck64 Luck65 Luck66 💢...</td>\n",
       "      <td>1</td>\n",
       "      <td>Analyze the following statement to determine i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3727</th>\n",
       "      <td>RT @USER ماذا تعلمت من فيروس #كورونا؟ LINK</td>\n",
       "      <td>0</td>\n",
       "      <td>Analyze the following statement to determine i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3728</th>\n",
       "      <td>كورونا (كوفيد-19) يكتسح أوروبا ويواصل حصد أروا...</td>\n",
       "      <td>0</td>\n",
       "      <td>Analyze the following statement to determine i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3729 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence  Fake Flag  \\\n",
       "0     أ.د.عبدالله الفوزان : “ التباعد المؤقت بين الز...          0   \n",
       "1     الدكتور / طلال عيسى السحل الفدعاني العنزي أحد ...          0   \n",
       "2     #حديث_مسؤول  معالي الرئيس العام لشؤون المسجد ا...          0   \n",
       "3     #ممكن_بدايه_الحر_ينتهي_كورونا _تفريج كربه_  .....          0   \n",
       "4     #ممكن_بدايه_الحر_ينتهي_كورونا ﴿وأنفقوا من ما ر...          0   \n",
       "...                                                 ...        ...   \n",
       "3724  يا بغلونة الصحة مسؤولية ذاتية مكانش على بالو ه...          1   \n",
       "3725  RT @USER التعليم الخاص، و الطب الخاص، و المهند...          0   \n",
       "3726  استخدم الان نون Less20💎 Luck64 Luck65 Luck66 💢...          1   \n",
       "3727         RT @USER ماذا تعلمت من فيروس #كورونا؟ LINK          0   \n",
       "3728  كورونا (كوفيد-19) يكتسح أوروبا ويواصل حصد أروا...          0   \n",
       "\n",
       "                                                 Prompt  \n",
       "0     Analyze the following statement to determine i...  \n",
       "1     Analyze the following statement to determine i...  \n",
       "2     Analyze the following statement to determine i...  \n",
       "3     Analyze the following statement to determine i...  \n",
       "4     Analyze the following statement to determine i...  \n",
       "...                                                 ...  \n",
       "3724  Analyze the following statement to determine i...  \n",
       "3725  Analyze the following statement to determine i...  \n",
       "3726  Analyze the following statement to determine i...  \n",
       "3727  Analyze the following statement to determine i...  \n",
       "3728  Analyze the following statement to determine i...  \n",
       "\n",
       "[3729 rows x 3 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts_df_ara_zs_cot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "se-vuYT6Rp-S"
   },
   "outputs": [],
   "source": [
    "# Define function to calculate metrics\n",
    "def calculate_metrics(test_set, params):\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in test_set.iterrows():\n",
    "        sentence = re.sub(r'[\\W_]+', ' ', row[\"claim_s\"])\n",
    "        actual_label = row[\"fake_flag\"]\n",
    "\n",
    "        # Generate prompt based on each row (CoT)\n",
    "        prompt = f\"\"\"The output of this prompt must at length 1 with two possible values 0 or 1:\n",
    "        \n",
    "        \n",
    "                  Analyze the following statement to determine its authenticity by considering these steps:\n",
    "                  1. Content Verification: Check if the claims made in the content can be independently verified with other credible information available.\n",
    "                  2. Logical Consistency: Assess whether the statement is logically consistent and whether it contains contradictions or implausible assertions.\n",
    "                  \n",
    "                  After carefully considering these points, determine whether the following text is real or fake. if real then output = 0 and if fake then output = 1\n",
    "                  \n",
    "                  Text: {sentence}\n",
    "\n",
    "                  Answer:\"\"\"\n",
    "\n",
    "        # Call the get_completion function with prompt and params\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        response = get_completion(params, messages)\n",
    "        content = response.get(\"message\").get(\"content\")\n",
    "        predicted_label = get_prediction(content)\n",
    "        none_count = 0\n",
    "        \n",
    "        if predicted_label is not None:\n",
    "            true_labels.append(actual_label)\n",
    "            predicted_labels.append(predicted_label)\n",
    "        else:\n",
    "            none_count += 1 \n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels)\n",
    "    recall = recall_score(true_labels, predicted_labels)\n",
    "    f1 = f1_score(true_labels, predicted_labels)\n",
    "\n",
    "    return accuracy, precision, recall, f1, predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HbsCMxy_Rp-T",
    "outputId": "f47479e9-90a3-4308-9504-1acc93c773e7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.621244635193133\n",
      "Precision: 0.36308006119326874\n",
      "Recall: 0.8137142857142857\n",
      "F1 Score: 0.5021156558533145\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "accuracy_ara_zh_cot, precision_ara_zh_cot, recall_ara_zh_cot, f1_ara_zh_cot, predicted_ara_zh_cot = calculate_metrics(df_ara_zs_cot, params)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_ara_zh_cot)\n",
    "print(\"Precision:\", precision_ara_zh_cot)\n",
    "print(\"Recall:\", recall_ara_zh_cot)\n",
    "print(\"F1 Score:\", f1_ara_zh_cot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_ara_zh_cot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ara_zh_cot = [0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few Shots Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read the files with encoding: utf-8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1302/366100206.py:28: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_train['fake_flag'] = df_train['fake_flag'].replace({'disinfo': 1, 'no-disinfo': 0})\n",
      "/tmp/ipykernel_1302/366100206.py:29: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_test['fake_flag'] = df_test['fake_flag'].replace({'disinfo': 1, 'no-disinfo': 0})\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "train_file_path = './datasets/ArAiEval23Json/ArAiEval23_disinfo_subtask2A_train.jsonl'\n",
    "test_file_path = './datasets/ArAiEval23Json/ArAiEval23_disinfo_subtask2A_test.jsonl'\n",
    "\n",
    "# Try reading the file with different encodings\n",
    "encodings = ['utf-8', 'utf-16', 'cp1256']\n",
    "\n",
    "for encoding in encodings:\n",
    "    try:\n",
    "        df_train = pd.read_json(train_file_path, lines=True, encoding=encoding)\n",
    "        df_test = pd.read_json(test_file_path, lines=True, encoding=encoding)\n",
    "        print(f\"Successfully read the files with encoding: {encoding}\")\n",
    "        break\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"Failed to read the files with encoding {encoding}: {e}\")\n",
    "\n",
    "# Remove the 'id' column if the DataFrames were successfully read\n",
    "if 'df_train' in locals() and 'df_test' in locals():\n",
    "    # Remove the 'id' column\n",
    "    df_train = df_train.drop(columns=['id'])\n",
    "    df_test = df_test.drop(columns=['id'])\n",
    "\n",
    "    # Rename columns\n",
    "    df_train = df_train.rename(columns={'text': 'claim_s', 'label': 'fake_flag'})\n",
    "    df_test = df_test.rename(columns={'text': 'claim_s', 'label': 'fake_flag'})\n",
    "\n",
    "    # Replace values in the 'fake_flag' column\n",
    "    df_train['fake_flag'] = df_train['fake_flag'].replace({'disinfo': 1, 'no-disinfo': 0})\n",
    "    df_test['fake_flag'] = df_test['fake_flag'].replace({'disinfo': 1, 'no-disinfo': 0})\n",
    "\n",
    "else:\n",
    "    print(\"Failed to read the files with all attempted encodings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ara_fs = df_train.copy()\n",
    "df_ara_zs = df_test.copy()\n",
    "\n",
    "# Initialize a list to store the prompts\n",
    "prompts = []\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in df_ara_fs.iterrows():\n",
    "    sentence = row['claim_s']\n",
    "    fake_flag = row['fake_flag']\n",
    "\n",
    "    # Generate prompt based on each row\n",
    "    prompt = f\"\"\"Text: {sentence}\n",
    "\n",
    "Answer: {fake_flag}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    # Append the prompt along with sentence and fake flag to the list\n",
    "    prompts.append((sentence, fake_flag, prompt))\n",
    "\n",
    "# Convert the list of prompts into a new DataFrame\n",
    "prompts_df_ara_fs = pd.DataFrame(prompts, columns=['Sentence', 'Fake Flag', 'Prompt'])\n",
    "\n",
    "# Save the prompts DataFrame to a new CSV file\n",
    "prompts_df_ara_fs.to_csv('prompts_df_ara_fs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Fake Flag</th>\n",
       "      <th>Prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>والناس بتقولك أنتم بتلعنوا في الصين ليه ؟ دي ب...</td>\n",
       "      <td>1</td>\n",
       "      <td>Text: والناس بتقولك أنتم بتلعنوا في الصين ليه ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>عندما ضرب #فيروس_كورونا الصين قالوا عنه عقوبه ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Text: عندما ضرب #فيروس_كورونا الصين قالوا عنه ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>عاجل | إيقاف الدوري السويسري لأجل غير مسمى ، ب...</td>\n",
       "      <td>0</td>\n",
       "      <td>Text: عاجل | إيقاف الدوري السويسري لأجل غير مس...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @USER #نزل_وزنك_اثناء_العزل_من_كورونا ايه ط...</td>\n",
       "      <td>0</td>\n",
       "      <td>Text: RT @USER #نزل_وزنك_اثناء_العزل_من_كورونا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @USER من أجل سلامتكم ننصح بتأجيل المواعيد و...</td>\n",
       "      <td>0</td>\n",
       "      <td>Text: RT @USER من أجل سلامتكم ننصح بتأجيل المو...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14142</th>\n",
       "      <td>@USER بس كورونا فيه عدوه</td>\n",
       "      <td>0</td>\n",
       "      <td>Text: @USER بس كورونا فيه عدوه\\n\\nAnswer: 0\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14143</th>\n",
       "      <td>( وَمَا تَشَاءُونَ إِلَّا أَن يَشَاءَ الله ) م...</td>\n",
       "      <td>0</td>\n",
       "      <td>Text: ( وَمَا تَشَاءُونَ إِلَّا أَن يَشَاءَ ال...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14144</th>\n",
       "      <td>RT @USER #هند_القحطاني #فايروس_كورونا #جراح_ال...</td>\n",
       "      <td>1</td>\n",
       "      <td>Text: RT @USER #هند_القحطاني #فايروس_كورونا #ج...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14145</th>\n",
       "      <td>@USER قله كورونا الي قبله كان من ألابل اصلا</td>\n",
       "      <td>0</td>\n",
       "      <td>Text: @USER قله كورونا الي قبله كان من ألابل ا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14146</th>\n",
       "      <td>قال ابن القـيم رحمه الله: «ومن أَعظم علاجات ال...</td>\n",
       "      <td>0</td>\n",
       "      <td>Text: قال ابن القـيم رحمه الله: «ومن أَعظم علا...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14147 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Sentence  Fake Flag  \\\n",
       "0      والناس بتقولك أنتم بتلعنوا في الصين ليه ؟ دي ب...          1   \n",
       "1      عندما ضرب #فيروس_كورونا الصين قالوا عنه عقوبه ...          1   \n",
       "2      عاجل | إيقاف الدوري السويسري لأجل غير مسمى ، ب...          0   \n",
       "3      RT @USER #نزل_وزنك_اثناء_العزل_من_كورونا ايه ط...          0   \n",
       "4      RT @USER من أجل سلامتكم ننصح بتأجيل المواعيد و...          0   \n",
       "...                                                  ...        ...   \n",
       "14142                           @USER بس كورونا فيه عدوه          0   \n",
       "14143  ( وَمَا تَشَاءُونَ إِلَّا أَن يَشَاءَ الله ) م...          0   \n",
       "14144  RT @USER #هند_القحطاني #فايروس_كورونا #جراح_ال...          1   \n",
       "14145        @USER قله كورونا الي قبله كان من ألابل اصلا          0   \n",
       "14146  قال ابن القـيم رحمه الله: «ومن أَعظم علاجات ال...          0   \n",
       "\n",
       "                                                  Prompt  \n",
       "0      Text: والناس بتقولك أنتم بتلعنوا في الصين ليه ...  \n",
       "1      Text: عندما ضرب #فيروس_كورونا الصين قالوا عنه ...  \n",
       "2      Text: عاجل | إيقاف الدوري السويسري لأجل غير مس...  \n",
       "3      Text: RT @USER #نزل_وزنك_اثناء_العزل_من_كورونا...  \n",
       "4      Text: RT @USER من أجل سلامتكم ننصح بتأجيل المو...  \n",
       "...                                                  ...  \n",
       "14142    Text: @USER بس كورونا فيه عدوه\\n\\nAnswer: 0\\n\\n  \n",
       "14143  Text: ( وَمَا تَشَاءُونَ إِلَّا أَن يَشَاءَ ال...  \n",
       "14144  Text: RT @USER #هند_القحطاني #فايروس_كورونا #ج...  \n",
       "14145  Text: @USER قله كورونا الي قبله كان من ألابل ا...  \n",
       "14146  Text: قال ابن القـيم رحمه الله: «ومن أَعظم علا...  \n",
       "\n",
       "[14147 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts_df_ara_fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8 Shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 4 samples with Fake Flag = 0\n",
    "samples_0 = prompts_df_ara_fs[prompts_df_ara_fs['Fake Flag'] == 0].sample(n=4, random_state=1)\n",
    "\n",
    "# Select 4 samples with Fake Flag = 1\n",
    "samples_1 = prompts_df_ara_fs[prompts_df_ara_fs['Fake Flag'] == 1].sample(n=4, random_state=1)\n",
    "\n",
    "# Concatenate the two samples\n",
    "sampled_df_8 = pd.concat([samples_0, samples_1])\n",
    "\n",
    "# Shuffle the resulting DataFrame to mix 0s and 1s\n",
    "sampled_df_8 = sampled_df_8.sample(frac=1, random_state=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: والناس بتقولك أنتم بتلعنوا في الصين ليه ؟ دي بلد كيوت و حطوا صور الدكاترة على المباني و عملولهم التحية و مبقاش عندهم كورونا أنا اسف يا جماعة بس أي حد بشوفه بيقول الكلام ده عن الصين بحس إنه مُغيب و ببقى عاوز ألطشه بالقلم LINK\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: عندما ضرب #فيروس_كورونا الصين قالوا عنه عقوبه ربانية لانها دولة كافرة(حوبه المسلمين)... وعندما وصل بلاد المسلمين قالوا خطة أمريكيه وأرتفع سعر الكمامات والتعقيم اضعاف مضاعفة ودولة الصين الكافرة توزعها على مواطنيها مجانا (مات أبا جهل فاصبح الجهل يتيماً فتبناه العرب) #فيروس_كورونا LINK\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: عاجل | إيقاف الدوري السويسري لأجل غير مسمى ، بسبب فيروس كورونا . LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: RT @USER #نزل_وزنك_اثناء_العزل_من_كورونا ايه طيب LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: RT @USER من أجل سلامتكم ننصح بتأجيل المواعيد والإجراءات الطبية غير الملحة. #الوقاية_من_كورونا LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: بعد نجاح المنشآت #السعودية في تطويق «#كورونا البعارين» الدور على «المستجد» #عكاظ #أن_تكون_أولاً LINK LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: يا #كورونا إني اعلمك كلمات : ما من مسلمٍ تصيبه فيشفى منك الا وقد حطّ الله عنه سيئات ورفعه درجات ، وما من مسلمٍ تصيبه فيموت إلاّ كان ذلك شهادةً له يوم القيامة . . فمالك ولنا ، هلاّ غادرت غير مأسوفٍ عليك ؟\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: إن صح ما يشاع عن عقار الملاريا .. فالدول الأفريقيه هي الگثر إستخداماً له وهو مايفسر عدم إنتشار #كوفيد19 فيها #كورونا LINK\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shots_8 = '\\n'.join(prompts_df_ara_fs.iloc[:8, 2].astype(str))\n",
    "print(shots_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to calculate metrics\n",
    "def calculate_metrics(test_set, params):\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in test_set.iterrows():\n",
    "        sentence = row[\"claim_s\"]\n",
    "        actual_label = row[\"fake_flag\"]\n",
    "\n",
    "        # Generate prompt based on each row\n",
    "        prompt = f\"\"\"Determine whether the following text is real or fake. If real, then output 0. If fake, then output 1. Respond with only the integer 0 or 1 and nothing else.\n",
    "\n",
    "{shots_8}\n",
    "\n",
    "Text: {sentence}\n",
    "\n",
    "Answer:\n",
    "\n",
    "\"\"\"\n",
    "        # Call the get_completion function with prompt and params\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        response = get_completion(params, messages)\n",
    "        content = response.get(\"message\").get(\"content\")\n",
    "        predicted_label = get_prediction(content)\n",
    "        none_count = 0\n",
    "        \n",
    "        if predicted_label is not None:\n",
    "            true_labels.append(actual_label)\n",
    "            predicted_labels.append(predicted_label)\n",
    "        else:\n",
    "            none_count += 1\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels)\n",
    "    recall = recall_score(true_labels, predicted_labels)\n",
    "    f1 = f1_score(true_labels, predicted_labels)\n",
    "\n",
    "    return accuracy, precision, recall, f1, predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8090640922499329\n",
      "Precision: 0.5841889117043121\n",
      "Recall: 0.6495433789954338\n",
      "F1 Score: 0.6151351351351352\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "accuracy, precision, recall, f1 , predicted_ara_8s_4o = calculate_metrics(df_ara_zs, params)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_ara_8s_4o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ara_8s_4o = [0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 16 Shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 8 samples with Fake Flag = 0\n",
    "samples_0 = prompts_df_ara_fs[prompts_df_ara_fs['Fake Flag'] == 0].sample(n=8, random_state=1)\n",
    "\n",
    "# Select 8 samples with Fake Flag = 1\n",
    "samples_1 = prompts_df_ara_fs[prompts_df_ara_fs['Fake Flag'] == 1].sample(n=8, random_state=1)\n",
    "\n",
    "# Concatenate the two samples\n",
    "sampled_df_16 = pd.concat([samples_0, samples_1])\n",
    "\n",
    "# Shuffle the resulting DataFrame to mix 0s and 1s\n",
    "sampled_df_16 = sampled_df_16.sample(frac=1, random_state=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: والناس بتقولك أنتم بتلعنوا في الصين ليه ؟ دي بلد كيوت و حطوا صور الدكاترة على المباني و عملولهم التحية و مبقاش عندهم كورونا أنا اسف يا جماعة بس أي حد بشوفه بيقول الكلام ده عن الصين بحس إنه مُغيب و ببقى عاوز ألطشه بالقلم LINK\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: عندما ضرب #فيروس_كورونا الصين قالوا عنه عقوبه ربانية لانها دولة كافرة(حوبه المسلمين)... وعندما وصل بلاد المسلمين قالوا خطة أمريكيه وأرتفع سعر الكمامات والتعقيم اضعاف مضاعفة ودولة الصين الكافرة توزعها على مواطنيها مجانا (مات أبا جهل فاصبح الجهل يتيماً فتبناه العرب) #فيروس_كورونا LINK\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: عاجل | إيقاف الدوري السويسري لأجل غير مسمى ، بسبب فيروس كورونا . LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: RT @USER #نزل_وزنك_اثناء_العزل_من_كورونا ايه طيب LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: RT @USER من أجل سلامتكم ننصح بتأجيل المواعيد والإجراءات الطبية غير الملحة. #الوقاية_من_كورونا LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: بعد نجاح المنشآت #السعودية في تطويق «#كورونا البعارين» الدور على «المستجد» #عكاظ #أن_تكون_أولاً LINK LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: يا #كورونا إني اعلمك كلمات : ما من مسلمٍ تصيبه فيشفى منك الا وقد حطّ الله عنه سيئات ورفعه درجات ، وما من مسلمٍ تصيبه فيموت إلاّ كان ذلك شهادةً له يوم القيامة . . فمالك ولنا ، هلاّ غادرت غير مأسوفٍ عليك ؟\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: إن صح ما يشاع عن عقار الملاريا .. فالدول الأفريقيه هي الگثر إستخداماً له وهو مايفسر عدم إنتشار #كوفيد19 فيها #كورونا LINK\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: مطلوب صديق مايسولف عن كورونا ولاياذينا باشاعات الوتساب LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: ايران الغنية بالموارد كالنفط والغاز..تأتيها المستلزمات الطبية(اغاثة) ولا تستطيع توفيرها لمواطنيها لمواجهه كورونا وليس لديها حتى منشأت طبية مؤهلة، لدرجة ان المصاب بالفايروس يذهب للمستشفى لينتظر الموت..فلا علاج ولا حتى رعاية طبية -هذا هو نموذج الثورة الحقيقي التي تريد تصديره للعرب\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: لازم كلنا نتجمع ونكتب عن أخوتنا المعتقلين في السجون ياترى دول هيعملوا ايه لو واحد بس لا قدر الله أصيب ب #فيروس_كورونا في عنبر مليان معتقلين هيقدروا ازاي يسيطروا على العدد ده ده هيبقى بؤرة لإنتشار الفيروس لكل البلد كمان كل سجان بيتعامل معاهم هيتصاب وينقل الفيروس😊 #خرجوا_المعتقلين\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: #فيروس_كورونا تحصنّا بذي العزة واعتصمنا برب الملكوت وتوكلنا على الحي الذي لا يموت ،اللهم اصرف عننا هذا الوباء وقنا شر الداء ونجنا من الطعن والطاعون والبلاء بلطفك يا لطيف إنك على كل شيء قدير..\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: RT @USER #كلنا_مسؤول البقاء في المنزل سلاحنا الأقوى بإذن الله لمواجهة #فايروس_كورونا\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: #شركة_تنظيف_مجالس_بالرياض من المعروف ان شركة تنظيف مجالس الرياض هي من أحسن الشركات على مستوى كل الشركات الموجودة في مجال التنظيف #رش_ضد_فيروس_كورونا خدماتنا : غسيل كنب نظافة موكيت تنظيف سجاد تنظيف الاستراحات تنظيف بيوت شعر نظافة خيام تنظيف فرش فرشات جوال 0501545009 0508011776 LINK\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: نشكر قيادتنا الرشيدة على قرارها الإحترازي الوقائي الرشيد بتعليق العمرة مؤقتاً بسبب التحرز من من انتقال فايروس كورونا حرصاً على سلامة رواد الحرم المكي من المواطنين والمقيمين وماهي إلا فترة محدودة إن شاء الله LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: RT @USER #كورونا LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shots_16 = '\\n'.join(prompts_df_ara_fs.iloc[:16, 2].astype(str))\n",
    "print(shots_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to calculate metrics\n",
    "def calculate_metrics(test_set, params):\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in test_set.iterrows():\n",
    "        sentence = row[\"claim_s\"]\n",
    "        actual_label = row[\"fake_flag\"]\n",
    "\n",
    "        # Generate prompt based on each row\n",
    "        prompt = f\"\"\"Determine whether the following text is real or fake. If real, then output 0. If fake, then output 1. Respond with only the integer 0 or 1 and nothing else.\n",
    "\n",
    "{shots_16}\n",
    "\n",
    "Text: {sentence}\n",
    "\n",
    "Answer:\n",
    "\n",
    "\"\"\"\n",
    "        # Call the get_completion function with prompt and params\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        response = get_completion(params, messages)\n",
    "        content = response.get(\"message\").get(\"content\")\n",
    "        predicted_label = get_prediction(content)\n",
    "        none_count = 0\n",
    "        \n",
    "        if predicted_label is not None:\n",
    "            true_labels.append(actual_label)\n",
    "            predicted_labels.append(predicted_label)\n",
    "        else:\n",
    "            none_count += 1\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels)\n",
    "    recall = recall_score(true_labels, predicted_labels)\n",
    "    f1 = f1_score(true_labels, predicted_labels)\n",
    "\n",
    "    return accuracy, precision, recall, f1, predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7680343255564495\n",
      "Precision: 0.5036065573770492\n",
      "Recall: 0.8767123287671232\n",
      "F1 Score: 0.6397334443981675\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "accuracy, precision, recall, f1, predicted_ara_16s_4o = calculate_metrics(df_ara_zs, params)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_ara_16s_4o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ara_16s_4o = [1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 32 Shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 16 samples with Fake Flag = 0\n",
    "samples_0 = prompts_df_ara_fs[prompts_df_ara_fs['Fake Flag'] == 0].sample(n=16, random_state=1)\n",
    "\n",
    "# Select 16 samples with Fake Flag = 1\n",
    "samples_1 = prompts_df_ara_fs[prompts_df_ara_fs['Fake Flag'] == 1].sample(n=16, random_state=1)\n",
    "\n",
    "# Concatenate the two samples\n",
    "sampled_df_32 = pd.concat([samples_0, samples_1])\n",
    "\n",
    "# Shuffle the resulting DataFrame to mix 0s and 1s\n",
    "sampled_df_32 = sampled_df_32.sample(frac=1, random_state=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: والناس بتقولك أنتم بتلعنوا في الصين ليه ؟ دي بلد كيوت و حطوا صور الدكاترة على المباني و عملولهم التحية و مبقاش عندهم كورونا أنا اسف يا جماعة بس أي حد بشوفه بيقول الكلام ده عن الصين بحس إنه مُغيب و ببقى عاوز ألطشه بالقلم LINK\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: عندما ضرب #فيروس_كورونا الصين قالوا عنه عقوبه ربانية لانها دولة كافرة(حوبه المسلمين)... وعندما وصل بلاد المسلمين قالوا خطة أمريكيه وأرتفع سعر الكمامات والتعقيم اضعاف مضاعفة ودولة الصين الكافرة توزعها على مواطنيها مجانا (مات أبا جهل فاصبح الجهل يتيماً فتبناه العرب) #فيروس_كورونا LINK\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: عاجل | إيقاف الدوري السويسري لأجل غير مسمى ، بسبب فيروس كورونا . LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: RT @USER #نزل_وزنك_اثناء_العزل_من_كورونا ايه طيب LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: RT @USER من أجل سلامتكم ننصح بتأجيل المواعيد والإجراءات الطبية غير الملحة. #الوقاية_من_كورونا LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: بعد نجاح المنشآت #السعودية في تطويق «#كورونا البعارين» الدور على «المستجد» #عكاظ #أن_تكون_أولاً LINK LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: يا #كورونا إني اعلمك كلمات : ما من مسلمٍ تصيبه فيشفى منك الا وقد حطّ الله عنه سيئات ورفعه درجات ، وما من مسلمٍ تصيبه فيموت إلاّ كان ذلك شهادةً له يوم القيامة . . فمالك ولنا ، هلاّ غادرت غير مأسوفٍ عليك ؟\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: إن صح ما يشاع عن عقار الملاريا .. فالدول الأفريقيه هي الگثر إستخداماً له وهو مايفسر عدم إنتشار #كوفيد19 فيها #كورونا LINK\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: مطلوب صديق مايسولف عن كورونا ولاياذينا باشاعات الوتساب LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: ايران الغنية بالموارد كالنفط والغاز..تأتيها المستلزمات الطبية(اغاثة) ولا تستطيع توفيرها لمواطنيها لمواجهه كورونا وليس لديها حتى منشأت طبية مؤهلة، لدرجة ان المصاب بالفايروس يذهب للمستشفى لينتظر الموت..فلا علاج ولا حتى رعاية طبية -هذا هو نموذج الثورة الحقيقي التي تريد تصديره للعرب\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: لازم كلنا نتجمع ونكتب عن أخوتنا المعتقلين في السجون ياترى دول هيعملوا ايه لو واحد بس لا قدر الله أصيب ب #فيروس_كورونا في عنبر مليان معتقلين هيقدروا ازاي يسيطروا على العدد ده ده هيبقى بؤرة لإنتشار الفيروس لكل البلد كمان كل سجان بيتعامل معاهم هيتصاب وينقل الفيروس😊 #خرجوا_المعتقلين\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: #فيروس_كورونا تحصنّا بذي العزة واعتصمنا برب الملكوت وتوكلنا على الحي الذي لا يموت ،اللهم اصرف عننا هذا الوباء وقنا شر الداء ونجنا من الطعن والطاعون والبلاء بلطفك يا لطيف إنك على كل شيء قدير..\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: RT @USER #كلنا_مسؤول البقاء في المنزل سلاحنا الأقوى بإذن الله لمواجهة #فايروس_كورونا\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: #شركة_تنظيف_مجالس_بالرياض من المعروف ان شركة تنظيف مجالس الرياض هي من أحسن الشركات على مستوى كل الشركات الموجودة في مجال التنظيف #رش_ضد_فيروس_كورونا خدماتنا : غسيل كنب نظافة موكيت تنظيف سجاد تنظيف الاستراحات تنظيف بيوت شعر نظافة خيام تنظيف فرش فرشات جوال 0501545009 0508011776 LINK\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: نشكر قيادتنا الرشيدة على قرارها الإحترازي الوقائي الرشيد بتعليق العمرة مؤقتاً بسبب التحرز من من انتقال فايروس كورونا حرصاً على سلامة رواد الحرم المكي من المواطنين والمقيمين وماهي إلا فترة محدودة إن شاء الله LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: RT @USER #كورونا LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: RT @USER عيناها ك فيروس كورونا و قلبى صيني لا يتحمل 😕💔 LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: أزمة #كورونا جعلتني اشاهد المشهد بتأملات جديده و انطباعات جديده و صدمت بسياسات دول كنت أظن فيها أنها تهتم بالإنسان أكثر من المال كل التحيه لدول الخليج اللذين سخروا الأموال لخدمه الأنسان (في هذه الأزمة)\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: فيروس كورونا 😱😱😱 الصين : مافي خروج من المنزل الكويت : مافي دراسة السعودية : مافي عمره وربما الحج  الامارات : مافي دراسة البحرين : مافي دراسة اليمن : مافي داعي للقلق شكراً حكومتنا الموقره نحن شعب مايهزه ريح  😂😂😂😂😂🌚💔✋🏻\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: RT @USER يامن تعلمون الناس الدجل والشعوذة اين انتم من تفعيل وتطوير الجانب الصحي !!! #ولايه_الفقيه_ظلم_وانتقام #كورونا_كشف_القناع\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: الصحة البريطانيه تقول للبريطانيين \" اذا حسيت بـ اعراض كورونا لاتتصل علينا وعالج نفسك بنفسك عشان تخفف العبء على خدماتنا الصحية !! وزارة الصحة السعودية تقول اذا حسيت بشي اتصل بنا وحنا نخدمك وامانة الرياض تصنع معقمات وتوزعها مجاناً وطننا عظيم ياجماعة 💚🙏🏻 LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: RT @USER مليت من كثرة النصايح في #كورونا؟ عندك حاجتين حافظ عليهم: ✅ نظافة يدينك ✅ مسافة متر من الناس في الأماكن العامة فقط🤷🏻\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: @USER @USER @USER يوم تعطلون المدارس كان لسى ماجانا كورونا ! تسلل ياححححكممم\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: _ بيقولوا الناس نزلت مظاهرات ليلية ضد اللى ما يتسماش = والله كنت متأكد إن الشعب هيفوق ويعمل ثورة على النظام! _ نظام أيه يابنى دول نازلين ضد فيروس كورونا\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: تواصل #أمانة_منطقة_الرياض توزيع معقمها مجانًا للسكان في أكثر من ٢٥ موقعًا ضمن جهودها الوقائية لمنع انتشار فيروس #كورونا المستجد.. LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: فيديوجرافيك 🎥 | أسئلة شائعة حول #كورونا.. هل يجب ارتداء كمامة للوقاية منه؟  LINK LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: احمى نفسك وغيرك من فيروس كورونا واشترى اونلاين ☺ واحصل على الخصم الاكيد مع كوبونات الخصومات ومن اكتر من متجر 👏 جميع احتياجات عندنا انسخ الكوبون واحصل على الخصم المضمون🏆 كوبون نون:Less17💨LUck41 Sprii:S12 اناس:  Star5 نمشى: star8 سنتربوينت : CPC197 كل: hi30 السعوديه LINK\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: يارب يخلص يومي وم أسمع كلمة كورونا.\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: أتمنئ ان لا يصل كورونا الئ (اليمن ) شعب ماعد به طافة يتحمل خلاص الموضوع مش سهل او عباطة هذه اكبر أزمة في العالم في القرن الحديث متخيل بس ماعد بش تخازين وأسواق قات وتخزن لوحدك بالبيت صح في مداعة وشمة لكن برضوا مافيش مزح نحتاج الئ أجهزة فحص طبية وحجر بالموانئ والمطارات المفتوحة LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: بالأرقام .. خسائر قطاع #السياحة_العربية والعالمية جراء #فيروس_كورونا #COVID-19 😷 حتى الآن 👇🏻 اهمها قد يتعرض أكثر من 50 مليون موظف يعمل في القطاع السياحي للإيقاف. المصدر: فريق إدارة الأزمات بـ#المنظمة_العربية_للسياحة اللهم أحفظ الأمة العربية والإسلامية والعالم من هذا الوباء LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: @USER @USER @USER كلارك ❤️❤️❤️❤️😏الا كلارك ولا اهد العالم فوق تحت بروح أستراليا ماعندهم كورونا 🌚❤️\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: فيني صداع قوي مدري من البخور أو كورونا 💔\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shots_all = '\\n'.join(prompts_df_ara_fs.iloc[:32, 2].astype(str))\n",
    "print(shots_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to calculate metrics\n",
    "def calculate_metrics(test_set, params):\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in test_set.iterrows():\n",
    "        sentence = row[\"claim_s\"]\n",
    "        actual_label = row[\"fake_flag\"]\n",
    "\n",
    "        # Generate prompt based on each row\n",
    "        prompt = f\"\"\"Determine whether the following text is real or fake. If real, then output 0. If fake, then output 1. Respond with only the integer 0 or 1 and nothing else.\n",
    "\n",
    "{shots_all}\n",
    "\n",
    "Text: {sentence}\n",
    "\n",
    "Answer:\n",
    "\n",
    "\"\"\"\n",
    "        # Call the get_completion function with prompt and params\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        response = get_completion(params, messages)\n",
    "        content = response.get(\"message\").get(\"content\")\n",
    "        predicted_label = get_prediction(content)\n",
    "        none_count = 0\n",
    "        \n",
    "        if predicted_label is not None:\n",
    "            true_labels.append(actual_label)\n",
    "            predicted_labels.append(predicted_label)\n",
    "        else:\n",
    "            none_count += 1\n",
    "\n",
    "    # Calculate metrics\n",
    "    print(\"none_count\", none_count)\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels)\n",
    "    recall = recall_score(true_labels, predicted_labels)\n",
    "    f1 = f1_score(true_labels, predicted_labels)\n",
    "\n",
    "    return accuracy, precision, recall, f1, predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "none_count 0\n",
      "Accuracy: 0.6275140788415124\n",
      "Precision: 0.3735830458353869\n",
      "Recall: 0.865296803652968\n",
      "F1 Score: 0.5218588640275387\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "accuracy, precision, recall, f1, predicted_ara_32s_4o = calculate_metrics(df_ara_zs, params)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_ara_32s_4o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ara_32s_4o = [0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "LOSyELDH1eVT",
    "uGppidLd1n_b"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f38e0373277d6f71ee44ee8fea5f1d408ad6999fda15d538a69a99a1665a839d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
