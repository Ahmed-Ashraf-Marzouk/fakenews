{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3s7uxte9qcKu"
   },
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HkZUqFMtqcKw"
   },
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">>> Downloading ollama...\n",
      "######################################################################## 100.0%##O=#  #                                                                      \n",
      ">>> Installing ollama to /usr/local/bin...\n",
      ">>> Creating ollama user...\n",
      ">>> Adding ollama user to video group...\n",
      ">>> Adding current user to ollama group...\n",
      ">>> Creating ollama systemd service...\n",
      "WARNING: Unable to detect NVIDIA/AMD GPU. Install lspci or lshw to automatically detect and install GPU dependencies.\n",
      ">>> The Ollama API is now available at 127.0.0.1:11434.\n",
      ">>> Install complete. Run \"ollama\" from the command line.\n"
     ]
    }
   ],
   "source": [
    "!curl -fsSL https://ollama.com/install.sh | sh"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "40mAGPxdqcK1",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain\n",
      "  Downloading langchain-0.2.11-py3-none-any.whl.metadata (7.1 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Collecting SQLAlchemy<3,>=1.4 (from langchain)\n",
      "  Downloading SQLAlchemy-2.0.31-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (9.6 kB)\n",
      "Collecting aiohttp<4.0.0,>=3.8.3 (from langchain)\n",
      "  Downloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (7.5 kB)\n",
      "Collecting async-timeout<5.0.0,>=4.0.0 (from langchain)\n",
      "  Downloading async_timeout-4.0.3-py3-none-any.whl.metadata (4.2 kB)\n",
      "Collecting langchain-core<0.3.0,>=0.2.23 (from langchain)\n",
      "  Downloading langchain_core-0.2.24-py3-none-any.whl.metadata (6.2 kB)\n",
      "Collecting langchain-text-splitters<0.3.0,>=0.2.0 (from langchain)\n",
      "  Downloading langchain_text_splitters-0.2.2-py3-none-any.whl.metadata (2.1 kB)\n",
      "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
      "  Downloading langsmith-0.1.94-py3-none-any.whl.metadata (13 kB)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.3)\n",
      "Collecting pydantic<3,>=1 (from langchain)\n",
      "  Downloading pydantic-2.8.2-py3-none-any.whl.metadata (125 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m125.2/125.2 kB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hRequirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain)\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting aiosignal>=1.1.2 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading aiosignal-1.3.1-py3-none-any.whl.metadata (4.0 kB)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Collecting frozenlist>=1.1.1 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Collecting multidict<7.0,>=4.5 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (4.2 kB)\n",
      "Collecting yarl<2.0,>=1.0 (from aiohttp<4.0.0,>=3.8.3->langchain)\n",
      "  Downloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (31 kB)\n",
      "Collecting jsonpatch<2.0,>=1.33 (from langchain-core<0.3.0,>=0.2.23->langchain)\n",
      "  Downloading jsonpatch-1.33-py2.py3-none-any.whl.metadata (3.0 kB)\n",
      "Collecting packaging<25,>=23.2 (from langchain-core<0.3.0,>=0.2.23->langchain)\n",
      "  Downloading packaging-24.1-py3-none-any.whl.metadata (3.2 kB)\n",
      "Collecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
      "  Downloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (50 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m50.4/50.4 kB\u001b[0m \u001b[31m18.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting annotated-types>=0.4.0 (from pydantic<3,>=1->langchain)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.20.1 (from pydantic<3,>=1->langchain)\n",
      "  Downloading pydantic_core-2.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.6 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Collecting greenlet!=0.4.17 (from SQLAlchemy<3,>=1.4->langchain)\n",
      "  Downloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.23->langchain) (2.1)\n",
      "Downloading langchain-0.2.11-py3-none-any.whl (990 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m990.3/990.3 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0mta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading aiohttp-3.9.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading async_timeout-4.0.3-py3-none-any.whl (5.7 kB)\n",
      "Downloading langchain_core-0.2.24-py3-none-any.whl (377 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m377.3/377.3 kB\u001b[0m \u001b[31m12.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading langchain_text_splitters-0.2.2-py3-none-any.whl (25 kB)\n",
      "Downloading langsmith-0.1.94-py3-none-any.whl (139 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.9/139.9 kB\u001b[0m \u001b[31m21.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic-2.8.2-py3-none-any.whl (423 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m423.9/423.9 kB\u001b[0m \u001b[31m12.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading pydantic_core-2.20.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading SQLAlchemy-2.0.31-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/3.1 MB\u001b[0m \u001b[31m18.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Downloading aiosignal-1.3.1-py3-none-any.whl (7.6 kB)\n",
      "Downloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading frozenlist-1.4.1-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_17_x86_64.manylinux2014_x86_64.whl (239 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m239.5/239.5 kB\u001b[0m \u001b[31m34.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading greenlet-3.0.3-cp310-cp310-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (616 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m616.0/616.0 kB\u001b[0m \u001b[31m31.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
      "Downloading multidict-6.0.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (124 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m124.3/124.3 kB\u001b[0m \u001b[31m36.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading orjson-3.10.6-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m40.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading packaging-24.1-py3-none-any.whl (53 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.0/54.0 kB\u001b[0m \u001b[31m16.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading yarl-1.9.4-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.6/301.6 kB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tenacity, pydantic-core, packaging, orjson, multidict, jsonpatch, greenlet, frozenlist, async-timeout, annotated-types, yarl, SQLAlchemy, pydantic, aiosignal, langsmith, aiohttp, langchain-core, langchain-text-splitters, langchain\n",
      "  Attempting uninstall: packaging\n",
      "    Found existing installation: packaging 23.1\n",
      "    Uninstalling packaging-23.1:\n",
      "      Successfully uninstalled packaging-23.1\n",
      "  Attempting uninstall: jsonpatch\n",
      "    Found existing installation: jsonpatch 1.32\n",
      "    Uninstalling jsonpatch-1.32:\n",
      "      Successfully uninstalled jsonpatch-1.32\n",
      "Successfully installed SQLAlchemy-2.0.31 aiohttp-3.9.5 aiosignal-1.3.1 annotated-types-0.7.0 async-timeout-4.0.3 frozenlist-1.4.1 greenlet-3.0.3 jsonpatch-1.33 langchain-0.2.11 langchain-core-0.2.24 langchain-text-splitters-0.2.2 langsmith-0.1.94 multidict-6.0.5 orjson-3.10.6 packaging-24.1 pydantic-2.8.2 pydantic-core-2.20.1 tenacity-8.5.0 yarl-1.9.4\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting python-dotenv\n",
      "  Downloading python_dotenv-1.0.1-py3-none-any.whl.metadata (23 kB)\n",
      "Downloading python_dotenv-1.0.1-py3-none-any.whl (19 kB)\n",
      "Installing collected packages: python-dotenv\n",
      "Successfully installed python-dotenv-1.0.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting langchain_community\n",
      "  Downloading langchain_community-0.2.10-py3-none-any.whl.metadata (2.7 kB)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (3.9.5)\n",
      "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain_community)\n",
      "  Downloading dataclasses_json-0.6.7-py3-none-any.whl.metadata (25 kB)\n",
      "Requirement already satisfied: langchain<0.3.0,>=0.2.9 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.2.11)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.23 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.2.24)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.1.94)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (1.26.3)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (8.5.0)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (1.9.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain_community) (4.0.3)\n",
      "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading marshmallow-3.21.3-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading typing_inspect-0.9.0-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from langchain<0.3.0,>=0.2.9->langchain_community) (0.2.2)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain<0.3.0,>=0.2.9->langchain_community) (2.8.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain_community) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain_community) (24.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.0->langchain_community) (3.10.6)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain_community) (2024.2.2)\n",
      "Requirement already satisfied: typing-extensions>=4.6.0 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (4.9.0)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain_community) (3.0.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.23->langchain_community) (2.1)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.9->langchain_community) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain<0.3.0,>=0.2.9->langchain_community) (2.20.1)\n",
      "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community)\n",
      "  Downloading mypy_extensions-1.0.0-py3-none-any.whl.metadata (1.1 kB)\n",
      "Downloading langchain_community-0.2.10-py3-none-any.whl (2.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m14.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading dataclasses_json-0.6.7-py3-none-any.whl (28 kB)\n",
      "Downloading marshmallow-3.21.3-py3-none-any.whl (49 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.2/49.2 kB\u001b[0m \u001b[31m19.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
      "Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: mypy-extensions, marshmallow, typing-inspect, dataclasses-json, langchain_community\n",
      "Successfully installed dataclasses-json-0.6.7 langchain_community-0.2.10 marshmallow-3.21.3 mypy-extensions-1.0.0 typing-inspect-0.9.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mRequirement already satisfied: langchain in /opt/conda/lib/python3.10/site-packages (0.2.11)\n",
      "Requirement already satisfied: langchain_community in /opt/conda/lib/python3.10/site-packages (0.2.10)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (6.0.1)\n",
      "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.0.31)\n",
      "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /opt/conda/lib/python3.10/site-packages (from langchain) (3.9.5)\n",
      "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (4.0.3)\n",
      "Requirement already satisfied: langchain-core<0.3.0,>=0.2.23 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.2.24)\n",
      "Requirement already satisfied: langchain-text-splitters<0.3.0,>=0.2.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.2.2)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /opt/conda/lib/python3.10/site-packages (from langchain) (0.1.94)\n",
      "Requirement already satisfied: numpy<2,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (1.26.3)\n",
      "Requirement already satisfied: pydantic<3,>=1 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.8.2)\n",
      "Requirement already satisfied: requests<3,>=2 in /opt/conda/lib/python3.10/site-packages (from langchain) (2.31.0)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in /opt/conda/lib/python3.10/site-packages (from langchain) (8.5.0)\n",
      "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /opt/conda/lib/python3.10/site-packages (from langchain_community) (0.6.7)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.1.0)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /opt/conda/lib/python3.10/site-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
      "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (3.21.3)\n",
      "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from dataclasses-json<0.7,>=0.5.7->langchain_community) (0.9.0)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain) (1.33)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /opt/conda/lib/python3.10/site-packages (from langchain-core<0.3.0,>=0.2.23->langchain) (24.1)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /opt/conda/lib/python3.10/site-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (2.20.1)\n",
      "Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic<3,>=1->langchain) (4.9.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (3.4)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
      "Requirement already satisfied: greenlet!=0.4.17 in /opt/conda/lib/python3.10/site-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /opt/conda/lib/python3.10/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3.0,>=0.2.23->langchain) (2.1)\n",
      "Requirement already satisfied: mypy-extensions>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain_community) (1.0.0)\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting scikit-learn\n",
      "  Downloading scikit_learn-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
      "Requirement already satisfied: numpy>=1.19.5 in /opt/conda/lib/python3.10/site-packages (from scikit-learn) (1.26.3)\n",
      "Collecting scipy>=1.6.0 (from scikit-learn)\n",
      "  Downloading scipy-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (60 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m60.8/60.8 kB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hCollecting joblib>=1.2.0 (from scikit-learn)\n",
      "  Downloading joblib-1.4.2-py3-none-any.whl.metadata (5.4 kB)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn)\n",
      "  Downloading threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Downloading scikit_learn-1.5.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.4/13.4 MB\u001b[0m \u001b[31m24.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading joblib-1.4.2-py3-none-any.whl (301 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m301.8/301.8 kB\u001b[0m \u001b[31m42.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading scipy-1.14.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (41.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m41.1/41.1 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Installing collected packages: threadpoolctl, scipy, joblib, scikit-learn\n",
      "Successfully installed joblib-1.4.2 scikit-learn-1.5.1 scipy-1.14.0 threadpoolctl-3.5.0\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting ollama\n",
      "  Downloading ollama-0.3.1-py3-none-any.whl.metadata (3.8 kB)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /opt/conda/lib/python3.10/site-packages (from ollama) (0.27.0)\n",
      "Requirement already satisfied: anyio in /opt/conda/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (4.3.0)\n",
      "Requirement already satisfied: certifi in /opt/conda/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (2024.2.2)\n",
      "Requirement already satisfied: httpcore==1.* in /opt/conda/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.0.4)\n",
      "Requirement already satisfied: idna in /opt/conda/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (3.4)\n",
      "Requirement already satisfied: sniffio in /opt/conda/lib/python3.10/site-packages (from httpx<0.28.0,>=0.27.0->ollama) (1.3.0)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /opt/conda/lib/python3.10/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama) (0.14.0)\n",
      "Requirement already satisfied: exceptiongroup>=1.0.2 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<0.28.0,>=0.27.0->ollama) (1.2.0)\n",
      "Requirement already satisfied: typing-extensions>=4.1 in /opt/conda/lib/python3.10/site-packages (from anyio->httpx<0.28.0,>=0.27.0->ollama) (4.9.0)\n",
      "Downloading ollama-0.3.1-py3-none-any.whl (10 kB)\n",
      "Installing collected packages: ollama\n",
      "Successfully installed ollama-0.3.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting pandas\n",
      "  Downloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (19 kB)\n",
      "Requirement already satisfied: numpy>=1.22.4 in /opt/conda/lib/python3.10/site-packages (from pandas) (1.26.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /opt/conda/lib/python3.10/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /opt/conda/lib/python3.10/site-packages (from pandas) (2023.3.post1)\n",
      "Collecting tzdata>=2022.7 (from pandas)\n",
      "  Downloading tzdata-2024.1-py2.py3-none-any.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: six>=1.5 in /opt/conda/lib/python3.10/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Downloading pandas-2.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (13.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.0/13.0 MB\u001b[0m \u001b[31m30.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading tzdata-2024.1-py2.py3-none-any.whl (345 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m345.4/345.4 kB\u001b[0m \u001b[31m74.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: tzdata, pandas\n",
      "Successfully installed pandas-2.2.2 tzdata-2024.1\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0mCollecting openpyxl\n",
      "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
      "Collecting et-xmlfile (from openpyxl)\n",
      "  Downloading et_xmlfile-1.1.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Downloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.9/250.9 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading et_xmlfile-1.1.0-py3-none-any.whl (4.7 kB)\n",
      "Installing collected packages: et-xmlfile, openpyxl\n",
      "Successfully installed et-xmlfile-1.1.0 openpyxl-3.1.5\n",
      "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
      "\u001b[0m"
     ]
    }
   ],
   "source": [
    "# update or install the necessary libraries\n",
    "!pip install --upgrade langchain\n",
    "!pip install --upgrade python-dotenv\n",
    "!pip install langchain_community\n",
    "!pip install --upgrade langchain langchain_community\n",
    "!pip install -U scikit-learn\n",
    "!pip install --upgrade ollama\n",
    "!pip install pandas\n",
    "!pip install openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "oYQ1tLEjqcK4"
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import IPython\n",
    "IPython.display.clear_output(wait=True)\n",
    "from langchain.llms import OpenAI\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "import pandas as pd\n",
    "import json\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "raRFI4yNBTjn"
   },
   "source": [
    "# Gemma2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'models': [{'name': 'gemma2:27b',\n",
       "   'model': 'gemma2:27b',\n",
       "   'modified_at': '2024-07-30T19:41:30.985017464Z',\n",
       "   'size': 15628387458,\n",
       "   'digest': '53261bc9c192c1cb5fcc898dd3aa15da093f5ab6f08e17e48cf838bb1c58abfe',\n",
       "   'details': {'parent_model': '',\n",
       "    'format': 'gguf',\n",
       "    'family': 'gemma2',\n",
       "    'families': ['gemma2'],\n",
       "    'parameter_size': '27.2B',\n",
       "    'quantization_level': 'Q4_0'}}]}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ollama.list()  # To check downloaded models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'success'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ollama.pull(\"gemma2:27b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "N9aAmQWoqcK8"
   },
   "outputs": [],
   "source": [
    "def set_llama_params(model=\"gemma2:27b\"):  # update model to your preference\n",
    "    \"\"\" set llama parameters\"\"\"\n",
    "    model_response = ollama.chat(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a  gemma ssistant that talks like a gemma, starting every word with 'll'.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Hi, happy gemma day!\"},\n",
    "        ],\n",
    "        stream=False\n",
    "    )\n",
    "    return {\"model\": model_response.get(\"model\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gemma2:27b\n"
     ]
    }
   ],
   "source": [
    "model = \"gemma2:27b\"\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': 'gemma2:27b'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_llama_params(model=model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "XxKH3yMcgkSL"
   },
   "outputs": [],
   "source": [
    "def get_completion(params, messages):\n",
    "    \"\"\" GET completion from gemma model\"\"\"\n",
    "    response = None\n",
    "    payload = {\n",
    "        \"model\": params[\"model\"],\n",
    "        \"tools\": [\n",
    "            {\"functions\": [\n",
    "                {'name': 'fake_news_detection',\n",
    "                'description': 'Detect whether a given news is fake or not.',\n",
    "                'parameters': {\n",
    "                    'type': 'object',\n",
    "                    'properties': {\n",
    "                        'sentiment': {\n",
    "                            'title': 'sentiment',\n",
    "                            'type': 'string',\n",
    "                            'description': 'the sentiment encountered in the passage'\n",
    "                        },\n",
    "                        'is_fake': {\n",
    "                            'title': 'is fake',\n",
    "                            'type': 'integer',\n",
    "                            'description': 'Determine whether the text is real or fake. if real then output = 0 and if fake then output = 1. Output must be integer 0 or 1 alone.'\n",
    "                        },\n",
    "                        'language': {\n",
    "                            'title': 'language',\n",
    "                            'type': 'string',\n",
    "                            'description': 'the language of the passage'\n",
    "                        }\n",
    "                      },\n",
    "                      'required': ['sentiment', 'is_fake', 'language']\n",
    "                    },\n",
    "                    \"function_call\": {\"name\": \"fake_news_detection\"},\n",
    "                }\n",
    "            ],}\n",
    "        ],\n",
    "        \"stream\": False,\n",
    "        \"options\": {\n",
    "            \"max_tokens\": 1,\n",
    "            \"temperature\": 0.1,\n",
    "        },\n",
    "    }\n",
    "    payload[\"messages\"] = messages\n",
    "\n",
    "    model_response = ollama.chat(\n",
    "        model=payload[\"model\"],\n",
    "        messages=payload[\"messages\"],\n",
    "        #tools=payload[\"tools\"], # track this PR: https://github.com/ollama/ollama-python/pull/213\n",
    "        options=payload[\"options\"],\n",
    "        stream=False\n",
    "    )\n",
    "\n",
    "    return model_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "D5Pp6v3Mf2k6",
    "outputId": "33298c12-efe8-445e-e7e1-975bf6a5924d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'gemma2:27b'}\n"
     ]
    }
   ],
   "source": [
    "params = set_llama_params()\n",
    "\n",
    "if not params:\n",
    "  raise Exception(\"gemma exception\")\n",
    "\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "W0Buk1j7eHsd"
   },
   "source": [
    "## ANS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "hHkJYsjJeAuL"
   },
   "source": [
    "### Zero Shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "hOOcXbMudKpI"
   },
   "outputs": [],
   "source": [
    "df_ans_zs = pd.read_csv('./datasets/ANS/test.csv')\n",
    "\n",
    "# Initialize a list to store the prompts\n",
    "prompts = []\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in df_ans_zs.iterrows():\n",
    "    sentence = row['claim_s']\n",
    "    fake_flag = row['fake_flag']\n",
    "\n",
    "    # Generate prompt based on each row\n",
    "    prompt = f\"\"\"Determine whether the following text is real or fake. if real then output = 0 and if fake then output = 1. Output must be integer 0 or 1 alone. No text.\n",
    "\n",
    "Text: {sentence}\"\"\"\n",
    "\n",
    "    # Append the prompt along with sentence and fake flag to the list\n",
    "    prompts.append((sentence, fake_flag, prompt))\n",
    "\n",
    "# Convert the list of prompts into a new DataFrame\n",
    "prompts_df_ans_zs = pd.DataFrame(prompts, columns=['Sentence', 'Fake Flag', 'Prompt'])\n",
    "\n",
    "# Save the prompts DataFrame to a new CSV file\n",
    "prompts_df_ans_zs.to_csv('prompts_df_ans_zs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "UAjkJ5mLzdFU",
    "outputId": "075bd32c-257a-4c8d-9d7e-b9846f7d4c78"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Fake Flag</th>\n",
       "      <th>Prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>المبعوث الدولي يطالب تل أبيب وحماس بالتراجع حا...</td>\n",
       "      <td>0</td>\n",
       "      <td>Determine whether the following text is real o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>بورصات أوروبية تتعرض لضربة إيطالية</td>\n",
       "      <td>0</td>\n",
       "      <td>Determine whether the following text is real o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>بحسب وسائل إعلام أمريكية: تركيا تمتلك تسجيلات ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Determine whether the following text is real o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>حقائق عن رفع شركات السيارات لأسعار قطع الغيار</td>\n",
       "      <td>0</td>\n",
       "      <td>Determine whether the following text is real o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>من هو نبيل رجب الذي سُجن لأنه حطّ من هيبة البح...</td>\n",
       "      <td>0</td>\n",
       "      <td>Determine whether the following text is real o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>أسماء الأسد تخضع للعلاج من سرطان الثدي</td>\n",
       "      <td>0</td>\n",
       "      <td>Determine whether the following text is real o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>الرئيس الفرنسي أقنع ترامب ببقاء القوات الأمريك...</td>\n",
       "      <td>0</td>\n",
       "      <td>Determine whether the following text is real o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>في صحف عربية: جسد سوريا الممزق بين أمريكا وروسيا</td>\n",
       "      <td>0</td>\n",
       "      <td>Determine whether the following text is real o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>موسيقى صوفية جذورها أفريقية في لبنان</td>\n",
       "      <td>1</td>\n",
       "      <td>Determine whether the following text is real o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>تعرف على أردوغان الذى روّض العسكر و حكم ل16 عا...</td>\n",
       "      <td>0</td>\n",
       "      <td>Determine whether the following text is real o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>456 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence  Fake Flag  \\\n",
       "0    المبعوث الدولي يطالب تل أبيب وحماس بالتراجع حا...          0   \n",
       "1                   بورصات أوروبية تتعرض لضربة إيطالية          0   \n",
       "2    بحسب وسائل إعلام أمريكية: تركيا تمتلك تسجيلات ...          0   \n",
       "3        حقائق عن رفع شركات السيارات لأسعار قطع الغيار          0   \n",
       "4    من هو نبيل رجب الذي سُجن لأنه حطّ من هيبة البح...          0   \n",
       "..                                                 ...        ...   \n",
       "451             أسماء الأسد تخضع للعلاج من سرطان الثدي          0   \n",
       "452  الرئيس الفرنسي أقنع ترامب ببقاء القوات الأمريك...          0   \n",
       "453   في صحف عربية: جسد سوريا الممزق بين أمريكا وروسيا          0   \n",
       "454               موسيقى صوفية جذورها أفريقية في لبنان          1   \n",
       "455  تعرف على أردوغان الذى روّض العسكر و حكم ل16 عا...          0   \n",
       "\n",
       "                                                Prompt  \n",
       "0    Determine whether the following text is real o...  \n",
       "1    Determine whether the following text is real o...  \n",
       "2    Determine whether the following text is real o...  \n",
       "3    Determine whether the following text is real o...  \n",
       "4    Determine whether the following text is real o...  \n",
       "..                                                 ...  \n",
       "451  Determine whether the following text is real o...  \n",
       "452  Determine whether the following text is real o...  \n",
       "453  Determine whether the following text is real o...  \n",
       "454  Determine whether the following text is real o...  \n",
       "455  Determine whether the following text is real o...  \n",
       "\n",
       "[456 rows x 3 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts_df_ans_zs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "MjBNl3Tfk5yc"
   },
   "outputs": [],
   "source": [
    "# Define function to calculate metrics\n",
    "def calculate_metrics(test_set, params):\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in test_set.iterrows():\n",
    "        #sentence = row[\"claim_s\"]\n",
    "        sentence = re.sub(r'[\\W_]+', ' ', row[\"claim_s\"])\n",
    "        actual_label = row[\"fake_flag\"]\n",
    "\n",
    "        # Generate prompt based on each row\n",
    "        prompt = f\"\"\"Determine whether the following text is real or fake. if real then output = 0 and if fake then output = 1. Output must be integer 0 or 1 alone. No text.\n",
    "\n",
    "Text: {sentence}\"\"\"\n",
    "\n",
    "        # Call the get_completion function with prompt and params\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        response = get_completion(params, messages)\n",
    "        predicted_label = int(response.get(\"message\").get(\"content\"))\n",
    "        true_labels.append(actual_label)\n",
    "        predicted_labels.append(predicted_label)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels)\n",
    "    recall = recall_score(true_labels, predicted_labels)\n",
    "    f1 = f1_score(true_labels, predicted_labels)\n",
    "\n",
    "    return accuracy, precision, recall, f1, predicted_labels\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "lmepSSKSwoXk",
    "outputId": "010e00f7-3c6b-4e90-90b6-e162d1c4e486"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.5701754385964912\n",
      "Precision: 0.3402777777777778\n",
      "Recall: 0.32666666666666666\n",
      "F1 Score: 0.3333333333333333\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "accuracy, precision, recall, f1, predicted_ans_zs_gemma2 = calculate_metrics(df_ans_zs, params)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_ans_zs_gemma2)  # var name shoul've been 70b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ans_zs_gemma2 = [0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MXKjbrRtjS6c"
   },
   "source": [
    "### Zero Shot CoT Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "GbRsJF0ejS6c"
   },
   "outputs": [],
   "source": [
    "df_ans_zs_cot = pd.read_csv('./datasets/ANS/test.csv')\n",
    "\n",
    "# Initialize a list to store the prompts\n",
    "prompts = []\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in df_ans_zs_cot.iterrows():\n",
    "    sentence = row['claim_s']\n",
    "    fake_flag = row['fake_flag']\n",
    "\n",
    "    # Generate prompt based on each row (CoT)\n",
    "    prompt = f\"\"\"The output of this prompt must at length 1 with two possible values 0 or 1:\n",
    "    \n",
    "              Analyze the following statement to determine its authenticity by considering these steps:\n",
    "              1. Content Verification: Check if the claims made in the content can be independently verified with other credible information available.\n",
    "              2. Logical Consistency: Assess whether the statement is logically consistent and whether it contains contradictions or implausible assertions.\n",
    "\n",
    "              After carefully considering these points, determine whether the following text is real or fake. if real then output = 0 and if fake then output = 1\n",
    "\n",
    "              Text: {sentence}\n",
    "\n",
    "              Answer:\"\"\"\n",
    "\n",
    "    # Append the prompt along with sentence and fake flag to the list\n",
    "    prompts.append((sentence, fake_flag, prompt))\n",
    "\n",
    "# Convert the list of prompts into a new DataFrame\n",
    "prompts_df_ans_zs_cot = pd.DataFrame(prompts, columns=['Sentence', 'Fake Flag', 'Prompt'])\n",
    "\n",
    "# Save the prompts DataFrame to a new CSV file\n",
    "prompts_df_ans_zs_cot.to_csv('prompts_df_ans_zs_cot.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "rdhNnXuejS6d",
    "outputId": "e339c1b5-ac99-4a14-96ee-f54449a75db0"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Fake Flag</th>\n",
       "      <th>Prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>المبعوث الدولي يطالب تل أبيب وحماس بالتراجع حا...</td>\n",
       "      <td>0</td>\n",
       "      <td>The output of this prompt must at length 1 wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>بورصات أوروبية تتعرض لضربة إيطالية</td>\n",
       "      <td>0</td>\n",
       "      <td>The output of this prompt must at length 1 wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>بحسب وسائل إعلام أمريكية: تركيا تمتلك تسجيلات ...</td>\n",
       "      <td>0</td>\n",
       "      <td>The output of this prompt must at length 1 wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>حقائق عن رفع شركات السيارات لأسعار قطع الغيار</td>\n",
       "      <td>0</td>\n",
       "      <td>The output of this prompt must at length 1 wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>من هو نبيل رجب الذي سُجن لأنه حطّ من هيبة البح...</td>\n",
       "      <td>0</td>\n",
       "      <td>The output of this prompt must at length 1 wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>451</th>\n",
       "      <td>أسماء الأسد تخضع للعلاج من سرطان الثدي</td>\n",
       "      <td>0</td>\n",
       "      <td>The output of this prompt must at length 1 wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>452</th>\n",
       "      <td>الرئيس الفرنسي أقنع ترامب ببقاء القوات الأمريك...</td>\n",
       "      <td>0</td>\n",
       "      <td>The output of this prompt must at length 1 wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>453</th>\n",
       "      <td>في صحف عربية: جسد سوريا الممزق بين أمريكا وروسيا</td>\n",
       "      <td>0</td>\n",
       "      <td>The output of this prompt must at length 1 wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>454</th>\n",
       "      <td>موسيقى صوفية جذورها أفريقية في لبنان</td>\n",
       "      <td>1</td>\n",
       "      <td>The output of this prompt must at length 1 wit...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>455</th>\n",
       "      <td>تعرف على أردوغان الذى روّض العسكر و حكم ل16 عا...</td>\n",
       "      <td>0</td>\n",
       "      <td>The output of this prompt must at length 1 wit...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>456 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              Sentence  Fake Flag  \\\n",
       "0    المبعوث الدولي يطالب تل أبيب وحماس بالتراجع حا...          0   \n",
       "1                   بورصات أوروبية تتعرض لضربة إيطالية          0   \n",
       "2    بحسب وسائل إعلام أمريكية: تركيا تمتلك تسجيلات ...          0   \n",
       "3        حقائق عن رفع شركات السيارات لأسعار قطع الغيار          0   \n",
       "4    من هو نبيل رجب الذي سُجن لأنه حطّ من هيبة البح...          0   \n",
       "..                                                 ...        ...   \n",
       "451             أسماء الأسد تخضع للعلاج من سرطان الثدي          0   \n",
       "452  الرئيس الفرنسي أقنع ترامب ببقاء القوات الأمريك...          0   \n",
       "453   في صحف عربية: جسد سوريا الممزق بين أمريكا وروسيا          0   \n",
       "454               موسيقى صوفية جذورها أفريقية في لبنان          1   \n",
       "455  تعرف على أردوغان الذى روّض العسكر و حكم ل16 عا...          0   \n",
       "\n",
       "                                                Prompt  \n",
       "0    The output of this prompt must at length 1 wit...  \n",
       "1    The output of this prompt must at length 1 wit...  \n",
       "2    The output of this prompt must at length 1 wit...  \n",
       "3    The output of this prompt must at length 1 wit...  \n",
       "4    The output of this prompt must at length 1 wit...  \n",
       "..                                                 ...  \n",
       "451  The output of this prompt must at length 1 wit...  \n",
       "452  The output of this prompt must at length 1 wit...  \n",
       "453  The output of this prompt must at length 1 wit...  \n",
       "454  The output of this prompt must at length 1 wit...  \n",
       "455  The output of this prompt must at length 1 wit...  \n",
       "\n",
       "[456 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts_df_ans_zs_cot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prediction(content):\n",
    "    \"\"\"\n",
    "    Extracts the prediction (0 or 1) based on the content.\n",
    "\n",
    "    Parameters:\n",
    "    - content (str): The content from the LLM response.\n",
    "\n",
    "    Returns:\n",
    "    - int: 0 if the text is real, 1 if the text is fake.\n",
    "    \"\"\"\n",
    "    if re.search(r'\\b(fake|1)\\b', content, re.IGNORECASE):\n",
    "        return 1\n",
    "    elif re.search(r'\\b(real|0)\\b', content, re.IGNORECASE):\n",
    "        return 0\n",
    "    else:\n",
    "        # Default case if neither \"real\" nor \"fake\" is clearly indicated\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "sPjK0IL1jS6d"
   },
   "outputs": [],
   "source": [
    "# Define function to calculate metrics\n",
    "def calculate_metrics(test_set, params):\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in test_set.iterrows():\n",
    "        sentence = re.sub(r'[\\W_]+', ' ', row[\"claim_s\"])\n",
    "        actual_label = row[\"fake_flag\"]\n",
    "\n",
    "        # Generate prompt based on each row (CoT)\n",
    "        prompt = f\"\"\"The output of this prompt must at length 1 with two possible values 0 or 1:\n",
    "        \n",
    "        \n",
    "                  Analyze the following statement to determine its authenticity by considering these steps:\n",
    "                  1. Content Verification: Check if the claims made in the content can be independently verified with other credible information available.\n",
    "                  2. Logical Consistency: Assess whether the statement is logically consistent and whether it contains contradictions or implausible assertions.\n",
    "                  \n",
    "                  After carefully considering these points, determine whether the following text is real or fake. if real then output = 0 and if fake then output = 1\n",
    "                  \n",
    "                  Text: {sentence}\n",
    "\n",
    "                  Answer:\"\"\"\n",
    "\n",
    "        # Call the get_completion function with prompt and params\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        response = get_completion(params, messages)\n",
    "        print(response)\n",
    "        content = response.get(\"message\").get(\"content\")\n",
    "        predicted_label = get_prediction(content)\n",
    "        print(predicted_label)\n",
    "        none_count = 0\n",
    "        \n",
    "        if predicted_label is not None:\n",
    "            true_labels.append(actual_label)\n",
    "            predicted_labels.append(predicted_label)\n",
    "        else:\n",
    "            none_count += 1 \n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels)\n",
    "    recall = recall_score(true_labels, predicted_labels)\n",
    "    f1 = f1_score(true_labels, predicted_labels)\n",
    "\n",
    "    return accuracy, precision, recall, f1, predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "colab": {
     "background_save": true,
     "base_uri": "https://localhost:8080/"
    },
    "id": "cLEh2WDojS6d",
    "outputId": "b8f58653-5b53-4172-f7f4-1b091548f1ee",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:16:59.72237Z', 'message': {'role': 'assistant', 'content': \"It's impossible for me to definitively determine the authenticity of the provided Arabic text without further context and analysis.  \\n\\nHere's why:\\n\\n* **Language Barrier:** While I can process text, I don't understand the nuances of languages like Arabic. A human translator familiar with regional politics would be needed to accurately interpret the statement's meaning.\\n* **Lack of Context:** The text snippet is isolated. To assess its authenticity, I'd need information about:\\n    * **Source:** Where did this text originate? Is it from a reputable news outlet, a social media post, or an unknown source?\\n    * **Surrounding Information:** What events or discussions might this statement be referring to?\\n\\n**Therefore, I cannot provide a reliable output of 0 (real) or 1 (fake).**  \\n\\nTo get an accurate assessment, you would need to consult with someone who understands Arabic and has knowledge of the relevant geopolitical context. \\n\"}, 'done_reason': 'stop', 'done': True, 'total_duration': 14114146833, 'load_duration': 33872208, 'prompt_eval_count': 165, 'prompt_eval_duration': 1801893000, 'eval_count': 199, 'eval_duration': 12275937000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:17:00.317744Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 590385000, 'load_duration': 19886708, 'prompt_eval_count': 158, 'prompt_eval_duration': 383663000, 'eval_count': 4, 'eval_duration': 184586000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:17:01.135039Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 811812333, 'load_duration': 20043417, 'prompt_eval_count': 169, 'prompt_eval_duration': 605571000, 'eval_count': 4, 'eval_duration': 183812000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:17:01.692085Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 549979084, 'load_duration': 19945709, 'prompt_eval_count': 156, 'prompt_eval_duration': 350583000, 'eval_count': 4, 'eval_duration': 177295000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:17:02.218714Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 518289917, 'load_duration': 20295292, 'prompt_eval_count': 161, 'prompt_eval_duration': 324595000, 'eval_count': 4, 'eval_duration': 170098000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:17:02.904832Z', 'message': {'role': 'assistant', 'content': '0 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 678743167, 'load_duration': 20280875, 'prompt_eval_count': 171, 'prompt_eval_duration': 488680000, 'eval_count': 4, 'eval_duration': 166876000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:17:06.864268Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement translates to \"Death of Jóhann Jóhannsson, the famous Icelandic composer.\"  This information is verifiable through reputable news sources and biographical data. There are no logical inconsistencies in the statement. \\n\\n\\nLet me know if you\\'d like me to analyze another statement!'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3952464458, 'load_duration': 20371750, 'prompt_eval_count': 162, 'prompt_eval_duration': 303343000, 'eval_count': 66, 'eval_duration': 3626427000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:17:07.37817Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 507301958, 'load_duration': 20154541, 'prompt_eval_count': 150, 'prompt_eval_duration': 312050000, 'eval_count': 4, 'eval_duration': 173131000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:17:20.46705Z', 'message': {'role': 'assistant', 'content': 'I cannot provide a definitive answer of 0 or 1 for the authenticity of the statement. Here\\'s why:\\n\\n* **Language Barrier:** I am a text-based AI and while I can process many languages, determining the veracity of news often requires cultural context and understanding nuances that may be lost in translation.\\n* **Lack of Access to Real-Time Information:** I don\\'t have access to the internet to verify the statement against credible news sources.\\n\\n**To determine the authenticity of the text, you would need to:**\\n\\n1. **Translate it:** Get an accurate English translation of \"مقتل الناشطة الحقوقية سعاد العلي بإطلاق نار في البصرة\".\\n2. **Fact-Check:** Consult reputable news sources in Arabic and English that cover events in Iraq (where Basra is located). Look for reports on the death of a human rights activist named Saad Al-Ali. \\n\\nRemember, it\\'s crucial to rely on verified information from trusted sources when assessing potentially sensitive news. \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 13079401583, 'load_duration': 21288416, 'prompt_eval_count': 162, 'prompt_eval_duration': 327331000, 'eval_count': 213, 'eval_duration': 12728079000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:17:21.316861Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 843819083, 'load_duration': 20425542, 'prompt_eval_count': 149, 'prompt_eval_duration': 639664000, 'eval_count': 4, 'eval_duration': 181380000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:17:21.867105Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 544674416, 'load_duration': 20043708, 'prompt_eval_count': 153, 'prompt_eval_duration': 344688000, 'eval_count': 4, 'eval_duration': 177928000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:17:26.283174Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe text \"الصين تندد بالحرب التجارية الأميركية القاتلة للثقة\" translates to \"China condemns the American trade war that is deadly to trust.\" This statement reflects a real geopolitical issue and aligns with known stances of the Chinese government.  Therefore, it\\'s likely authentic. \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4409799584, 'load_duration': 20923292, 'prompt_eval_count': 159, 'prompt_eval_duration': 335325000, 'eval_count': 72, 'eval_duration': 4051190000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:17:26.817733Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 528689583, 'load_duration': 20479541, 'prompt_eval_count': 158, 'prompt_eval_duration': 331278000, 'eval_count': 4, 'eval_duration': 174453000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:17:32.74551Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement \"عائدات السياحة في الأردن تسجل رقما اقتصاديا جديدا\" translates to \"Tourism revenues in Jordan are recording a new economic figure.\"  This type of statement is plausible and often reported in news. It doesn\\'t contain any inherently illogical claims. \\n\\nWhile I cannot independently verify the specific economic figures, the general sentiment of tourism growth in Jordan is something that can be corroborated through further research. \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 5922415125, 'load_duration': 20384292, 'prompt_eval_count': 159, 'prompt_eval_duration': 331500000, 'eval_count': 97, 'eval_duration': 5568254000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:17:33.297327Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 546869208, 'load_duration': 20455375, 'prompt_eval_count': 159, 'prompt_eval_duration': 345998000, 'eval_count': 4, 'eval_duration': 178243000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:17:33.841377Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 535109792, 'load_duration': 21060334, 'prompt_eval_count': 156, 'prompt_eval_duration': 336453000, 'eval_count': 4, 'eval_duration': 175303000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:17:34.363686Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 516774416, 'load_duration': 20030958, 'prompt_eval_count': 157, 'prompt_eval_duration': 322619000, 'eval_count': 4, 'eval_duration': 171835000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:17:35.061491Z', 'message': {'role': 'assistant', 'content': '0 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 688184792, 'load_duration': 21076167, 'prompt_eval_count': 171, 'prompt_eval_duration': 497305000, 'eval_count': 4, 'eval_duration': 167317000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:17:44.381724Z', 'message': {'role': 'assistant', 'content': 'It\\'s impossible for me to definitively say whether the statement \"الاقتصاد الإيراني يتعرض لكارثة جراء العقوبات الأميركية\" (The Iranian economy is facing a catastrophe due to US sanctions) is real or fake without access to external information and analysis. \\n\\nHere\\'s why:\\n\\n* **I\\'m a language model, not a fact-checker:** My expertise lies in understanding and generating text, not verifying the truthfulness of statements.\\n* **Complex geopolitical situation:** The impact of US sanctions on the Iranian economy is a complex issue with varying opinions and interpretations. \\n\\nTo determine the authenticity of the statement, you would need to consult reliable news sources, economic reports, and expert analysis on Iran\\'s current economic situation. \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 9315558042, 'load_duration': 19779334, 'prompt_eval_count': 158, 'prompt_eval_duration': 301470000, 'eval_count': 157, 'eval_duration': 8992103000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:17:45.196099Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 807405292, 'load_duration': 20262958, 'prompt_eval_count': 148, 'prompt_eval_duration': 604143000, 'eval_count': 4, 'eval_duration': 180637000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:17:45.741939Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 540193333, 'load_duration': 20042583, 'prompt_eval_count': 155, 'prompt_eval_duration': 341626000, 'eval_count': 4, 'eval_duration': 176348000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:17:53.81753Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe text \"نفط ينخفض وسط مخاوف النمو\" translates to \"Oil falls amid growth concerns\" in English. This is a plausible and common headline, reflecting typical market fluctuations based on economic indicators.  \\n\\n* **Content Verification:** While I can\\'t verify real-time oil prices, the statement aligns with general economic trends where concerns about slowing growth often lead to decreased demand for commodities like oil.\\n* **Logical Consistency:** The statement is logically sound. Concerns about economic growth would reasonably lead to a decrease in oil prices. \\n\\n\\nTherefore, based on these factors, the text appears to be authentic.'}, 'done_reason': 'stop', 'done': True, 'total_duration': 8068141417, 'load_duration': 20295958, 'prompt_eval_count': 153, 'prompt_eval_duration': 321003000, 'eval_count': 134, 'eval_duration': 7724532000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:17:54.571346Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 747516542, 'load_duration': 20182792, 'prompt_eval_count': 168, 'prompt_eval_duration': 548331000, 'eval_count': 4, 'eval_duration': 176722000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:18:03.499638Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement \"انخفاض بأسعار النفط بالتزامن مع مخاوف النمو\" translates to \"Decline in oil prices coinciding with growth concerns.\" This is a plausible and often observed economic phenomenon.  \\n\\n* **Content Verification:** While I can\\'t access real-time data, it\\'s common knowledge that oil prices fluctuate based on various factors, including global economic outlook and demand. Concerns about slowing growth could lead to reduced demand for oil, hence the price decline.\\n* **Logical Consistency:** The statement is logically consistent. A decrease in oil prices often accompanies worries about a slowdown in economic activity. \\n\\n\\nTherefore, based on these considerations, the statement appears authentic.'}, 'done_reason': 'stop', 'done': True, 'total_duration': 8921843458, 'load_duration': 19831375, 'prompt_eval_count': 160, 'prompt_eval_duration': 321925000, 'eval_count': 149, 'eval_duration': 8577927000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:18:04.044488Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 538516000, 'load_duration': 19672042, 'prompt_eval_count': 158, 'prompt_eval_duration': 340997000, 'eval_count': 4, 'eval_duration': 175127000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:18:04.567572Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 516288875, 'load_duration': 20183458, 'prompt_eval_count': 156, 'prompt_eval_duration': 323372000, 'eval_count': 4, 'eval_duration': 170559000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:18:05.070625Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 497028542, 'load_duration': 20001792, 'prompt_eval_count': 157, 'prompt_eval_duration': 308373000, 'eval_count': 4, 'eval_duration': 165951000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:18:10.394594Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe text \"أزمة إيطاليا تضرب بورصات أوروبية\" translates to \"Italy\\'s crisis hits European stock markets.\" This statement is a plausible headline and reflects real-world events. Economic crises in one country can indeed have ripple effects on financial markets in other countries, particularly within the same region like Europe. \\n\\n\\nLet me know if you\\'d like me to analyze another statement!'}, 'done_reason': 'stop', 'done': True, 'total_duration': 5317976000, 'load_duration': 20108458, 'prompt_eval_count': 155, 'prompt_eval_duration': 301046000, 'eval_count': 90, 'eval_duration': 4994750000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:18:10.937792Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 539423042, 'load_duration': 19760042, 'prompt_eval_count': 163, 'prompt_eval_duration': 339570000, 'eval_count': 4, 'eval_duration': 177655000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:18:11.488396Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 541842458, 'load_duration': 20991333, 'prompt_eval_count': 162, 'prompt_eval_duration': 341573000, 'eval_count': 4, 'eval_duration': 176786000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:18:12.239336Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 745042458, 'load_duration': 20201916, 'prompt_eval_count': 167, 'prompt_eval_duration': 546545000, 'eval_count': 4, 'eval_duration': 175527000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:18:12.770497Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 523177667, 'load_duration': 20517959, 'prompt_eval_count': 163, 'prompt_eval_duration': 329209000, 'eval_count': 4, 'eval_duration': 171274000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:18:13.268456Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 490746375, 'load_duration': 19945125, 'prompt_eval_count': 152, 'prompt_eval_duration': 302735000, 'eval_count': 4, 'eval_duration': 165733000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:18:24.756937Z', 'message': {'role': 'assistant', 'content': 'It\\'s impossible for me to definitively determine the authenticity of that statement. Here\\'s why:\\n\\n* **Language Barrier:** I don\\'t understand Arabic.  To accurately assess the content, I would need a translation. \\n* **Context is Crucial:** Even with a translation, understanding the political climate and news sources in Egypt would be essential to verify the claim.\\n\\n**Therefore, I cannot provide an output of 0 or 1.** \\n\\nTo get an accurate assessment, you would need to:\\n\\n1. **Translate the text:** Get a reliable translation of \"السيسي يفشل فى الوصول لولاية ثانية فى رئاسة مصر\".\\n2. **Research Egyptian News:** Consult reputable news sources from Egypt to see if this claim is reported elsewhere. \\n3. **Consider the Source:**  Where did you encounter this statement? Knowing the source can provide clues about its potential reliability. \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 11481852708, 'load_duration': 21221333, 'prompt_eval_count': 160, 'prompt_eval_duration': 302787000, 'eval_count': 191, 'eval_duration': 11155622000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:18:25.278946Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 512709416, 'load_duration': 21508666, 'prompt_eval_count': 152, 'prompt_eval_duration': 317810000, 'eval_count': 4, 'eval_duration': 171128000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:18:25.790273Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 503271458, 'load_duration': 20358333, 'prompt_eval_count': 163, 'prompt_eval_duration': 312223000, 'eval_count': 4, 'eval_duration': 168448000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:18:37.871305Z', 'message': {'role': 'assistant', 'content': \"It's impossible for me to definitively determine the authenticity of that statement without access to external information.  Here's why:\\n\\n* **Language Barrier:** The text is in Arabic, and I need context to understand its meaning fully. \\n* **Fact-Checking Requires Sources:** To verify the claim about OPEC reducing production despite falling oil prices, I would need to consult reliable news sources, economic reports, or official OPEC statements.\\n\\n**Therefore, I cannot provide an output of 0 or 1.**  \\n\\nTo get a reliable answer, you'd want to:\\n\\n1. **Translate the text:** Get an accurate English translation.\\n2. **Research OPEC Decisions:** Look for news articles or press releases from OPEC regarding recent production decisions.\\n3. **Compare Oil Prices:** Check historical oil price data to see if prices have indeed been falling. \\n\\n\\nLet me know if you have any other questions that don't require external fact-checking!\"}, 'done_reason': 'stop', 'done': True, 'total_duration': 12077745750, 'load_duration': 19982375, 'prompt_eval_count': 162, 'prompt_eval_duration': 305173000, 'eval_count': 198, 'eval_duration': 11750079000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:18:38.447513Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 570448125, 'load_duration': 20087125, 'prompt_eval_count': 162, 'prompt_eval_duration': 365081000, 'eval_count': 4, 'eval_duration': 182908000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:18:39.01329Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 558180334, 'load_duration': 20717959, 'prompt_eval_count': 162, 'prompt_eval_duration': 357006000, 'eval_count': 4, 'eval_duration': 178035000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:18:39.557103Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 535018084, 'load_duration': 21230917, 'prompt_eval_count': 156, 'prompt_eval_duration': 336787000, 'eval_count': 4, 'eval_duration': 174532000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:18:40.075827Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 511583333, 'load_duration': 20736208, 'prompt_eval_count': 154, 'prompt_eval_duration': 318448000, 'eval_count': 4, 'eval_duration': 170245000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:18:40.570636Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 490332917, 'load_duration': 19499917, 'prompt_eval_count': 153, 'prompt_eval_duration': 301085000, 'eval_count': 4, 'eval_duration': 167626000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:18:41.067693Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 491128416, 'load_duration': 19857500, 'prompt_eval_count': 156, 'prompt_eval_duration': 302057000, 'eval_count': 4, 'eval_duration': 166523000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:18:41.559032Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 486244250, 'load_duration': 19929292, 'prompt_eval_count': 166, 'prompt_eval_duration': 296644000, 'eval_count': 4, 'eval_duration': 167094000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:18:42.241978Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 676049209, 'load_duration': 19862459, 'prompt_eval_count': 167, 'prompt_eval_duration': 487242000, 'eval_count': 4, 'eval_duration': 166373000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:18:42.740535Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 492551250, 'load_duration': 19509042, 'prompt_eval_count': 161, 'prompt_eval_duration': 303367000, 'eval_count': 4, 'eval_duration': 167414000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:18:51.688132Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement \"الذهب يتعافى رغم أزمة إيطاليا\" translates to \"Gold recovers despite the Italian crisis.\" This type of statement is commonly found in financial news and analysis.  \\n\\n* **Content Verification:** While I cannot access real-time financial data, it\\'s plausible that gold prices could rise during an economic crisis in a specific country like Italy. Gold is often seen as a safe haven asset.\\n* **Logical Consistency:** The statement is logically consistent. It presents a cause (Italian crisis) and a potential effect (gold recovery). \\n\\n\\nTherefore, based on the general understanding of financial markets, the statement appears to be plausible and potentially real.'}, 'done_reason': 'stop', 'done': True, 'total_duration': 8941895333, 'load_duration': 19734875, 'prompt_eval_count': 154, 'prompt_eval_duration': 300622000, 'eval_count': 144, 'eval_duration': 8619344000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:18:56.544325Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement translates to \"The United Nations announces a ceasefire in the Libyan capital.\"  This type of announcement is plausible and aligns with the UN\\'s role in international peacekeeping.  \\n\\nWhile I cannot independently verify the specific details of a ceasefire, the general content is consistent with real-world events and the UN\\'s mandate. \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4851048375, 'load_duration': 19321709, 'prompt_eval_count': 159, 'prompt_eval_duration': 358756000, 'eval_count': 76, 'eval_duration': 4470571000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:19:04.943586Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe text translates to \"Weak earthquake on the Iran-Iraq border.\" This type of statement is common and factually plausible.  \\n\\n* **Content Verification:** While I cannot independently verify the earthquake\\'s occurrence, such events are regularly reported by seismological agencies and news outlets. \\n* **Logical Consistency:** The statement is logically consistent and doesn\\'t contain any implausible assertions. Earthquakes occur frequently in seismically active regions like the Iran-Iraq border. \\n\\n\\nTherefore, based on the likelihood of earthquakes in that region and the lack of contradictory information, the text appears to be real.'}, 'done_reason': 'stop', 'done': True, 'total_duration': 8391995125, 'load_duration': 20083583, 'prompt_eval_count': 156, 'prompt_eval_duration': 382673000, 'eval_count': 130, 'eval_duration': 7986937000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:19:12.443486Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement translates to \"Stability in the Middle East helps stabilize oil.\" This is a generally accepted geopolitical principle.  \\n\\n* **Content Verification:** The relationship between Middle Eastern stability and oil prices is well-documented and discussed by experts. \\n* **Logical Consistency:** The statement makes logical sense. Political instability in the region often disrupts oil production and supply chains, leading to price fluctuations. Conversely, stability tends to promote smoother operations and more predictable pricing. \\n\\n\\nLet me know if you\\'d like to analyze another statement!'}, 'done_reason': 'stop', 'done': True, 'total_duration': 7494163458, 'load_duration': 20581958, 'prompt_eval_count': 155, 'prompt_eval_duration': 380061000, 'eval_count': 115, 'eval_duration': 7091284000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:19:13.042433Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 589739708, 'load_duration': 21210750, 'prompt_eval_count': 150, 'prompt_eval_duration': 380928000, 'eval_count': 4, 'eval_duration': 185346000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:19:21.413671Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement translates to \"France hosts a Kurdish delegation, and Turkey criticizes it.\" This type of geopolitical event is plausible and aligns with known tensions between Turkey and Kurdish groups.  \\n\\n* **Content Verification:** While I cannot independently verify the specific event, it\\'s consistent with broader political dynamics in the region.\\n* **Logical Consistency:** The statement makes sense logically. France hosting a Kurdish delegation could indeed lead to criticism from Turkey given their history and perspectives on Kurdish autonomy. \\n\\n\\nTherefore, based on the plausibility of the content and its logical consistency, the statement appears to be real.'}, 'done_reason': 'stop', 'done': True, 'total_duration': 8365068416, 'load_duration': 19897166, 'prompt_eval_count': 156, 'prompt_eval_duration': 363414000, 'eval_count': 128, 'eval_duration': 7979148000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:19:22.001149Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 581740750, 'load_duration': 20458167, 'prompt_eval_count': 153, 'prompt_eval_duration': 374439000, 'eval_count': 4, 'eval_duration': 184635000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:19:22.567794Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 559477542, 'load_duration': 20396750, 'prompt_eval_count': 157, 'prompt_eval_duration': 358036000, 'eval_count': 4, 'eval_duration': 178777000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:19:23.113067Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 539241166, 'load_duration': 20258416, 'prompt_eval_count': 164, 'prompt_eval_duration': 342128000, 'eval_count': 4, 'eval_duration': 174661000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:19:23.630994Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 512085083, 'load_duration': 20011750, 'prompt_eval_count': 160, 'prompt_eval_duration': 320391000, 'eval_count': 4, 'eval_duration': 169184000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:19:24.133605Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 497373500, 'load_duration': 20734500, 'prompt_eval_count': 154, 'prompt_eval_duration': 306265000, 'eval_count': 4, 'eval_duration': 167973000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:19:24.63444Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 494455292, 'load_duration': 20182709, 'prompt_eval_count': 162, 'prompt_eval_duration': 304935000, 'eval_count': 4, 'eval_duration': 167040000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:19:25.13383Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 493222084, 'load_duration': 20484459, 'prompt_eval_count': 157, 'prompt_eval_duration': 302675000, 'eval_count': 4, 'eval_duration': 167787000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:19:25.632266Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 493204833, 'load_duration': 20230500, 'prompt_eval_count': 160, 'prompt_eval_duration': 303135000, 'eval_count': 4, 'eval_duration': 167575000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:19:26.125665Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 489611875, 'load_duration': 19866792, 'prompt_eval_count': 154, 'prompt_eval_duration': 300996000, 'eval_count': 4, 'eval_duration': 166482000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:19:43.994615Z', 'message': {'role': 'assistant', 'content': 'It\\'s impossible for me to definitively label this statement as \"real\" or \"fake\" with a simple 0 or 1. Here\\'s why:\\n\\n* **Nuance and Context:** The statement  \"إسرائيل استخدمت قوة غير متكافئة ضد المحتجين على حدود غزة\" (Israel used disproportionate force against protesters at the Gaza border) is highly charged and politically sensitive. Determining \"disproportionate force\" requires in-depth analysis of the specific events, military tactics used, and international legal frameworks. \\n* **Bias and Perspective:**  Different sources may interpret the same event through different lenses, leading to varying conclusions about the use of force.\\n\\n**What I can do:**\\n\\nI can help you find more information from reputable sources to form your own informed opinion. Consider researching:\\n\\n* **Reports from international organizations:** Look for reports from groups like the UN Human Rights Council or Amnesty International that investigate such incidents.\\n* **News coverage from diverse outlets:** Compare reporting from different news organizations with varying perspectives to get a broader understanding.\\n* **Academic analyses:** Search for scholarly articles and studies that examine the Israeli-Palestinian conflict and the use of force in this context. \\n\\n\\nRemember, critical thinking and consulting multiple sources are essential when evaluating complex and sensitive statements like this one. \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 17863024500, 'load_duration': 20293042, 'prompt_eval_count': 159, 'prompt_eval_duration': 302379000, 'eval_count': 271, 'eval_duration': 17538048000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:19:44.613152Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 611037708, 'load_duration': 20635541, 'prompt_eval_count': 164, 'prompt_eval_duration': 399001000, 'eval_count': 4, 'eval_duration': 189218000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:19:45.208942Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 589508250, 'load_duration': 20285875, 'prompt_eval_count': 160, 'prompt_eval_duration': 382192000, 'eval_count': 4, 'eval_duration': 184552000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:19:46.006001Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 791621000, 'load_duration': 20171875, 'prompt_eval_count': 167, 'prompt_eval_duration': 588751000, 'eval_count': 4, 'eval_duration': 180459000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:19:46.558714Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 545863500, 'load_duration': 20246542, 'prompt_eval_count': 159, 'prompt_eval_duration': 346738000, 'eval_count': 4, 'eval_duration': 176620000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:19:47.090331Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 524281542, 'load_duration': 20112000, 'prompt_eval_count': 164, 'prompt_eval_duration': 329981000, 'eval_count': 4, 'eval_duration': 171254000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:19:47.600662Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 506049791, 'load_duration': 19807416, 'prompt_eval_count': 163, 'prompt_eval_duration': 315721000, 'eval_count': 4, 'eval_duration': 168460000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:19:48.099425Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 492874042, 'load_duration': 19877917, 'prompt_eval_count': 160, 'prompt_eval_duration': 304800000, 'eval_count': 4, 'eval_duration': 165819000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:19:48.596919Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 491267875, 'load_duration': 20144166, 'prompt_eval_count': 157, 'prompt_eval_duration': 301587000, 'eval_count': 4, 'eval_duration': 167241000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:19:49.097234Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 494235208, 'load_duration': 20378792, 'prompt_eval_count': 162, 'prompt_eval_duration': 304358000, 'eval_count': 4, 'eval_duration': 167437000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:19:49.589854Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 486939584, 'load_duration': 19911125, 'prompt_eval_count': 166, 'prompt_eval_duration': 296304000, 'eval_count': 4, 'eval_duration': 168059000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:19:50.090274Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 494952875, 'load_duration': 20074208, 'prompt_eval_count': 159, 'prompt_eval_duration': 304007000, 'eval_count': 4, 'eval_duration': 168378000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:19:50.60025Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 503456709, 'load_duration': 20528459, 'prompt_eval_count': 157, 'prompt_eval_duration': 310330000, 'eval_count': 4, 'eval_duration': 170614000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:19:51.121054Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 516717583, 'load_duration': 20424000, 'prompt_eval_count': 157, 'prompt_eval_duration': 320023000, 'eval_count': 4, 'eval_duration': 174035000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:19:51.657013Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 529844583, 'load_duration': 20197417, 'prompt_eval_count': 163, 'prompt_eval_duration': 331417000, 'eval_count': 4, 'eval_duration': 175824000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:19:52.192274Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 531529917, 'load_duration': 20458584, 'prompt_eval_count': 153, 'prompt_eval_duration': 333381000, 'eval_count': 4, 'eval_duration': 175493000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:19:52.741187Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 542931792, 'load_duration': 20125834, 'prompt_eval_count': 157, 'prompt_eval_duration': 341891000, 'eval_count': 4, 'eval_duration': 178572000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:19:53.291669Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 544455917, 'load_duration': 20305125, 'prompt_eval_count': 159, 'prompt_eval_duration': 344695000, 'eval_count': 4, 'eval_duration': 177113000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:19:53.840801Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 543622792, 'load_duration': 20583667, 'prompt_eval_count': 156, 'prompt_eval_duration': 342476000, 'eval_count': 4, 'eval_duration': 178290000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:19:54.387978Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 541739916, 'load_duration': 20142541, 'prompt_eval_count': 162, 'prompt_eval_duration': 342944000, 'eval_count': 4, 'eval_duration': 176401000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:19:54.930608Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 536843458, 'load_duration': 19919208, 'prompt_eval_count': 164, 'prompt_eval_duration': 338562000, 'eval_count': 4, 'eval_duration': 175753000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:19:55.456487Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 521054250, 'load_duration': 19657917, 'prompt_eval_count': 155, 'prompt_eval_duration': 326369000, 'eval_count': 4, 'eval_duration': 173011000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:19:55.980616Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 519778292, 'load_duration': 19977209, 'prompt_eval_count': 153, 'prompt_eval_duration': 322446000, 'eval_count': 4, 'eval_duration': 174722000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:19:56.512394Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 525690625, 'load_duration': 20704792, 'prompt_eval_count': 164, 'prompt_eval_duration': 328287000, 'eval_count': 4, 'eval_duration': 174396000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:20:12.243635Z', 'message': {'role': 'assistant', 'content': 'It\\'s impossible for me to definitively say whether a news statement is \"real\" or \"fake\" based solely on the text provided.  Here\\'s why:\\n\\n* **I lack real-world knowledge:** I am a language model and don\\'t have access to the internet to verify information against credible sources.\\n* **Context is crucial:** Understanding the authenticity of a news statement often requires knowing the source, its reputation, and the broader context surrounding the event. \\n\\n**To determine the authenticity of the text you provided (\"سوريا التوصل إلى اتفاق لإجلاء الجرحى من مدينة دوما\"), you would need to:**\\n\\n1. **Identify the source:** Where did this text come from? A reputable news organization, a social media post, an unknown website?\\n2. **Cross-reference:** Check if other reliable news sources are reporting on a similar event in Douma, Syria. \\n3. **Consider potential biases:** Is there any reason why the source might be presenting biased or inaccurate information?\\n\\n\\nLet me know if you have any other questions about language or text analysis! \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 15724808500, 'load_duration': 20462416, 'prompt_eval_count': 158, 'prompt_eval_duration': 324041000, 'eval_count': 229, 'eval_duration': 15378022000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:20:12.896437Z', 'message': {'role': 'assistant', 'content': '0 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 644240333, 'load_duration': 21121250, 'prompt_eval_count': 157, 'prompt_eval_duration': 423688000, 'eval_count': 4, 'eval_duration': 197078000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:20:13.511422Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 611067333, 'load_duration': 19143041, 'prompt_eval_count': 159, 'prompt_eval_duration': 400810000, 'eval_count': 4, 'eval_duration': 188954000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:20:21.555596Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement translates to \"Gnawa music of Morocco is Sufi music with African roots.\" This is a **factually accurate statement**.  \\n\\n* **Content Verification:** Gnawa music is indeed a genre of Moroccan music with strong Sufi influences and origins tracing back to West Africa. This information can be easily verified through various sources like encyclopedias, music databases, and academic articles.\\n* **Logical Consistency:** The statement is logically sound and doesn\\'t contain any contradictions. \\n\\n\\nTherefore, the text is real.'}, 'done_reason': 'stop', 'done': True, 'total_duration': 8040390458, 'load_duration': 19776417, 'prompt_eval_count': 158, 'prompt_eval_duration': 384790000, 'eval_count': 114, 'eval_duration': 7633419000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:20:22.176106Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 611274583, 'load_duration': 20527958, 'prompt_eval_count': 155, 'prompt_eval_duration': 400157000, 'eval_count': 4, 'eval_duration': 188128000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:20:22.771611Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 589498666, 'load_duration': 20140750, 'prompt_eval_count': 155, 'prompt_eval_duration': 381417000, 'eval_count': 4, 'eval_duration': 185309000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:20:23.346535Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 569190791, 'load_duration': 19627625, 'prompt_eval_count': 155, 'prompt_eval_duration': 364713000, 'eval_count': 4, 'eval_duration': 182200000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:20:24.131477Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 775807625, 'load_duration': 20755916, 'prompt_eval_count': 177, 'prompt_eval_duration': 574562000, 'eval_count': 4, 'eval_duration': 178233000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:20:24.679495Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 542210917, 'load_duration': 20509542, 'prompt_eval_count': 158, 'prompt_eval_duration': 343233000, 'eval_count': 4, 'eval_duration': 176271000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:20:33.397327Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe text \"السيسي يؤدي اليمين الدستورية رئيسا لولاية ثانية\" translates to \"Sisi takes the constitutional oath for a second term.\" This statement refers to Abdel Fattah el-Sisi, the President of Egypt.  \\n\\n* **Content Verification:** This event is verifiable through reputable news sources. \\n* **Logical Consistency:** The statement is logically consistent as it aligns with the political process in Egypt where presidents can serve multiple terms.\\n\\n\\nTherefore, based on content verification and logical consistency, the text appears to be authentic.'}, 'done_reason': 'stop', 'done': True, 'total_duration': 8713912916, 'load_duration': 20236666, 'prompt_eval_count': 160, 'prompt_eval_duration': 332461000, 'eval_count': 122, 'eval_duration': 8358775000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:20:34.016133Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 612951167, 'load_duration': 19730000, 'prompt_eval_count': 156, 'prompt_eval_duration': 399566000, 'eval_count': 4, 'eval_duration': 191079000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:20:45.115234Z', 'message': {'role': 'assistant', 'content': 'It\\'s impossible to definitively determine the authenticity of the statement \"عملة بيتكوين تقفز لأعلى مستوى في 6 أسابيع\" (Bitcoin jumps to a six-week high) without access to real-time market data.  \\n\\nHere\\'s why:\\n\\n* **Content Verification:** To verify this, we\\'d need to check current Bitcoin prices against historical data from the past six weeks.\\n* **Logical Consistency:** The statement itself is logically consistent. Cryptocurrency prices fluctuate, so a jump to a six-week high is plausible. \\n\\n**Therefore, I cannot provide a definitive 0 or 1 answer.**  You would need to consult financial news sources or cryptocurrency tracking websites to confirm the accuracy of the statement. \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 11090952083, 'load_duration': 21678708, 'prompt_eval_count': 159, 'prompt_eval_duration': 395385000, 'eval_count': 154, 'eval_duration': 10671622000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:21:05.99931Z', 'message': {'role': 'assistant', 'content': 'It\\'s impossible for me to definitively label this statement as \"real\" or \"fake\" with a simple 0 or 1. Here\\'s why:\\n\\n* **Nuance and Context:** The statement  \"استخدمت إسرائيل قوة غير متكافئة ضد المعارضين على حدود غزة\" (Israel used disproportionate force against opponents on the Gaza border) is highly charged and politically sensitive. Determining its \"authenticity\" requires deep understanding of the Israeli-Palestinian conflict, military tactics, and international law regarding proportionality in warfare. \\n\\n* **Subjectivity:**  The concept of \"disproportionate force\" is subjective and often debated. What one side considers disproportionate, another might view as necessary for self-defense.\\n\\n* **Lack of Verification Data:** I don\\'t have access to real-time information or the ability to verify specific military actions. \\n\\n\\n**Instead of a simple 0 or 1, a more responsible approach would be to:**\\n\\n1. **Acknowledge the complexity:** State that the issue is multifaceted and requires careful consideration of various perspectives.\\n2. **Highlight the need for further research:** Encourage seeking information from reputable news sources, human rights organizations, and academic studies on the Israeli-Palestinian conflict.\\n3. **Promote critical thinking:**  Emphasize the importance of evaluating information critically, considering biases, and understanding different narratives. \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 20879066000, 'load_duration': 19841292, 'prompt_eval_count': 160, 'prompt_eval_duration': 458398000, 'eval_count': 285, 'eval_duration': 20398845000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:21:13.084433Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe text appears to be a credible news headline in Arabic. It translates to \"International envoy to Israel and Gaza urges Tel Aviv and Hamas to step back from the brink of another war.\"  This type of statement aligns with ongoing geopolitical tensions in the region and is consistent with the role of international envoys in mediating conflicts. \\n\\n\\nLet me know if you\\'d like me to analyze another piece of text!'}, 'done_reason': 'stop', 'done': True, 'total_duration': 7076480959, 'load_duration': 20279084, 'prompt_eval_count': 167, 'prompt_eval_duration': 727258000, 'eval_count': 90, 'eval_duration': 6326814000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:21:13.778934Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 687940458, 'load_duration': 20837666, 'prompt_eval_count': 155, 'prompt_eval_duration': 458280000, 'eval_count': 4, 'eval_duration': 206535000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:21:14.416737Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 632394167, 'load_duration': 20233083, 'prompt_eval_count': 163, 'prompt_eval_duration': 418703000, 'eval_count': 4, 'eval_duration': 191056000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:21:31.278366Z', 'message': {'role': 'assistant', 'content': 'It\\'s impossible to definitively label this text as \"real\" or \"fake\" based solely on the provided information. Here\\'s why:\\n\\n* **Translation:** The text is in Arabic and translates to \"Canada\\'s crisis with Saudi Arabia is increasing due to human rights.\" This statement itself could be true, reflecting a real geopolitical situation.\\n* **Lack of Context:** We don\\'t have any context about the source of this text. Is it from a reputable news outlet? A social media post?  A political blog? The source heavily influences its credibility.\\n\\n**To determine authenticity, we would need:**\\n\\n1. **Source Verification:** Identify where the text originated and assess the reliability of that source.\\n2. **Fact-Checking:** Cross-reference the claims made in the text with other credible sources to see if they align.\\n\\n\\n**Therefore, I cannot provide a definitive 0 or 1 output.** \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 16856321333, 'load_duration': 20496000, 'prompt_eval_count': 155, 'prompt_eval_duration': 384376000, 'eval_count': 192, 'eval_duration': 16449428000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:21:31.997692Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 715320125, 'load_duration': 20039958, 'prompt_eval_count': 157, 'prompt_eval_duration': 477049000, 'eval_count': 4, 'eval_duration': 216180000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:21:32.661041Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 652194625, 'load_duration': 20175292, 'prompt_eval_count': 151, 'prompt_eval_duration': 432517000, 'eval_count': 4, 'eval_duration': 196915000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:21:33.275707Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 608252625, 'load_duration': 20399750, 'prompt_eval_count': 159, 'prompt_eval_duration': 397850000, 'eval_count': 4, 'eval_duration': 187707000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:21:33.863548Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 581347834, 'load_duration': 19959834, 'prompt_eval_count': 153, 'prompt_eval_duration': 374562000, 'eval_count': 4, 'eval_duration': 184368000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:21:34.433323Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 563519958, 'load_duration': 20109083, 'prompt_eval_count': 160, 'prompt_eval_duration': 360662000, 'eval_count': 4, 'eval_duration': 180681000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:21:52.738237Z', 'message': {'role': 'assistant', 'content': 'It\\'s impossible for me to definitively say whether the statement \"السيسي يصرح بأن مصر ستصبح مركز إقليمي للطاقة\" (translated as \"Sisi declares that Egypt will become a regional energy hub\") is real or fake without access to external information. \\n\\nHere\\'s why:\\n\\n* **I lack real-time information:** I am a language model and do not have access to the internet to verify news sources or statements made by political figures.\\n* **Context is crucial:**  Understanding the authenticity of this statement requires knowing when it was supposedly made, the context surrounding it, and potential corroborating evidence from reliable news outlets.\\n\\n**To determine if the statement is real or fake, you would need to:**\\n\\n1. **Find a credible source:** Look for reputable news organizations reporting on Sisi\\'s statements.\\n2. **Check the date:** Ensure the reported statement aligns with a timeframe when Sisi might have made such a declaration.\\n3. **Look for corroboration:** See if other sources are reporting on the same statement.\\n\\n\\nLet me know if you have any other questions that don\\'t require real-time information access! \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 18298771458, 'load_duration': 20238750, 'prompt_eval_count': 158, 'prompt_eval_duration': 345846000, 'eval_count': 242, 'eval_duration': 17930132000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:22:06.335921Z', 'message': {'role': 'assistant', 'content': \"It's impossible to definitively determine the authenticity of the Arabic text provided without further context and analysis.  \\n\\nHere's why:\\n\\n* **Language Barrier:** I am a text-based AI and cannot understand the meaning of the Arabic text. \\n* **Lack of Context:** The statement is presented in isolation. Knowing the source, surrounding information, or intended audience would be crucial for assessing its authenticity.\\n\\n**To determine if the text is real or fake, you would need:**\\n\\n1. **Translation:** Get an accurate translation of the Arabic text into a language you understand.\\n2. **Fact-Checking:** Verify the claims made in the translated text against reliable news sources and information about the situation in Douma, Syria. \\n\\n\\nLet me know if you have the translated text, and I can help you with the fact-checking step! \\n\"}, 'done_reason': 'stop', 'done': True, 'total_duration': 13591829167, 'load_duration': 20389000, 'prompt_eval_count': 160, 'prompt_eval_duration': 466441000, 'eval_count': 177, 'eval_duration': 13102321000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:22:15.509317Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement \"منع التعامل بالعملات المعدنية في الهند\" translates to \"Ban on the use of coins in India\".  While this might sound unusual, it\\'s important to note that India has been progressively moving towards a cashless society. The government has implemented policies encouraging digital payments and reducing reliance on physical currency.\\n\\nTherefore, while a complete ban on coins is unlikely, the statement could be interpreted as reflecting a trend towards reduced coin usage in India.  \\n\\n\\nLet me know if you\\'d like to analyze another statement! \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 9167334250, 'load_duration': 20190416, 'prompt_eval_count': 153, 'prompt_eval_duration': 472833000, 'eval_count': 119, 'eval_duration': 8672087000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:22:16.497486Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 980060833, 'load_duration': 21068542, 'prompt_eval_count': 167, 'prompt_eval_duration': 745297000, 'eval_count': 4, 'eval_duration': 210873000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:22:17.135239Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 633011958, 'load_duration': 20433041, 'prompt_eval_count': 157, 'prompt_eval_duration': 418931000, 'eval_count': 4, 'eval_duration': 191087000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:22:17.738446Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 598137125, 'load_duration': 20661042, 'prompt_eval_count': 160, 'prompt_eval_duration': 388772000, 'eval_count': 4, 'eval_duration': 186500000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:22:18.318325Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 572941917, 'load_duration': 20686167, 'prompt_eval_count': 155, 'prompt_eval_duration': 367639000, 'eval_count': 4, 'eval_duration': 182206000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:22:18.882056Z', 'message': {'role': 'assistant', 'content': '0 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 557975625, 'load_duration': 20750833, 'prompt_eval_count': 163, 'prompt_eval_duration': 356499000, 'eval_count': 4, 'eval_duration': 178138000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:22:19.428334Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 541404500, 'load_duration': 20502291, 'prompt_eval_count': 158, 'prompt_eval_duration': 342971000, 'eval_count': 4, 'eval_duration': 175422000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:22:19.972286Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 538371208, 'load_duration': 21595083, 'prompt_eval_count': 156, 'prompt_eval_duration': 337935000, 'eval_count': 4, 'eval_duration': 176128000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:22:30.354621Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe text \"مارس ارتفاع إيرادات قناة السويس\" translates to \"March saw an increase in Suez Canal revenues.\" This is a plausible statement and likely refers to financial data about the Suez Canal.  \\n\\n* **Content Verification:** While I cannot directly verify the accuracy of the revenue figures, it\\'s common for organizations like the Suez Canal Authority to release financial reports. \\n* **Logical Consistency:** The statement is logically consistent. It states a factual event (revenue increase) and specifies a timeframe (March).\\n\\n\\nTherefore, based on the plausibility and lack of contradictions, the text appears to be real.'}, 'done_reason': 'stop', 'done': True, 'total_duration': 10374956667, 'load_duration': 20123542, 'prompt_eval_count': 152, 'prompt_eval_duration': 338464000, 'eval_count': 134, 'eval_duration': 10014355000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:22:31.102702Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 739749041, 'load_duration': 20890791, 'prompt_eval_count': 156, 'prompt_eval_duration': 496976000, 'eval_count': 4, 'eval_duration': 219558000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:22:31.77159Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 664735583, 'load_duration': 20225792, 'prompt_eval_count': 153, 'prompt_eval_duration': 443163000, 'eval_count': 4, 'eval_duration': 199247000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:22:32.396379Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 613504041, 'load_duration': 21068083, 'prompt_eval_count': 163, 'prompt_eval_duration': 400806000, 'eval_count': 4, 'eval_duration': 189304000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:22:38.161114Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement translates to \"The richest personalities in the world on the Instagram list are topped by Kylie Jenner.\" This is a factual statement. Kylie Jenner has consistently been ranked among the highest-earning celebrities and influencers, often topping lists like Forbes\\' billionaires list.  Her massive following on Instagram further supports this claim. \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 5754483000, 'load_duration': 20476750, 'prompt_eval_count': 166, 'prompt_eval_duration': 367519000, 'eval_count': 72, 'eval_duration': 5364089000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:22:51.11Z', 'message': {'role': 'assistant', 'content': 'It\\'s impossible for me to definitively say whether the statement \"وفاة 48 مهاجرا غرقا أمام سواحل تونس\" (Death of 48 migrants drowned off the coast of Tunisia) is real or fake without access to external information sources.  \\n\\nHere\\'s why:\\n\\n* **I am a language model:** I can process and understand text, but I don\\'t have real-time information or the ability to verify news events.\\n* **The statement needs verification:** To determine its authenticity, you would need to cross-reference it with reputable news sources, official reports, or humanitarian organizations working in the region.\\n\\n**Therefore, I cannot provide an output of 0 or 1.**  You\\'ll need to consult reliable sources to confirm the veracity of this statement. \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 12941605750, 'load_duration': 20871667, 'prompt_eval_count': 159, 'prompt_eval_duration': 511845000, 'eval_count': 169, 'eval_duration': 12406655000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:22:51.823829Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 709949542, 'load_duration': 20600042, 'prompt_eval_count': 153, 'prompt_eval_duration': 472368000, 'eval_count': 4, 'eval_duration': 214449000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:22:52.498092Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 668152125, 'load_duration': 20170750, 'prompt_eval_count': 160, 'prompt_eval_duration': 445441000, 'eval_count': 4, 'eval_duration': 200076000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:22:58.280898Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement translates to \"Oil prices rise due to Middle East tensions.\" This is a plausible and commonly observed phenomenon.  Geopolitical instability in the Middle East, a major oil-producing region, often leads to concerns about supply disruptions, driving up oil prices. \\n\\n\\nLet me know if you\\'d like to analyze another statement!'}, 'done_reason': 'stop', 'done': True, 'total_duration': 5775941875, 'load_duration': 20807333, 'prompt_eval_count': 155, 'prompt_eval_duration': 403512000, 'eval_count': 75, 'eval_duration': 5349102000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:22:59.322276Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1034092542, 'load_duration': 20367500, 'prompt_eval_count': 170, 'prompt_eval_duration': 800642000, 'eval_count': 4, 'eval_duration': 210606000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:22:59.951969Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 620361542, 'load_duration': 21649334, 'prompt_eval_count': 154, 'prompt_eval_duration': 407402000, 'eval_count': 4, 'eval_duration': 189109000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:23:00.542913Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 583857500, 'load_duration': 20667042, 'prompt_eval_count': 160, 'prompt_eval_duration': 377279000, 'eval_count': 4, 'eval_duration': 183376000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:23:01.109835Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 558500292, 'load_duration': 20811125, 'prompt_eval_count': 163, 'prompt_eval_duration': 355971000, 'eval_count': 4, 'eval_duration': 179286000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:23:01.651322Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 536765583, 'load_duration': 20452208, 'prompt_eval_count': 158, 'prompt_eval_duration': 337890000, 'eval_count': 4, 'eval_duration': 176220000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:23:13.060374Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement \"باراغواي تغلق سفارتها لدى إسرائيل\" translates to \"Paraguay closes its embassy in Israel\".  This type of geopolitical event is verifiable through news sources and official statements.  \\n\\nTo confirm its authenticity, one would need to:\\n\\n1. **Check reputable news sources:** Look for reports from international news agencies (e.g., Reuters, Associated Press) or major newspapers that cover Middle Eastern affairs.\\n2. **Consult official government websites:** Check the websites of the Paraguayan and Israeli governments for any press releases or statements regarding diplomatic relations. \\n\\n\\nLet me know if you\\'d like me to help you find sources to verify this statement! \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 11403364625, 'load_duration': 19898916, 'prompt_eval_count': 154, 'prompt_eval_duration': 327047000, 'eval_count': 147, 'eval_duration': 11053986000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:23:29.455792Z', 'message': {'role': 'assistant', 'content': 'It\\'s impossible for me to definitively determine the authenticity of that statement without access to external information sources.  \\n\\nHere\\'s why:\\n\\n* **Language Barrier:** While I can process text, I don\\'t understand Arabic. To verify the content, I\\'d need a translation.\\n* **Context is Crucial:** Even with a translation, knowing the source of this statement is vital. Is it from a reputable news outlet, a government website, or a social media post? The source heavily influences its credibility.\\n\\n**To get an accurate answer, you would need to:**\\n\\n1. **Translate the text:** Get a reliable translation of \"سوريا تمنح عفوا عن الفارين والمتهربين من الخدمة العسكرية\".\\n2. **Research the Source:** Find out where this statement originated. \\n3. **Cross-Reference:** Look for independent confirmation of the amnesty from other credible sources.\\n\\n\\nLet me know if you have the translated text and source, and I can help you analyze it further! \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 16445445625, 'load_duration': 20231500, 'prompt_eval_count': 162, 'prompt_eval_duration': 489744000, 'eval_count': 214, 'eval_duration': 15932639000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:23:35.774388Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe text translates to \"A Syrian refugee speaks about being refused as a maid.\" This statement is plausible and doesn\\'t contain inherent logical contradictions.  While I cannot independently verify the specific situation, the experience of refugees facing discrimination and difficulty finding employment is a documented reality. \\n\\n\\nLet me know if you have any other statements you\\'d like me to analyze!'}, 'done_reason': 'stop', 'done': True, 'total_duration': 6312388208, 'load_duration': 20423292, 'prompt_eval_count': 158, 'prompt_eval_duration': 457344000, 'eval_count': 81, 'eval_duration': 5832410000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:23:36.488461Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 708546834, 'load_duration': 20307792, 'prompt_eval_count': 158, 'prompt_eval_duration': 475174000, 'eval_count': 4, 'eval_duration': 210692000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:23:42.34943Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement translates to \"The Egyptian House of Representatives rejects a bill to combat cybercrime.\"  This type of news is plausible and aligns with real-world political discussions.  \\n\\nWhile I cannot independently verify the specific details of this event, the general concept of a legislative body debating and potentially rejecting a cybercrime bill is realistic. \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 5854714958, 'load_duration': 20431791, 'prompt_eval_count': 160, 'prompt_eval_duration': 426433000, 'eval_count': 76, 'eval_duration': 5405209000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:23:43.091159Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 735512708, 'load_duration': 19976000, 'prompt_eval_count': 157, 'prompt_eval_duration': 498931000, 'eval_count': 4, 'eval_duration': 213964000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:23:43.737137Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 639037625, 'load_duration': 20198000, 'prompt_eval_count': 163, 'prompt_eval_duration': 425827000, 'eval_count': 4, 'eval_duration': 190661000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:23:44.331224Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 588903958, 'load_duration': 20131291, 'prompt_eval_count': 154, 'prompt_eval_duration': 381818000, 'eval_count': 4, 'eval_duration': 184836000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:23:52.367952Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement translates to \"The first women\\'s television channel in Gaza will soon be launched.\"  \\n\\n* **Content Verification:** While I cannot independently verify the launch date, the existence of a women\\'s television channel in Gaza is plausible given the region\\'s media landscape and social dynamics. \\n* **Logical Consistency:** The statement is logically consistent and does not contain any contradictions or implausible assertions.\\n\\n\\nTherefore, based on these considerations, the statement appears to be real.'}, 'done_reason': 'stop', 'done': True, 'total_duration': 8033407125, 'load_duration': 19827708, 'prompt_eval_count': 159, 'prompt_eval_duration': 361614000, 'eval_count': 106, 'eval_duration': 7649920000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:23:53.008767Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 634791625, 'load_duration': 20118500, 'prompt_eval_count': 162, 'prompt_eval_duration': 417899000, 'eval_count': 4, 'eval_duration': 194503000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:24:03.839074Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe text \"مصر تبدأ الانتخاب الرئاسية بين دعوات المقاطعة و المشاركة\" translates to \"Egypt begins presidential elections amid calls for boycott and participation.\" This statement is a plausible news headline and reflects the complex political realities of Egypt.  \\n\\n* **Content Verification:** While I cannot independently verify the specific details, the general topic of Egyptian presidential elections with debates about participation is well-documented and aligns with real-world events.\\n* **Logical Consistency:** The statement presents two opposing viewpoints (boycott vs. participation) which is typical in a democratic election context. \\n\\n\\nTherefore, based on these factors, the text appears to be authentic.'}, 'done_reason': 'stop', 'done': True, 'total_duration': 10821248416, 'load_duration': 19975250, 'prompt_eval_count': 160, 'prompt_eval_duration': 399459000, 'eval_count': 143, 'eval_duration': 10399634000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:24:04.577899Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 731433666, 'load_duration': 20929375, 'prompt_eval_count': 165, 'prompt_eval_duration': 490726000, 'eval_count': 4, 'eval_duration': 217491000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:24:14.938665Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement \"الحرب التجارية تنذر بكارثة للاقتصاد العالمي\" translates to \"The trade war threatens a catastrophe for the global economy.\" This is a plausible and widely discussed concern.  \\n\\n* **Content Verification:** Numerous credible sources, including economic institutions and news outlets, have reported on the potential negative impacts of trade wars on the global economy.\\n* **Logical Consistency:** The statement is logically consistent. Trade wars often lead to increased tariffs, disrupted supply chains, and reduced investment, all of which can contribute to an economic downturn. \\n\\n\\nTherefore, based on content verification and logical consistency, the statement appears to be real.'}, 'done_reason': 'stop', 'done': True, 'total_duration': 10355923958, 'load_duration': 20118583, 'prompt_eval_count': 155, 'prompt_eval_duration': 439878000, 'eval_count': 138, 'eval_duration': 9893747000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:24:15.630231Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 682478542, 'load_duration': 20510167, 'prompt_eval_count': 156, 'prompt_eval_duration': 452351000, 'eval_count': 4, 'eval_duration': 207345000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:24:16.273279Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 639539042, 'load_duration': 19402500, 'prompt_eval_count': 165, 'prompt_eval_duration': 425304000, 'eval_count': 4, 'eval_duration': 192731000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:24:22.989361Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe text appears to be a genuine Arabic news headline. It translates to \"BBC will discuss with Egyptian authorities their complaints about a documentary on human rights.\"  This type of statement is plausible and aligns with the BBC\\'s role as a news organization that sometimes faces criticism or scrutiny from governments regarding its reporting. \\n\\n\\nLet me know if you have any other text snippets you\\'d like me to analyze!'}, 'done_reason': 'stop', 'done': True, 'total_duration': 6706298083, 'load_duration': 20392791, 'prompt_eval_count': 163, 'prompt_eval_duration': 394785000, 'eval_count': 89, 'eval_duration': 6288900000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:24:23.663961Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 665744333, 'load_duration': 20847042, 'prompt_eval_count': 157, 'prompt_eval_duration': 442961000, 'eval_count': 4, 'eval_duration': 199737000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:24:32.653156Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement \"تحالف الصدر يفوز بالانتخابات البرلمانية في العراق\" translates to \"The Sadrist Alliance wins the parliamentary elections in Iraq.\"  \\n\\nThis statement is **potentially real**. The Sadrist Alliance, led by Muqtada al-Sadr, has been a significant political force in Iraq and has won elections in the past. To definitively determine its authenticity, one would need to cross-reference this information with reliable news sources reporting on Iraqi election results. \\n\\n\\nLet me know if you\\'d like me to analyze another statement!'}, 'done_reason': 'stop', 'done': True, 'total_duration': 8983622417, 'load_duration': 20019417, 'prompt_eval_count': 157, 'prompt_eval_duration': 399530000, 'eval_count': 121, 'eval_duration': 8561739000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:24:33.307669Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 649979625, 'load_duration': 19320958, 'prompt_eval_count': 162, 'prompt_eval_duration': 429653000, 'eval_count': 4, 'eval_duration': 198545000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:24:51.01373Z', 'message': {'role': 'assistant', 'content': 'It\\'s impossible for me to definitively say whether the provided Arabic text is \"real\" or \"fake\" without further context. Here\\'s why:\\n\\n* **Translation:** The text translates roughly to \"The Russian military operation is nearing its end in Eastern Ghouta.\"  This statement itself could be true or false depending on the specific timeframe and events being referenced.\\n* **Lack of Context:** To determine authenticity, I need more information:\\n    * **Source:** Where did this text originate? A reputable news source? Social media? \\n    * **Date:** When was this statement made? The situation in Eastern Ghouta has changed significantly over time.\\n\\n**How to Approach This Problem:**\\n\\n1. **Find the Source:**  Identify where you encountered this text.\\n2. **Verify with Reputable Sources:** Cross-reference the information with trusted news organizations that report on the Syrian conflict. \\n3. **Consider the Date:** If a date is provided, check if events align with what was reported at that time.\\n\\n\\nLet me know if you can provide more context about the text, and I\\'ll do my best to help! \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 17700785375, 'load_duration': 19833834, 'prompt_eval_count': 159, 'prompt_eval_duration': 406486000, 'eval_count': 241, 'eval_duration': 17272426000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:24:51.693678Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 673738292, 'load_duration': 19782250, 'prompt_eval_count': 163, 'prompt_eval_duration': 449405000, 'eval_count': 4, 'eval_duration': 202585000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:25:01.264912Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement appears to be a credible news headline. It translates from Arabic to \"Kuwaiti police arrest a Lebanese man suspected of killing a Pakistani worker.\"  \\n\\n* **Content Verification:** This type of event is unfortunately not uncommon and would likely be reported by reputable news sources. \\n* **Logical Consistency:** The statement is logically consistent. There\\'s a clear subject (Lebanese man), action (arrest), and reason for the arrest (suspicion of murder).\\n\\n\\nWhile I cannot independently verify the specific details without further research, the structure and content of the statement align with typical news reporting. \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 9562669458, 'load_duration': 20619583, 'prompt_eval_count': 163, 'prompt_eval_duration': 416825000, 'eval_count': 131, 'eval_duration': 9123027000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:25:01.940986Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 666958583, 'load_duration': 21245833, 'prompt_eval_count': 154, 'prompt_eval_duration': 441516000, 'eval_count': 4, 'eval_duration': 201905000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:25:02.57409Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 627671625, 'load_duration': 19922834, 'prompt_eval_count': 157, 'prompt_eval_duration': 414695000, 'eval_count': 4, 'eval_duration': 190941000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:25:20.203647Z', 'message': {'role': 'assistant', 'content': 'It\\'s impossible for me to definitively say whether the statement \"تركيا تعرقل عمليات التنقيب قبالة قبرص\" (Turkey is obstructing exploration operations off Cyprus) is real or fake without access to external information and geopolitical analysis. \\n\\n**Here\\'s why:**\\n\\n* **I lack real-time knowledge:** My knowledge is based on the data I was trained on, which doesn\\'t include constantly updating news events.\\n* **Geopolitical complexity:**  Statements about international relations are often nuanced and require understanding of historical context, political motivations, and ongoing negotiations. \\n\\n**To determine the authenticity of this statement, you would need to:**\\n\\n1. **Verify the source:** Where did you encounter this statement? Is the source known for reliability and accuracy?\\n2. **Cross-reference with reputable news sources:** Check if major news organizations are reporting on a similar situation.\\n3. **Consider expert analysis:** Look for commentary from political analysts or specialists in Turkish-Cypriot relations. \\n\\n\\nLet me know if you have any other questions that don\\'t require real-time information or subjective judgment!'}, 'done_reason': 'stop', 'done': True, 'total_duration': 17619318459, 'load_duration': 21109917, 'prompt_eval_count': 157, 'prompt_eval_duration': 388381000, 'eval_count': 233, 'eval_duration': 17207579000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:25:20.883953Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 674515750, 'load_duration': 20723125, 'prompt_eval_count': 163, 'prompt_eval_duration': 445457000, 'eval_count': 4, 'eval_duration': 205944000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:25:28.018093Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement translates to \"Kuwaiti women launch a radio station to raise awareness about women\\'s rights.\"  This type of initiative is plausible and aligns with ongoing global conversations about gender equality. There\\'s no inherent logical inconsistency, and the claim could be independently verified through news sources or research on Kuwaiti women\\'s organizations. \\n\\n\\nLet me know if you have any other statements you\\'d like me to analyze!'}, 'done_reason': 'stop', 'done': True, 'total_duration': 7128330167, 'load_duration': 20404042, 'prompt_eval_count': 158, 'prompt_eval_duration': 439928000, 'eval_count': 94, 'eval_duration': 6665867000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:25:34.005934Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement appears to be a credible news headline. It reports on legal action taken by the Egyptian Public Prosecution, which is a legitimate institution. The language used is consistent with typical news reporting style.  \\n\\nWhile I cannot independently verify the specific details of the case without further research, the overall structure and content of the statement suggest authenticity. \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 5982618167, 'load_duration': 19878875, 'prompt_eval_count': 167, 'prompt_eval_duration': 703053000, 'eval_count': 77, 'eval_duration': 5257419000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:25:41.724054Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement translates to \"A UAE official announced that Arab relations with Turkey are not in their best state.\" This type of statement is plausible and reflects real-world political dynamics.  There have been periods of tension between Turkey and some Arab countries. \\n\\nTherefore, based on the criteria of content verification (political statements about international relations are common) and logical consistency (the statement doesn\\'t contain contradictions), it appears to be a potentially authentic statement. \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 7712383333, 'load_duration': 20421541, 'prompt_eval_count': 160, 'prompt_eval_duration': 527187000, 'eval_count': 100, 'eval_duration': 7161876000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:25:46.77394Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe text translates to \"An earthquake of magnitude 6 on the Richter scale hits the Iran-Iraq border.\"  This type of statement is commonly reported and verifiable through news sources and seismological agencies. \\n\\n\\nLet me know if you\\'d like me to analyze another statement!'}, 'done_reason': 'stop', 'done': True, 'total_duration': 5044113834, 'load_duration': 20471000, 'prompt_eval_count': 164, 'prompt_eval_duration': 451815000, 'eval_count': 64, 'eval_duration': 4569021000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:25:47.416634Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 637900333, 'load_duration': 19806250, 'prompt_eval_count': 153, 'prompt_eval_duration': 422434000, 'eval_count': 4, 'eval_duration': 193770000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:25:53.034089Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement translates to \"Iran announced that it is ready for unexpected measures after Trump\\'s withdrawal from the nuclear deal.\" This aligns with known geopolitical events and Iran\\'s past statements regarding the nuclear deal.  Therefore, the text appears to be real. \\n\\n\\nLet me know if you have any other text you\\'d like me to analyze!'}, 'done_reason': 'stop', 'done': True, 'total_duration': 5614017541, 'load_duration': 20474125, 'prompt_eval_count': 169, 'prompt_eval_duration': 388249000, 'eval_count': 78, 'eval_duration': 5203057000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:25:53.721232Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 680458625, 'load_duration': 19493541, 'prompt_eval_count': 154, 'prompt_eval_duration': 453956000, 'eval_count': 4, 'eval_duration': 204569000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:25:54.339707Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 613127458, 'load_duration': 20039333, 'prompt_eval_count': 153, 'prompt_eval_duration': 402711000, 'eval_count': 4, 'eval_duration': 188297000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:25:54.92964Z', 'message': {'role': 'assistant', 'content': '0 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 585372583, 'load_duration': 19642958, 'prompt_eval_count': 157, 'prompt_eval_duration': 380079000, 'eval_count': 4, 'eval_duration': 183537000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:26:00.195475Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement translates to \"Kuwait and the Philippines sign an agreement ending the domestic worker crisis between them.\"  This type of news is plausible and aligns with real-world diplomatic efforts.  \\n\\nWhile I cannot independently verify the specific agreement, the content itself is consistent with known issues regarding labor relations between Kuwait and the Philippines. \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 5259864166, 'load_duration': 20073625, 'prompt_eval_count': 163, 'prompt_eval_duration': 358873000, 'eval_count': 74, 'eval_duration': 4878861000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:26:00.95422Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 753109042, 'load_duration': 20083542, 'prompt_eval_count': 154, 'prompt_eval_duration': 512864000, 'eval_count': 4, 'eval_duration': 217549000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:26:01.593012Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 634835000, 'load_duration': 19971500, 'prompt_eval_count': 155, 'prompt_eval_duration': 422300000, 'eval_count': 4, 'eval_duration': 190310000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:26:10.515751Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement translates to \"Khamenei did not issue a fatwa on the permissibility of polygamy.\" This claim is consistent with known facts about Ayatollah Khamenei\\'s stance and Islamic jurisprudence.  \\n\\n* **Content Verification:** There is no widely available evidence or reporting suggesting Khamenei has issued such a fatwa.\\n* **Logical Consistency:** The statement aligns with general Islamic teachings, which permit polygamy under specific conditions but do not encourage it as a default practice. \\n\\n\\nTherefore, based on the analysis, the text appears to be real (0).'}, 'done_reason': 'stop', 'done': True, 'total_duration': 8913744417, 'load_duration': 20777084, 'prompt_eval_count': 160, 'prompt_eval_duration': 378122000, 'eval_count': 126, 'eval_duration': 8512570000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:26:11.12776Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 603111084, 'load_duration': 21102917, 'prompt_eval_count': 152, 'prompt_eval_duration': 390674000, 'eval_count': 4, 'eval_duration': 188728000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:26:12.060257Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 927765417, 'load_duration': 19910250, 'prompt_eval_count': 149, 'prompt_eval_duration': 702807000, 'eval_count': 4, 'eval_duration': 202828000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:26:18.134953Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement translates to \"Gold loses its value with the continued rise of the dollar.\" This is a generally accepted economic principle.  When the US dollar strengthens, commodities priced in dollars (like gold) tend to become more expensive for buyers using other currencies, leading to decreased demand and potentially lower prices. \\n\\n\\nLet me know if you\\'d like to analyze another statement!'}, 'done_reason': 'stop', 'done': True, 'total_duration': 6070017916, 'load_duration': 20248208, 'prompt_eval_count': 155, 'prompt_eval_duration': 417093000, 'eval_count': 83, 'eval_duration': 5630600000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:26:18.794859Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 652528209, 'load_duration': 20796459, 'prompt_eval_count': 157, 'prompt_eval_duration': 432681000, 'eval_count': 4, 'eval_duration': 196653000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:26:19.401465Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 602519500, 'load_duration': 19874250, 'prompt_eval_count': 155, 'prompt_eval_duration': 394451000, 'eval_count': 4, 'eval_duration': 186017000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:26:28.250066Z', 'message': {'role': 'assistant', 'content': \"It's impossible for me to definitively determine the authenticity of that statement without access to external information sources.  \\n\\nHere's why:\\n\\n* **Language Barrier:** The text is in Arabic, and I don't have translation capabilities. \\n* **Need for Verification:** To assess its authenticity, I would need to cross-reference it with reliable news sources or legal databases in Egypt.\\n\\n**Therefore, I cannot provide an output of 0 or 1.**  You would need to consult Arabic-language news sources or legal experts familiar with Egyptian law to verify the statement's accuracy. \\n\"}, 'done_reason': 'stop', 'done': True, 'total_duration': 8844926458, 'load_duration': 20560208, 'prompt_eval_count': 160, 'prompt_eval_duration': 378366000, 'eval_count': 125, 'eval_duration': 8443660000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:26:28.879006Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 619491125, 'load_duration': 21097625, 'prompt_eval_count': 161, 'prompt_eval_duration': 406099000, 'eval_count': 4, 'eval_duration': 189682000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:26:29.482941Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 600369292, 'load_duration': 20372584, 'prompt_eval_count': 157, 'prompt_eval_duration': 391303000, 'eval_count': 4, 'eval_duration': 186592000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:26:30.076602Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 587996250, 'load_duration': 20353167, 'prompt_eval_count': 162, 'prompt_eval_duration': 381827000, 'eval_count': 4, 'eval_duration': 183571000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:26:34.504824Z', 'message': {'role': 'assistant', 'content': \"It's impossible for me to definitively determine the authenticity of that statement. I am a text-based AI and cannot access real-time information or verify news events. \\n\\nTo assess the statement's authenticity, you would need to consult reliable news sources and fact-checking websites.  \\n\"}, 'done_reason': 'stop', 'done': True, 'total_duration': 4422450667, 'load_duration': 20708542, 'prompt_eval_count': 167, 'prompt_eval_duration': 588862000, 'eval_count': 61, 'eval_duration': 3810493000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:26:35.248895Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 737929708, 'load_duration': 20958417, 'prompt_eval_count': 159, 'prompt_eval_duration': 493480000, 'eval_count': 4, 'eval_duration': 220809000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:26:49.034994Z', 'message': {'role': 'assistant', 'content': 'It\\'s impossible to definitively label the statement as \"real\" or \"fake\" with a simple 0 or 1 output. Here\\'s why:\\n\\n* **Translation:** The text translates to \"Accelerating economic downturn in Turkey.\" This is a statement of fact, not an inherently true or false claim.\\n* **Context Matters:**  To determine the authenticity, we need context. Is this statement being made in a news article? A social media post? An academic paper? The source and its reputation are crucial.\\n\\n**What I can do:**\\n\\nI can help you find information to assess the statement:\\n\\n* **Search for economic data on Turkey:** Look for reports from reputable sources like the World Bank, IMF, or Turkish government agencies.\\n* **Analyze news coverage:** See what major news outlets are reporting about the Turkish economy. \\n\\n\\nLet me know if you\\'d like me to help with any of these searches! \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 13777374250, 'load_duration': 20840084, 'prompt_eval_count': 153, 'prompt_eval_duration': 454940000, 'eval_count': 195, 'eval_duration': 13299376000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:26:53.702488Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement claims that Abdel Fattah el-Sisi was elected President of Egypt with 97% of the vote. This claim is consistent with publicly available information and has been widely reported by credible news sources.  Therefore, the statement is considered real. \\n\\n\\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4662368500, 'load_duration': 20547750, 'prompt_eval_count': 168, 'prompt_eval_duration': 698484000, 'eval_count': 62, 'eval_duration': 3940973000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:26:54.384365Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 675264958, 'load_duration': 21313125, 'prompt_eval_count': 166, 'prompt_eval_duration': 443492000, 'eval_count': 4, 'eval_duration': 207911000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:27:07.654769Z', 'message': {'role': 'assistant', 'content': \"It's impossible for me to definitively determine the authenticity of that statement without access to external information sources.  \\n\\nHere's why:\\n\\n* **Language Barrier:** The text is in Arabic, and I need translation capabilities to understand its content fully. \\n* **Fact-Checking Requires Context:** Even with translation, verifying news requires cross-referencing with reliable sources. I don't have access to the internet to do that.\\n\\n**To get an accurate answer, you would need to:**\\n\\n1. **Translate the text:** Get a reliable translation of the Arabic statement.\\n2. **Consult reputable news sources:** Check if major news outlets are reporting on similar events in southern Iraq. \\n3. **Look for corroborating evidence:** See if there are images, videos, or eyewitness accounts that support the claim. \\n\\n\\nLet me know if you have any other questions that don't require external information access!\"}, 'done_reason': 'stop', 'done': True, 'total_duration': 13264808167, 'load_duration': 21107333, 'prompt_eval_count': 161, 'prompt_eval_duration': 430756000, 'eval_count': 190, 'eval_duration': 12810565000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:27:08.30756Z', 'message': {'role': 'assistant', 'content': '0 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 646137875, 'load_duration': 20832750, 'prompt_eval_count': 153, 'prompt_eval_duration': 426175000, 'eval_count': 4, 'eval_duration': 196765000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:27:08.926103Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 612818209, 'load_duration': 20339584, 'prompt_eval_count': 159, 'prompt_eval_duration': 400905000, 'eval_count': 4, 'eval_duration': 189428000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:27:14.825584Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe text \"وقف العمل باتفاقية التجارة الحرة الأردنية التركية\" translates to \"Suspension of the Jordanian-Turkish Free Trade Agreement\".  This type of statement is plausible and relates to real-world international trade agreements.  \\n\\nWhile I cannot independently verify if this specific suspension occurred, the statement itself is logically consistent and aligns with potential geopolitical events. \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 5890940083, 'load_duration': 20751000, 'prompt_eval_count': 158, 'prompt_eval_duration': 379617000, 'eval_count': 84, 'eval_duration': 5488164000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:27:15.526937Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 689346083, 'load_duration': 20364083, 'prompt_eval_count': 159, 'prompt_eval_duration': 463675000, 'eval_count': 4, 'eval_duration': 203086000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:27:16.142895Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 607539000, 'load_duration': 20886416, 'prompt_eval_count': 154, 'prompt_eval_duration': 397241000, 'eval_count': 4, 'eval_duration': 186841000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:27:16.72402Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 575377750, 'load_duration': 20044375, 'prompt_eval_count': 160, 'prompt_eval_duration': 371814000, 'eval_count': 4, 'eval_duration': 181096000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:27:17.27442Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 544408041, 'load_duration': 20343916, 'prompt_eval_count': 158, 'prompt_eval_duration': 346324000, 'eval_count': 4, 'eval_duration': 175650000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:27:22.734013Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement translates to \"The West and some countries in the world are hesitant to deal with Iran due to sanctions.\" This is a factually accurate statement. Western nations and some others have imposed sanctions on Iran for various reasons, including its nuclear program and regional activities.  Therefore, the statement aligns with verifiable information and is logically consistent. \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 5455379584, 'load_duration': 20334250, 'prompt_eval_count': 160, 'prompt_eval_duration': 326433000, 'eval_count': 77, 'eval_duration': 5106311000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:27:23.454523Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 714526917, 'load_duration': 20666750, 'prompt_eval_count': 151, 'prompt_eval_duration': 485209000, 'eval_count': 4, 'eval_duration': 205978000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:27:24.323645Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 864971375, 'load_duration': 20781250, 'prompt_eval_count': 167, 'prompt_eval_duration': 653907000, 'eval_count': 4, 'eval_duration': 187287000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:27:24.898856Z', 'message': {'role': 'assistant', 'content': '0 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 570112709, 'load_duration': 20393625, 'prompt_eval_count': 163, 'prompt_eval_duration': 367719000, 'eval_count': 4, 'eval_duration': 179720000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:27:32.277919Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe provided text translates to \"A Syrian refugee speaks about refusing to be just a wife.\"  This statement is plausible and doesn\\'t contain any inherently illogical elements. It reflects a potential desire for personal agency and fulfillment beyond traditional societal roles, which is a common theme in discussions of gender equality and empowerment. \\n\\n\\nWhile I cannot independently verify the existence of this specific refugee or her statements, the content itself aligns with real-world issues faced by refugees and women globally. \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 7369663792, 'load_duration': 20216583, 'prompt_eval_count': 158, 'prompt_eval_duration': 336200000, 'eval_count': 104, 'eval_duration': 7011022000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:27:42.057362Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement translates to \"Iran is ready for unexpected measures in response to Trump\\'s withdrawal from the nuclear deal.\" This type of statement aligns with geopolitical realities and Iran\\'s past responses to international pressure.  \\n\\n* **Content Verification:** While I cannot independently verify the specific wording, the general sentiment expressed is consistent with known Iranian positions on the nuclear deal.\\n* **Logical Consistency:** The statement is logically sound. It presents a cause (Trump\\'s withdrawal) and a potential effect (Iran taking unexpected measures). This is a common pattern in international relations. \\n\\n\\nTherefore, based on these considerations, the text appears to be authentic.'}, 'done_reason': 'stop', 'done': True, 'total_duration': 9772778708, 'load_duration': 20816166, 'prompt_eval_count': 167, 'prompt_eval_duration': 632592000, 'eval_count': 137, 'eval_duration': 9116736000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:27:49.504892Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe text translates to \"Russia\\'s military operation in Eastern Ghouta is about to end.\"  This statement aligns with historical events. In 2018, Russia was involved in a military campaign in Eastern Ghouta, Syria. The statement suggests the operation was nearing completion, which is consistent with the timeline of events as the siege of Eastern Ghouta ended in April 2018.\\n\\n\\nLet me know if you\\'d like to analyze another statement!'}, 'done_reason': 'stop', 'done': True, 'total_duration': 7441723875, 'load_duration': 20487250, 'prompt_eval_count': 159, 'prompt_eval_duration': 404406000, 'eval_count': 106, 'eval_duration': 7014364000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:27:50.133886Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 619635125, 'load_duration': 21124041, 'prompt_eval_count': 158, 'prompt_eval_duration': 407453000, 'eval_count': 4, 'eval_duration': 188696000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:27:50.73708Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 597617250, 'load_duration': 19920166, 'prompt_eval_count': 162, 'prompt_eval_duration': 389509000, 'eval_count': 4, 'eval_duration': 185170000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:27:51.311622Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 567819917, 'load_duration': 20355709, 'prompt_eval_count': 154, 'prompt_eval_duration': 365617000, 'eval_count': 4, 'eval_duration': 179766000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:27:51.865667Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 548051375, 'load_duration': 20188458, 'prompt_eval_count': 157, 'prompt_eval_duration': 348335000, 'eval_count': 4, 'eval_duration': 177480000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:27:52.398646Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 527068833, 'load_duration': 20177208, 'prompt_eval_count': 157, 'prompt_eval_duration': 331331000, 'eval_count': 4, 'eval_duration': 173352000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:27:52.922645Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 517961125, 'load_duration': 20484209, 'prompt_eval_count': 165, 'prompt_eval_duration': 324056000, 'eval_count': 4, 'eval_duration': 171206000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:27:53.431934Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 503551666, 'load_duration': 20603666, 'prompt_eval_count': 156, 'prompt_eval_duration': 311385000, 'eval_count': 4, 'eval_duration': 169286000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:27:53.935286Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 497351500, 'load_duration': 19732375, 'prompt_eval_count': 153, 'prompt_eval_duration': 306558000, 'eval_count': 4, 'eval_duration': 169058000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:27:54.4383Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 498802541, 'load_duration': 20115208, 'prompt_eval_count': 157, 'prompt_eval_duration': 307504000, 'eval_count': 4, 'eval_duration': 168845000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:27:54.948535Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 502496041, 'load_duration': 21039208, 'prompt_eval_count': 154, 'prompt_eval_duration': 308701000, 'eval_count': 4, 'eval_duration': 170438000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:28:05.502776Z', 'message': {'role': 'assistant', 'content': \"It's impossible for me to determine the authenticity of that statement without understanding Arabic.  \\n\\nMy purpose is to provide helpful and harmless information, and that includes being transparent about my limitations. I can process and generate text, but I don't have the ability to understand or translate languages. \\n\\nTo figure out if the statement is real or fake, you would need to:\\n\\n1. **Translate the Arabic text:** Find a reliable translation service to understand what the statement says.\\n2. **Fact-check:** Once translated, research the claims made in the statement using credible sources. Look for evidence to support or refute the information. \\n\\n\\nLet me know if you have any other questions that don't require language understanding! \\n\"}, 'done_reason': 'stop', 'done': True, 'total_duration': 10549654042, 'load_duration': 20097042, 'prompt_eval_count': 161, 'prompt_eval_duration': 315844000, 'eval_count': 152, 'eval_duration': 10211468000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:28:06.165468Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 659109500, 'load_duration': 20827500, 'prompt_eval_count': 162, 'prompt_eval_duration': 437906000, 'eval_count': 4, 'eval_duration': 197800000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:28:06.783688Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 609535625, 'load_duration': 20975291, 'prompt_eval_count': 158, 'prompt_eval_duration': 397664000, 'eval_count': 4, 'eval_duration': 188682000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:28:14.975501Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe text you provided is a headline in Arabic. It translates to \"The last chapters of the crisis between Turkey and Saudi Arabia in the case of the disappearance of Saudi journalist Jamal Khashoggi.\"  \\n\\nThis statement refers to a real-world event – the disappearance and alleged murder of Jamal Khashoggi in 2018. The incident sparked a major international diplomatic crisis, particularly between Turkey and Saudi Arabia. Therefore, the text is authentic. \\n\\n\\nLet me know if you have any other statements you\\'d like me to analyze!'}, 'done_reason': 'stop', 'done': True, 'total_duration': 8183227625, 'load_duration': 21315209, 'prompt_eval_count': 166, 'prompt_eval_duration': 367799000, 'eval_count': 118, 'eval_duration': 7791340000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:28:15.827326Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 844938500, 'load_duration': 20783375, 'prompt_eval_count': 168, 'prompt_eval_duration': 633878000, 'eval_count': 4, 'eval_duration': 187904000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:28:22.77748Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement translates to \"For the first time in Saudi Arabia, an orchestra and opera house are being established.\"  This claim is plausible and aligns with Saudi Arabia\\'s recent efforts to modernize and diversify its cultural scene. There have been reports of investments in arts and entertainment infrastructure within the country. \\n\\n\\nWhile I cannot independently verify the specific details of this orchestra and opera house establishment, the general sentiment aligns with known trends and initiatives in Saudi Arabia. \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 6943730084, 'load_duration': 20739709, 'prompt_eval_count': 161, 'prompt_eval_duration': 373650000, 'eval_count': 100, 'eval_duration': 6546842000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:28:30.863878Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement \"التوتر بالشرق الأوسط يرفع أسعار النفط\" translates to \"Tension in the Middle East raises oil prices.\" This is a factually accurate statement.  \\n\\n* **Content Verification:** Geopolitical tensions in the Middle East, a major oil-producing region, historically have impacted global oil prices. \\n* **Logical Consistency:** The statement follows a logical cause-and-effect relationship: increased tension (cause) leads to higher oil prices (effect). \\n\\n\\nTherefore, the text is considered real.'}, 'done_reason': 'stop', 'done': True, 'total_duration': 8078962833, 'load_duration': 20577166, 'prompt_eval_count': 156, 'prompt_eval_duration': 409074000, 'eval_count': 116, 'eval_duration': 7646995000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:28:31.486826Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 615714500, 'load_duration': 20270125, 'prompt_eval_count': 163, 'prompt_eval_duration': 403557000, 'eval_count': 4, 'eval_duration': 189397000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:28:32.314087Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 822521959, 'load_duration': 20358959, 'prompt_eval_count': 173, 'prompt_eval_duration': 615626000, 'eval_count': 4, 'eval_duration': 184424000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:28:32.881014Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 559533083, 'load_duration': 20978375, 'prompt_eval_count': 158, 'prompt_eval_duration': 358336000, 'eval_count': 4, 'eval_duration': 177845000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:28:33.41914Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 533910250, 'load_duration': 20257375, 'prompt_eval_count': 158, 'prompt_eval_duration': 336538000, 'eval_count': 4, 'eval_duration': 174931000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:28:38.504001Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThis statement is real.  Gary Oldman won the Academy Award for Best Actor and Frances McDormand won for Best Actress at the 90th Academy Awards in 2018. This information can be easily verified through reputable sources like the official Oscars website or news articles from that time. \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 5077636792, 'load_duration': 21006834, 'prompt_eval_count': 176, 'prompt_eval_duration': 526614000, 'eval_count': 71, 'eval_duration': 4527348000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:28:39.26338Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 749605584, 'load_duration': 21428042, 'prompt_eval_count': 156, 'prompt_eval_duration': 509154000, 'eval_count': 4, 'eval_duration': 216565000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:28:45.950574Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe text translates to \"The Syrian army announces the recapture of the last opposition-held areas near Damascus.\" This type of statement is consistent with ongoing news and reports about the Syrian Civil War.  \\n\\nWhile I cannot independently verify the specific claim, it aligns with the broader context of the conflict and has been reported by various news sources over time. \\n\\n\\nLet me know if you have any other text you\\'d like me to analyze!'}, 'done_reason': 'stop', 'done': True, 'total_duration': 6680420958, 'load_duration': 20660917, 'prompt_eval_count': 162, 'prompt_eval_duration': 424867000, 'eval_count': 96, 'eval_duration': 6232459000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:28:46.638064Z', 'message': {'role': 'assistant', 'content': '0 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 679667500, 'load_duration': 20542541, 'prompt_eval_count': 154, 'prompt_eval_duration': 456874000, 'eval_count': 4, 'eval_duration': 199938000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:28:57.441816Z', 'message': {'role': 'assistant', 'content': 'It\\'s impossible to definitively determine the authenticity of the statement \"تدني أسعار الذهب لمستوى غير مسبوق خلال عام ونصف\" (Gold prices have fallen to an unprecedented level in a year and a half) without access to real-time gold market data. \\n\\n**Here\\'s why:**\\n\\n* **Content Verification:** To verify this claim, we would need to consult reliable sources of gold price information (e.g., financial news websites, commodity exchanges).\\n* **Logical Consistency:** The statement itself is logically consistent. Falling gold prices are a plausible event.\\n\\n**Therefore, I cannot provide a definitive 0 or 1 answer.**  You would need to cross-reference the statement with actual gold price data to determine its accuracy. \\n\\n\\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 10798331292, 'load_duration': 19598250, 'prompt_eval_count': 160, 'prompt_eval_duration': 396135000, 'eval_count': 160, 'eval_duration': 10380098000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:28:58.057586Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 608378625, 'load_duration': 20505708, 'prompt_eval_count': 152, 'prompt_eval_duration': 395342000, 'eval_count': 4, 'eval_duration': 190516000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:29:08.523128Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement translates to \"Khamenei denies issuing a fatwa on the permissibility of polygamy.\"  \\n\\n* **Content Verification:** This type of statement, regarding religious pronouncements from a prominent figure like Ayatollah Khamenei, would likely be reported by reputable news sources if it were true. A quick search reveals discussions and articles about Khamenei\\'s stance on polygamy, but no credible sources indicate he recently issued a fatwa endorsing it.\\n\\n* **Logical Consistency:** The statement itself is logically consistent. It presents a denial of a specific action (issuing a fatwa). There are no inherent contradictions within the statement. \\n\\n\\nGiven these factors, the statement appears to be authentic.  \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 10462536792, 'load_duration': 20740667, 'prompt_eval_count': 159, 'prompt_eval_duration': 389751000, 'eval_count': 154, 'eval_duration': 10049676000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:29:12.442061Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement translates to \"Italy raises trading in European stock exchanges.\" This is a plausible statement. While I cannot verify its factual accuracy without further context, the content itself aligns with potential economic news and doesn\\'t contain obvious contradictions.  \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3911436208, 'load_duration': 20763333, 'prompt_eval_count': 154, 'prompt_eval_duration': 400615000, 'eval_count': 56, 'eval_duration': 3487706000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:29:13.066603Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 619427459, 'load_duration': 20179459, 'prompt_eval_count': 162, 'prompt_eval_duration': 407232000, 'eval_count': 4, 'eval_duration': 189871000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:29:14.010343Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 937762250, 'load_duration': 19890583, 'prompt_eval_count': 149, 'prompt_eval_duration': 712366000, 'eval_count': 4, 'eval_duration': 203284000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:29:14.642249Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 626298917, 'load_duration': 19770500, 'prompt_eval_count': 164, 'prompt_eval_duration': 413886000, 'eval_count': 4, 'eval_duration': 190086000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:29:18.903792Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe text translates to \"Films nominated for Best Foreign Language Film at the Oscars 2018\". This is a factual statement that can be verified through reliable sources like the official Academy Awards website.  There are no logical inconsistencies or implausible claims. \\n\\n\\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4255662625, 'load_duration': 19773250, 'prompt_eval_count': 166, 'prompt_eval_duration': 378435000, 'eval_count': 62, 'eval_duration': 3855042000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:29:19.60896Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 697542166, 'load_duration': 20193875, 'prompt_eval_count': 157, 'prompt_eval_duration': 462690000, 'eval_count': 4, 'eval_duration': 212558000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:29:20.269363Z', 'message': {'role': 'assistant', 'content': '0 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 653133250, 'load_duration': 20515250, 'prompt_eval_count': 155, 'prompt_eval_duration': 432045000, 'eval_count': 4, 'eval_duration': 197859000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:29:20.884578Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 609765291, 'load_duration': 20351375, 'prompt_eval_count': 158, 'prompt_eval_duration': 398679000, 'eval_count': 4, 'eval_duration': 188300000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:29:28.499626Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe text translates to \"Turkish police search forest for Jamal Khashoggi\" in English. This statement aligns with known events surrounding the disappearance and alleged murder of journalist Jamal Khashoggi in Turkey.  \\n\\n* **Content Verification:** The event was widely reported by international news organizations, making it independently verifiable.\\n* **Logical Consistency:** The statement is logically consistent with the circumstances of Khashoggi\\'s disappearance and the subsequent investigation. \\n\\n\\nTherefore, based on these factors, the text appears to be real.'}, 'done_reason': 'stop', 'done': True, 'total_duration': 7610823958, 'load_duration': 21229708, 'prompt_eval_count': 158, 'prompt_eval_duration': 371740000, 'eval_count': 111, 'eval_duration': 7215570000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:29:29.117211Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 608910917, 'load_duration': 20865667, 'prompt_eval_count': 164, 'prompt_eval_duration': 399401000, 'eval_count': 4, 'eval_duration': 186241000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:29:38.669454Z', 'message': {'role': 'assistant', 'content': \"It's impossible for me to definitively determine the authenticity of that statement. Here's why:\\n\\n* **Language Barrier:** I don't understand Arabic. To accurately assess the content, I would need a reliable translation. \\n* **Context is Crucial:**  Even with a translation, understanding the full context surrounding this statement is essential. Who said it? When and where was it said? What are the political circumstances?\\n\\n**Without these factors, I cannot responsibly output 0 or 1.**\\n\\nIt's important to be cautious about information, especially regarding sensitive topics like political conflicts. Always seek out multiple sources and consider the potential biases involved. \\n\"}, 'done_reason': 'stop', 'done': True, 'total_duration': 9548017291, 'load_duration': 20202541, 'prompt_eval_count': 168, 'prompt_eval_duration': 602766000, 'eval_count': 137, 'eval_duration': 8922280000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:29:50.364361Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement \"إيران تستعد لزيادة مستوى تخصيب اليورانيوم إذا انهار الاتفاق\" translates to \"Iran is preparing to increase the level of uranium enrichment if the agreement collapses.\" This type of statement aligns with geopolitical realities and ongoing discussions surrounding Iran\\'s nuclear program.  \\n\\n* **Content Verification:** While I cannot independently verify the specific details, this claim reflects a common concern in international relations regarding Iran\\'s nuclear capabilities. \\n* **Logical Consistency:** The statement is logically consistent. It presents a conditional scenario (agreement collapse) leading to a potential consequence (increased enrichment). This is a plausible cause-and-effect relationship within the context of nuclear negotiations.\\n\\n\\nTherefore, based on the content and logical consistency, the statement appears to be real. \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 11688849708, 'load_duration': 20487708, 'prompt_eval_count': 162, 'prompt_eval_duration': 391565000, 'eval_count': 168, 'eval_duration': 11274683000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:29:51.262055Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 892056458, 'load_duration': 20288875, 'prompt_eval_count': 168, 'prompt_eval_duration': 679727000, 'eval_count': 4, 'eval_duration': 189501000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:29:51.864732Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 596884125, 'load_duration': 19983792, 'prompt_eval_count': 162, 'prompt_eval_duration': 389074000, 'eval_count': 4, 'eval_duration': 185645000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:29:52.434953Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 566355708, 'load_duration': 19408167, 'prompt_eval_count': 163, 'prompt_eval_duration': 362851000, 'eval_count': 4, 'eval_duration': 181994000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:29:52.98294Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 542288750, 'load_duration': 20463000, 'prompt_eval_count': 161, 'prompt_eval_duration': 342444000, 'eval_count': 4, 'eval_duration': 177008000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:29:53.507975Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 518941500, 'load_duration': 19958583, 'prompt_eval_count': 159, 'prompt_eval_duration': 322948000, 'eval_count': 4, 'eval_duration': 173962000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:29:54.021718Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 509823917, 'load_duration': 20137042, 'prompt_eval_count': 154, 'prompt_eval_duration': 312475000, 'eval_count': 4, 'eval_duration': 174883000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:30:07.094194Z', 'message': {'role': 'assistant', 'content': \"It's impossible for me to definitively determine the authenticity of that statement without access to external information sources.  \\n\\nHere's why:\\n\\n* **Language Barrier:** The text is in Arabic, and I need context to understand its meaning fully. \\n* **Fact-Checking Requires External Sources:** To verify the claims made, I would need to cross-reference them with reliable news sources, historical records, or expert analysis on the Syrian conflict.\\n\\n**To get an accurate answer, you would need to consult:**\\n\\n* **Arabic-language news sources:** Look for reporting from reputable outlets known for their accuracy.\\n* **Fact-checking websites:** Some organizations specialize in verifying information and debunking false claims.\\n* **Experts on the Syrian conflict:** Academics or journalists who specialize in this region could provide valuable insights. \\n\\n\\nLet me know if you have any other questions that don't require external fact-checking!\"}, 'done_reason': 'stop', 'done': True, 'total_duration': 13066561333, 'load_duration': 21223125, 'prompt_eval_count': 162, 'prompt_eval_duration': 310161000, 'eval_count': 190, 'eval_duration': 12732909000}\n",
      "None\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:30:07.714617Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 612158583, 'load_duration': 21269583, 'prompt_eval_count': 156, 'prompt_eval_duration': 400052000, 'eval_count': 4, 'eval_duration': 188120000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:30:08.303308Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 584155958, 'load_duration': 20089583, 'prompt_eval_count': 152, 'prompt_eval_duration': 377054000, 'eval_count': 4, 'eval_duration': 184626000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:30:08.868633Z', 'message': {'role': 'assistant', 'content': '0 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 560093958, 'load_duration': 20184417, 'prompt_eval_count': 153, 'prompt_eval_duration': 357318000, 'eval_count': 4, 'eval_duration': 180264000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:30:09.410844Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 536333584, 'load_duration': 20328292, 'prompt_eval_count': 153, 'prompt_eval_duration': 338786000, 'eval_count': 4, 'eval_duration': 174930000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:30:15.258759Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement translates to \"A Syrian refugee uses food to raise awareness for her country\\'s cause.\" This is a plausible scenario and aligns with real-world examples of activists using creative methods to highlight social issues.  There\\'s no inherent logical inconsistency, and the claim could be independently verified through news reports or documentation of such initiatives. \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 5842903167, 'load_duration': 19658959, 'prompt_eval_count': 158, 'prompt_eval_duration': 324754000, 'eval_count': 77, 'eval_duration': 5495998000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:30:15.978183Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 714429083, 'load_duration': 20582833, 'prompt_eval_count': 158, 'prompt_eval_duration': 489607000, 'eval_count': 4, 'eval_duration': 201833000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:30:16.583582Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 598856000, 'load_duration': 20301875, 'prompt_eval_count': 157, 'prompt_eval_duration': 391728000, 'eval_count': 4, 'eval_duration': 184807000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:30:17.138488Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 548208333, 'load_duration': 20419958, 'prompt_eval_count': 160, 'prompt_eval_duration': 348174000, 'eval_count': 4, 'eval_duration': 176503000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:30:27.105773Z', 'message': {'role': 'assistant', 'content': 'It\\'s impossible for me to definitively say whether the statement \"تحالف الصدر يخسر الانتخابات البرلمانية في العراق\" (The Sadrist Alliance loses the parliamentary elections in Iraq) is real or fake without access to real-time information and election results.  \\n\\n**Here\\'s why:**\\n\\n* **I am a language model, not a news source.** I don\\'t have access to breaking news or the ability to verify election outcomes.\\n* **Political situations are complex and fluid.** Election results can change, and claims about them need to be verified by reliable sources.\\n\\n\\nTo determine the authenticity of this statement, you would need to consult reputable news outlets reporting on Iraqi elections. \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 9963425250, 'load_duration': 19973458, 'prompt_eval_count': 156, 'prompt_eval_duration': 319595000, 'eval_count': 145, 'eval_duration': 9620900000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:30:27.730015Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 616237792, 'load_duration': 20514292, 'prompt_eval_count': 160, 'prompt_eval_duration': 401905000, 'eval_count': 4, 'eval_duration': 191795000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:30:28.349009Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 609349417, 'load_duration': 21134334, 'prompt_eval_count': 158, 'prompt_eval_duration': 396557000, 'eval_count': 4, 'eval_duration': 189562000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:30:38.282062Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe text \"انتخابات الرئاسة المصرية 2018 في أرقام\" translates to \"Egyptian Presidential Elections 2018 in Numbers\". This is a factual topic and likely refers to statistical data about the election.  \\n\\n* **Content Verification:** Information about election results is typically publicly available from reliable sources like election commissions and news organizations.\\n* **Logical Consistency:** The statement itself is logically consistent. It indicates a specific event (Egyptian Presidential Elections 2018) and suggests numerical data will be presented.\\n\\n\\nTherefore, based on the nature of the text and its logical coherence, it\\'s highly probable that the content is real. \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 9927306000, 'load_duration': 20309292, 'prompt_eval_count': 157, 'prompt_eval_duration': 384857000, 'eval_count': 145, 'eval_duration': 9519975000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:30:38.909143Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 621490042, 'load_duration': 20368042, 'prompt_eval_count': 159, 'prompt_eval_duration': 408274000, 'eval_count': 4, 'eval_duration': 190299000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:30:39.51202Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 596527000, 'load_duration': 19749208, 'prompt_eval_count': 155, 'prompt_eval_duration': 387272000, 'eval_count': 4, 'eval_duration': 186844000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:30:51.331282Z', 'message': {'role': 'assistant', 'content': 'It\\'s impossible to definitively say whether the statement \"عملة بيتكوين في أعلى مستوياتها في 6 أسابيع\" (Bitcoin is at its highest level in 6 weeks) is real or fake without access to real-time Bitcoin price data.  \\n\\n**Here\\'s why:**\\n\\n* **Fluctuating Market:** Cryptocurrency prices, like Bitcoin, are incredibly volatile and change constantly. What might be true at one moment could be false the next.\\n* **Need for Verification:** To determine the authenticity, you would need to compare the statement to a reliable source of Bitcoin price information (e.g., a reputable cryptocurrency exchange or financial news website).\\n\\n**Therefore, I cannot provide an output of 0 or 1.**  You\\'ll need to consult a real-time Bitcoin price tracker to verify the statement. \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 11812849500, 'load_duration': 20267375, 'prompt_eval_count': 158, 'prompt_eval_duration': 370446000, 'eval_count': 174, 'eval_duration': 11419822000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:30:58.870738Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement \"مسؤول إماراتي يعلن تحسن العلاقات العربية التركية\" translates to \"An Emirati official announces improvement in Arab-Turkish relations.\"  This type of statement is plausible and aligns with recent geopolitical trends. There have been efforts towards reconciliation between Turkey and several Arab countries, including the UAE. \\n\\nTherefore, based on content verification (the possibility of such a statement being true) and logical consistency (it aligns with known geopolitical developments), the text is likely real. \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 7535168167, 'load_duration': 21198750, 'prompt_eval_count': 155, 'prompt_eval_duration': 420669000, 'eval_count': 108, 'eval_duration': 7090563000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:30:59.50145Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 622842959, 'load_duration': 20830042, 'prompt_eval_count': 158, 'prompt_eval_duration': 408931000, 'eval_count': 4, 'eval_duration': 190823000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:31:00.103344Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 596851250, 'load_duration': 19953333, 'prompt_eval_count': 159, 'prompt_eval_duration': 388784000, 'eval_count': 4, 'eval_duration': 186021000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:31:00.684698Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 575886542, 'load_duration': 20498334, 'prompt_eval_count': 160, 'prompt_eval_duration': 370118000, 'eval_count': 4, 'eval_duration': 182921000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:31:01.242892Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 551390959, 'load_duration': 21009167, 'prompt_eval_count': 161, 'prompt_eval_duration': 350280000, 'eval_count': 4, 'eval_duration': 177932000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:31:11.140959Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe text \"سبعة أسئلة تساعدك على فهم الصراع في سوريا\" translates to \"Seven questions to help you understand the conflict in Syria\".  This is a plausible title for an article or piece of content aiming to explain the complex Syrian conflict. \\n\\n* **Content Verification:** While I cannot verify the specific content without seeing the full text, the title itself suggests a factual and informative approach.\\n* **Logical Consistency:** The title is logically consistent. It proposes a set of questions as a means to understand a complex issue, which is a reasonable approach.\\n\\n\\nTherefore, based on the title alone, it appears more likely that the text is real (0). \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 9891999375, 'load_duration': 20251167, 'prompt_eval_count': 155, 'prompt_eval_duration': 329596000, 'eval_count': 145, 'eval_duration': 9539616000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:31:11.763883Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 617019041, 'load_duration': 19734958, 'prompt_eval_count': 157, 'prompt_eval_duration': 403928000, 'eval_count': 4, 'eval_duration': 191262000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:31:15.444439Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement translates to \"Gold at its lowest level in 17 months.\" This type of financial statement is commonly reported and can be verified through reputable financial news sources.  Therefore, it\\'s likely real. \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3672739750, 'load_duration': 20967167, 'prompt_eval_count': 156, 'prompt_eval_duration': 391543000, 'eval_count': 53, 'eval_duration': 3257980000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:31:16.081587Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 632417125, 'load_duration': 19955458, 'prompt_eval_count': 163, 'prompt_eval_duration': 414944000, 'eval_count': 4, 'eval_duration': 194765000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:31:16.705939Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 617121292, 'load_duration': 20569125, 'prompt_eval_count': 164, 'prompt_eval_duration': 404371000, 'eval_count': 4, 'eval_duration': 189554000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:31:17.314058Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 598899458, 'load_duration': 20636416, 'prompt_eval_count': 164, 'prompt_eval_duration': 389824000, 'eval_count': 4, 'eval_duration': 186202000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:31:17.895864Z', 'message': {'role': 'assistant', 'content': '0 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 576020458, 'load_duration': 20346458, 'prompt_eval_count': 162, 'prompt_eval_duration': 370989000, 'eval_count': 4, 'eval_duration': 182285000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:31:18.671267Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 768837834, 'load_duration': 20697584, 'prompt_eval_count': 168, 'prompt_eval_duration': 566786000, 'eval_count': 4, 'eval_duration': 178941000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:31:34.023376Z', 'message': {'role': 'assistant', 'content': 'It\\'s impossible for me to definitively say whether the statement \"أعلنت تونس عن غرق 48 من المهاجرين إليها\" (Tunisia announced the drowning of 48 migrants) is real or fake without access to external information sources.  \\n\\nHere\\'s why:\\n\\n* **I am a language model:** I can process and understand text, but I cannot verify real-world events.\\n* **Need for Fact-Checking:** Determining the authenticity of news requires cross-referencing with reliable news sources, official statements, or reports from organizations like the UN Refugee Agency. \\n\\n\\n**To get an accurate answer, you would need to:**\\n\\n1. **Search for reputable news sources:** Look for articles from well-known international news agencies or Tunisian media outlets reporting on this event.\\n2. **Check official statements:** See if the Tunisian government or relevant authorities have released any information about the incident. \\n3. **Consult fact-checking websites:** Organizations like Snopes or FactCheck.org often investigate claims circulating online. \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 15348113333, 'load_duration': 19452750, 'prompt_eval_count': 159, 'prompt_eval_duration': 336289000, 'eval_count': 217, 'eval_duration': 14989955000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:31:34.638177Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 607315000, 'load_duration': 19943875, 'prompt_eval_count': 157, 'prompt_eval_duration': 396023000, 'eval_count': 4, 'eval_duration': 189063000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:31:35.237412Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 595889541, 'load_duration': 19493750, 'prompt_eval_count': 165, 'prompt_eval_duration': 388868000, 'eval_count': 4, 'eval_duration': 185532000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:31:41.405862Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement translates to \"Kuwait refused to cooperate with the Philippines on the issue of domestic workers.\" This is a plausible statement reflecting real-world geopolitical issues.  \\n\\nWhile I cannot independently verify the specific details of this diplomatic situation, it aligns with known tensions between countries regarding labor practices and worker rights. \\n\\n\\nLet me know if you have any other statements you\\'d like me to analyze!'}, 'done_reason': 'stop', 'done': True, 'total_duration': 6165203083, 'load_duration': 19621583, 'prompt_eval_count': 160, 'prompt_eval_duration': 371856000, 'eval_count': 87, 'eval_duration': 5771737000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:31:42.079414Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 665461333, 'load_duration': 20558875, 'prompt_eval_count': 166, 'prompt_eval_duration': 441967000, 'eval_count': 4, 'eval_duration': 200937000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:32:00.399773Z', 'message': {'role': 'assistant', 'content': 'It\\'s impossible to definitively determine the authenticity of the provided text (\"جيش السوري استعادة السيطرة على آخر مناطق المعارضة قرب دمشق\") without further context and analysis. \\n\\nHere\\'s why:\\n\\n* **Language Barrier:** The text is in Arabic, and I don\\'t have the capability to translate and understand its nuances.\\n* **Lack of Context:**  I need more information about the source of this text. Is it from a news outlet? A social media post? Knowing the source would help assess its credibility.\\n* **Geopolitical Complexity:** The situation in Syria is complex, with multiple factions involved. Determining the accuracy of claims about military actions requires in-depth knowledge of the ongoing conflict.\\n\\n**To get an accurate assessment, you would need to:**\\n\\n1. **Translate the text:** Get a reliable translation into English or another language you understand.\\n2. **Research the source:** Find out where the text originated from and evaluate the source\\'s reputation for accuracy.\\n3. **Cross-reference information:** Compare the claims made in the text with reports from reputable news organizations and independent sources familiar with the Syrian conflict. \\n\\n\\nLet me know if you have any other questions that don\\'t require analyzing external information or making subjective judgments.'}, 'done_reason': 'stop', 'done': True, 'total_duration': 18316787333, 'load_duration': 19804917, 'prompt_eval_count': 160, 'prompt_eval_duration': 398742000, 'eval_count': 264, 'eval_duration': 17896193000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:32:01.017257Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 609660042, 'load_duration': 19995500, 'prompt_eval_count': 159, 'prompt_eval_duration': 399363000, 'eval_count': 4, 'eval_duration': 188045000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:32:01.616194Z', 'message': {'role': 'assistant', 'content': '0 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 590635084, 'load_duration': 20331417, 'prompt_eval_count': 159, 'prompt_eval_duration': 382922000, 'eval_count': 4, 'eval_duration': 185280000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:32:05.055444Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement translates to \"Gold reaches a 17-month high.\" This type of financial news is frequently reported and can be verified through reputable financial sources.  Therefore, the statement is likely real. \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 3430969458, 'load_duration': 20919125, 'prompt_eval_count': 153, 'prompt_eval_duration': 363465000, 'eval_count': 51, 'eval_duration': 3044410000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:32:05.699824Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 637727583, 'load_duration': 20691333, 'prompt_eval_count': 165, 'prompt_eval_duration': 414936000, 'eval_count': 4, 'eval_duration': 199896000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:32:06.344467Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 635056375, 'load_duration': 20493000, 'prompt_eval_count': 159, 'prompt_eval_duration': 418176000, 'eval_count': 4, 'eval_duration': 194310000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:32:06.965568Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 615563250, 'load_duration': 19308458, 'prompt_eval_count': 165, 'prompt_eval_duration': 404885000, 'eval_count': 4, 'eval_duration': 189107000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:32:07.559649Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 586319000, 'load_duration': 20388875, 'prompt_eval_count': 157, 'prompt_eval_duration': 379825000, 'eval_count': 4, 'eval_duration': 184049000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:32:08.119378Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 556265959, 'load_duration': 19700875, 'prompt_eval_count': 158, 'prompt_eval_duration': 356711000, 'eval_count': 4, 'eval_duration': 177654000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:32:08.659031Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 530298000, 'load_duration': 19821083, 'prompt_eval_count': 156, 'prompt_eval_duration': 333574000, 'eval_count': 4, 'eval_duration': 174839000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:32:09.174288Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 509782834, 'load_duration': 19395959, 'prompt_eval_count': 159, 'prompt_eval_duration': 319339000, 'eval_count': 4, 'eval_duration': 169160000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:32:09.687218Z', 'message': {'role': 'assistant', 'content': '0 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 502859750, 'load_duration': 21440834, 'prompt_eval_count': 162, 'prompt_eval_duration': 309979000, 'eval_count': 4, 'eval_duration': 168749000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:32:20.82914Z', 'message': {'role': 'assistant', 'content': 'It\\'s impossible to definitively determine the authenticity of the statement \"الصلب العراقي يسجل أعلى معدل صادرات في أغسطس\" (Iraqi steel records highest export rate in August) without further context and verification. \\n\\nHere\\'s why:\\n\\n* **Language Barrier:** While I can process the text, I don\\'t have access to real-time information or databases to verify Iraqi steel export statistics.\\n* **Need for Sources:** To assess authenticity, I would need to compare this statement with data from reputable sources like Iraqi government trade reports, international trade organizations, or financial news outlets.\\n\\n**Therefore, I cannot provide a definitive 0 (real) or 1 (fake) output.**  You would need to consult reliable sources to verify the claim. \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 11135523208, 'load_duration': 20505208, 'prompt_eval_count': 157, 'prompt_eval_duration': 302175000, 'eval_count': 161, 'eval_duration': 10810482000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:32:21.786813Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 948987417, 'load_duration': 20982542, 'prompt_eval_count': 170, 'prompt_eval_duration': 724547000, 'eval_count': 4, 'eval_duration': 201248000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:32:26.07857Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement translates to \"No stones fall from the Western Wall in Jerusalem.\" This is a factually accurate statement. The Western Wall is a retaining wall, not a freestanding structure prone to rockfalls.  \\n\\n\\nLet me know if you\\'d like me to analyze another statement!'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4286373125, 'load_duration': 20826708, 'prompt_eval_count': 159, 'prompt_eval_duration': 399358000, 'eval_count': 64, 'eval_duration': 3864023000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:32:26.749635Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 666838084, 'load_duration': 19181459, 'prompt_eval_count': 161, 'prompt_eval_duration': 437744000, 'eval_count': 4, 'eval_duration': 207643000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:32:27.412834Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 655303500, 'load_duration': 20288833, 'prompt_eval_count': 164, 'prompt_eval_duration': 435007000, 'eval_count': 4, 'eval_duration': 197956000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:32:28.034678Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 617911583, 'load_duration': 19942125, 'prompt_eval_count': 161, 'prompt_eval_duration': 406159000, 'eval_count': 4, 'eval_duration': 189497000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:32:34.206588Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement translates to \"Iran ruled out increasing the level of uranium enrichment.\" This is a plausible statement given Iran\\'s history with its nuclear program and ongoing negotiations with world powers.  \\n\\nWhile I cannot independently verify the statement, it aligns with broader geopolitical discussions and news reports about Iran\\'s nuclear activities. \\n\\n\\nLet me know if you have any other statements you\\'d like me to analyze!'}, 'done_reason': 'stop', 'done': True, 'total_duration': 6166572417, 'load_duration': 20548542, 'prompt_eval_count': 156, 'prompt_eval_duration': 380340000, 'eval_count': 89, 'eval_duration': 5762962000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:32:34.885776Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 672307625, 'load_duration': 20102708, 'prompt_eval_count': 160, 'prompt_eval_duration': 451707000, 'eval_count': 4, 'eval_duration': 198119000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:32:35.502941Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 611203667, 'load_duration': 20311875, 'prompt_eval_count': 165, 'prompt_eval_duration': 401928000, 'eval_count': 4, 'eval_duration': 186137000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:32:46.860075Z', 'message': {'role': 'assistant', 'content': 'It\\'s impossible to definitively determine the authenticity of the statement \"مصر تحقق أعلى معدل نمو في 10 سنوات\" (Egypt achieves highest growth rate in 10 years) without further context and verification.  \\n\\nHere\\'s why:\\n\\n* **Lack of Specifics:** The statement is very general. What kind of growth rate? Economic? Population? Industrial? Without specifics, it\\'s impossible to verify.\\n* **Need for Data:** To assess authenticity, we would need to compare Egypt\\'s growth rates over the past 10 years with reliable sources like the World Bank or IMF.\\n\\n**Therefore, I cannot provide a definitive 0 (real) or 1 (fake).**  You would need to conduct further research to determine the statement\\'s accuracy. \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 11350279084, 'load_duration': 20720292, 'prompt_eval_count': 155, 'prompt_eval_duration': 366295000, 'eval_count': 166, 'eval_duration': 10960788000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:32:54.425255Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe text is a genuine question in Arabic asking \"What are the films nominated for Best Foreign Language Film at the 2018 Oscars?\".  \\n\\n* **Content Verification:** This type of question about award nominations is common and verifiable through reliable sources like official Oscar websites or film databases.\\n* **Logical Consistency:** The question is logically sound and doesn\\'t contain any contradictions. \\n\\n\\nLet me know if you have any other text you\\'d like me to analyze!'}, 'done_reason': 'stop', 'done': True, 'total_duration': 7557968583, 'load_duration': 19921708, 'prompt_eval_count': 167, 'prompt_eval_duration': 700631000, 'eval_count': 104, 'eval_duration': 6835278000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:32:59.03673Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement \"السعودية تلغي سباق دراجات\" translates to \"Saudi Arabia cancels cycling race\".  This type of news is plausible and could be verified through news sources or official Saudi Arabian announcements. \\n\\n\\nLet me know if you\\'d like me to analyze another statement!'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4602229667, 'load_duration': 21079792, 'prompt_eval_count': 150, 'prompt_eval_duration': 413701000, 'eval_count': 66, 'eval_duration': 4165040000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:33:12.820723Z', 'message': {'role': 'assistant', 'content': 'It\\'s impossible for me to definitively say whether a news event is \"real\" or \"fake\" based solely on a text snippet in Arabic.  Here\\'s why:\\n\\n* **Lack of Context:** The statement \"توقف احتجاجات الأردن بعد استقالة رئيس الوزراء\" (Protests in Jordan stopped after the resignation of the Prime Minister) needs context. \\n    * When did these protests occur?\\n    * What were the reasons for the protests?\\n    * Was the Prime Minister\\'s resignation directly linked to the protests, or were there other factors involved?\\n\\n* **Verification Requires Sources:** To determine authenticity, I would need to cross-reference this statement with reliable news sources in Arabic and English. \\n\\n**Therefore, I cannot provide a definitive 0 (real) or 1 (fake) answer.**  \\n\\nTo get an accurate assessment, you\\'d need to research the event using reputable news outlets. \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 13779943792, 'load_duration': 20860667, 'prompt_eval_count': 156, 'prompt_eval_duration': 431069000, 'eval_count': 197, 'eval_duration': 13325759000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:33:29.185584Z', 'message': {'role': 'assistant', 'content': 'It\\'s impossible for me to definitively say whether a news statement is \"real\" or \"fake\" with only the text provided.  Here\\'s why:\\n\\n* **I lack real-time information:** I am a language model and don\\'t have access to constantly updating news sources to verify claims. \\n* **Context is crucial:** The statement \"إسرائيل بمنع الوقود إلى غزة\" (Israel prevented fuel to Gaza) needs context.  Was this a recent event? Is there an ongoing blockade? Understanding the situation is key to determining accuracy.\\n\\n**To determine the authenticity of this statement, you would need to:**\\n\\n1. **Consult reputable news sources:** Check major international news organizations for reports on the situation in Gaza and any fuel restrictions imposed by Israel.\\n2. **Look for corroborating evidence:** See if other sources (human rights groups, government statements) confirm or deny the claim.\\n3. **Consider potential biases:** Be aware that different sources may have varying perspectives on the Israeli-Palestinian conflict. \\n\\n\\nLet me know if you have any other questions that don\\'t require real-time information or subjective judgment!'}, 'done_reason': 'stop', 'done': True, 'total_duration': 16359278500, 'load_duration': 20197000, 'prompt_eval_count': 152, 'prompt_eval_duration': 411132000, 'eval_count': 236, 'eval_duration': 15925805000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:33:36.159662Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement \"منع التعامل بالعملات الرقمية في الهند\" translates to \"Banning the dealing of cryptocurrencies in India.\"  This statement is **real**. \\n\\nIndia has indeed implemented regulations and restrictions on cryptocurrency trading and usage. While there isn\\'t a complete outright ban, the government has taken steps to limit its accessibility and use.\\n\\n\\nLet me know if you have any other statements you\\'d like me to analyze!'}, 'done_reason': 'stop', 'done': True, 'total_duration': 6968146000, 'load_duration': 20252208, 'prompt_eval_count': 154, 'prompt_eval_duration': 411420000, 'eval_count': 98, 'eval_duration': 6534128000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:33:36.791656Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 624457375, 'load_duration': 20274875, 'prompt_eval_count': 156, 'prompt_eval_duration': 410599000, 'eval_count': 4, 'eval_duration': 191243000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:33:43.191469Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement translates to \"Erdogan said that the Turkish people tasked him with leading the country.\" This is a plausible statement and aligns with Erdogan\\'s political role as the President of Turkey.  \\n\\nWhile I cannot independently verify the exact quote and context, it is consistent with Erdogan\\'s public persona and political position. \\n\\n\\nLet me know if you have any other statements you\\'d like me to analyze!'}, 'done_reason': 'stop', 'done': True, 'total_duration': 6391194417, 'load_duration': 20768667, 'prompt_eval_count': 159, 'prompt_eval_duration': 387464000, 'eval_count': 91, 'eval_duration': 5980775000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:33:43.849192Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 651680208, 'load_duration': 20468042, 'prompt_eval_count': 153, 'prompt_eval_duration': 432679000, 'eval_count': 4, 'eval_duration': 196188000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:33:48.265962Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe text \"انخفاض على عائدات السياحة الاردنية\" translates to \"Decline in Jordanian tourism revenues.\" This is a plausible statement and can be verified through economic reports and news articles about Jordan\\'s tourism industry.  Therefore, it is likely real. \\n\\n\\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4411256625, 'load_duration': 19995625, 'prompt_eval_count': 155, 'prompt_eval_duration': 390953000, 'eval_count': 65, 'eval_duration': 3997922000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:33:48.981513Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 709051667, 'load_duration': 19701125, 'prompt_eval_count': 153, 'prompt_eval_duration': 468269000, 'eval_count': 4, 'eval_duration': 218797000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:33:49.673074Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 685365833, 'load_duration': 19753250, 'prompt_eval_count': 162, 'prompt_eval_duration': 458304000, 'eval_count': 4, 'eval_duration': 204586000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:33:50.298215Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 619682625, 'load_duration': 20279542, 'prompt_eval_count': 165, 'prompt_eval_duration': 408962000, 'eval_count': 4, 'eval_duration': 188372000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:33:50.881052Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 578042666, 'load_duration': 20458791, 'prompt_eval_count': 157, 'prompt_eval_duration': 373556000, 'eval_count': 4, 'eval_duration': 181319000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:33:51.42761Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 541712042, 'load_duration': 19879667, 'prompt_eval_count': 153, 'prompt_eval_duration': 343911000, 'eval_count': 4, 'eval_duration': 175685000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:33:51.954403Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 520454083, 'load_duration': 20354250, 'prompt_eval_count': 155, 'prompt_eval_duration': 325743000, 'eval_count': 4, 'eval_duration': 172071000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:33:52.463938Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 503541125, 'load_duration': 20424625, 'prompt_eval_count': 159, 'prompt_eval_duration': 312152000, 'eval_count': 4, 'eval_duration': 168691000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:34:05.809707Z', 'message': {'role': 'assistant', 'content': 'It\\'s impossible to definitively determine the authenticity of the statement \"وصل عدد من المهاجرين إلى سواحل تونس بكل سلام\" (A number of migrants arrived safely on the shores of Tunisia) without further context and verification. \\n\\nHere\\'s why:\\n\\n* **Language Barrier:** While I can translate the Arabic, I don\\'t have access to real-time information or news sources to verify if such an event occurred.\\n* **Lack of Specificity:** The statement is vague.  \"A number of migrants\" and \"safely\" are subjective terms. To assess authenticity, we\\'d need details like:\\n    * Approximate number of migrants\\n    * Date and time of arrival\\n    * Source of the information\\n\\n**Therefore, I cannot provide a definitive 0 or 1 output.**  To determine its authenticity, you would need to consult reliable news sources or organizations that track migration patterns. \\n\\n\\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 13340537583, 'load_duration': 20429208, 'prompt_eval_count': 157, 'prompt_eval_duration': 302895000, 'eval_count': 191, 'eval_duration': 13014865000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:34:15.448532Z', 'message': {'role': 'assistant', 'content': \"It's impossible for me to definitively determine the authenticity of the Arabic text provided. I am a text-based AI and lack the capability to:\\n\\n* **Verify Information:** I cannot access external websites or databases to cross-reference the claims made in the text. \\n* **Understand Nuance:**  While I can translate the text, understanding the full context and potential biases within a news story requires cultural and situational awareness that I don't possess.\\n\\n\\n**Therefore, I cannot provide an output of 0 or 1.** To determine the authenticity of this statement, you would need to consult reliable news sources in Arabic or seek verification from fact-checking organizations. \\n\"}, 'done_reason': 'stop', 'done': True, 'total_duration': 9633880583, 'load_duration': 20187833, 'prompt_eval_count': 165, 'prompt_eval_duration': 426179000, 'eval_count': 139, 'eval_duration': 9185105000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:34:16.072859Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 618462667, 'load_duration': 20322292, 'prompt_eval_count': 164, 'prompt_eval_duration': 405916000, 'eval_count': 4, 'eval_duration': 189736000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:34:16.677598Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 598826875, 'load_duration': 20429167, 'prompt_eval_count': 160, 'prompt_eval_duration': 389095000, 'eval_count': 4, 'eval_duration': 187076000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:34:17.264739Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 577223000, 'load_duration': 20879917, 'prompt_eval_count': 156, 'prompt_eval_duration': 369175000, 'eval_count': 4, 'eval_duration': 182739000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:34:17.822837Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 551235916, 'load_duration': 20185708, 'prompt_eval_count': 156, 'prompt_eval_duration': 350383000, 'eval_count': 4, 'eval_duration': 178689000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:34:25.487131Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement translates to \"Egypt\\'s House of Representatives passes a law to combat cybercrime.\" This type of legislation is common and plausible in today\\'s world.  \\n\\n* **Content Verification:** While I cannot directly verify the existence of this specific law, it aligns with global trends of governments enacting laws to address online crime. \\n* **Logical Consistency:** The statement is logically sound and doesn\\'t contain any contradictions. \\n\\n\\nTherefore, based on these factors, the statement appears to be real.'}, 'done_reason': 'stop', 'done': True, 'total_duration': 7659235166, 'load_duration': 19961708, 'prompt_eval_count': 160, 'prompt_eval_duration': 337223000, 'eval_count': 110, 'eval_duration': 7299636000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:34:33.604305Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement translates to \"After US sanctions, widespread abstention from Iranian oil.\" This is a plausible statement given the context of US sanctions against Iran and their impact on Iranian oil exports.  \\n\\n* **Content Verification:** News sources frequently report on the effects of US sanctions on Iran\\'s oil industry. \\n* **Logical Consistency:** The statement logically follows the premise that sanctions often aim to reduce a country\\'s economic activity, including its ability to export goods like oil.\\n\\n\\nTherefore, based on these factors, the statement appears authentic.'}, 'done_reason': 'stop', 'done': True, 'total_duration': 8111278500, 'load_duration': 20821708, 'prompt_eval_count': 157, 'prompt_eval_duration': 383699000, 'eval_count': 117, 'eval_duration': 7703010000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:34:34.21365Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 604236500, 'load_duration': 19804958, 'prompt_eval_count': 152, 'prompt_eval_duration': 393051000, 'eval_count': 4, 'eval_duration': 188954000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:34:43.768917Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe provided text \"الانتخابات الرئاسية المصرية ما بين دعوات المقاطعة والمشاركة\" translates to \"Egyptian presidential elections between calls for boycott and participation\". This is a plausible statement reflecting the complex political landscape surrounding Egyptian elections.  \\n\\n* **Content Verification:** While I cannot independently verify specific details about Egyptian election campaigns, the general theme of debates around participation versus boycott is common in democratic processes.\\n* **Logical Consistency:** The statement presents two opposing viewpoints (boycott and participation) which are logically consistent within the context of an election. \\n\\n\\nTherefore, based on these considerations, the text appears to be a real and plausible statement.'}, 'done_reason': 'stop', 'done': True, 'total_duration': 9547712125, 'load_duration': 20323666, 'prompt_eval_count': 158, 'prompt_eval_duration': 381192000, 'eval_count': 139, 'eval_duration': 9144036000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:34:44.391787Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 614981334, 'load_duration': 20141375, 'prompt_eval_count': 158, 'prompt_eval_duration': 401921000, 'eval_count': 4, 'eval_duration': 190683000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:34:45.001694Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 603429709, 'load_duration': 20217917, 'prompt_eval_count': 163, 'prompt_eval_duration': 393414000, 'eval_count': 4, 'eval_duration': 187341000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:34:45.590991Z', 'message': {'role': 'assistant', 'content': '0 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 579060750, 'load_duration': 20997625, 'prompt_eval_count': 154, 'prompt_eval_duration': 372469000, 'eval_count': 4, 'eval_duration': 183011000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:34:46.155227Z', 'message': {'role': 'assistant', 'content': '0 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 557484000, 'load_duration': 20500500, 'prompt_eval_count': 155, 'prompt_eval_duration': 355065000, 'eval_count': 4, 'eval_duration': 179599000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:34:46.698204Z', 'message': {'role': 'assistant', 'content': '0 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 536181417, 'load_duration': 20588334, 'prompt_eval_count': 159, 'prompt_eval_duration': 339536000, 'eval_count': 4, 'eval_duration': 173595000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:34:47.223666Z', 'message': {'role': 'assistant', 'content': '0 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 519477542, 'load_duration': 20079084, 'prompt_eval_count': 156, 'prompt_eval_duration': 324750000, 'eval_count': 4, 'eval_duration': 172369000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:35:00.475371Z', 'message': {'role': 'assistant', 'content': 'It\\'s impossible to definitively determine the authenticity of the Arabic text \"مظاهرات البصرة السلطات ترفع حظر التجول في المدينة\"  without further context and analysis. \\n\\nHere\\'s why:\\n\\n* **Language Barrier:** I don\\'t understand Arabic, so I can\\'t directly assess the content for logical consistency or factual accuracy.\\n* **Need for Verification:** Even if I understood the text, determining its authenticity would require cross-referencing it with reliable news sources, official statements, or eyewitness accounts.\\n\\n**To get a proper answer, you would need to:**\\n\\n1. **Translate the text:** Get an accurate English translation of the Arabic statement.\\n2. **Fact-Check:** Compare the translated information with reputable news sources and reports about Basra (the city mentioned). \\n\\n\\nLet me know if you have the translated text, and I can help you analyze it further! \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 13246797625, 'load_duration': 19686750, 'prompt_eval_count': 159, 'prompt_eval_duration': 315772000, 'eval_count': 192, 'eval_duration': 12909260000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:35:05.513008Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement translates to \"In Iraq, applications for ministerial portfolios are submitted online.\" This claim is plausible and aligns with the increasing digitization of government processes worldwide.  While I cannot independently verify the specific Iraqi policy, the general concept is realistic. \\n\\n\\nLet me know if you\\'d like to analyze another statement!'}, 'done_reason': 'stop', 'done': True, 'total_duration': 5030893709, 'load_duration': 20520167, 'prompt_eval_count': 155, 'prompt_eval_duration': 413098000, 'eval_count': 72, 'eval_duration': 4594648000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:35:21.109232Z', 'message': {'role': 'assistant', 'content': 'It\\'s impossible for me to definitively determine the authenticity of that statement.  Here\\'s why:\\n\\n* **I lack real-world knowledge:** I am a language model and cannot access external websites or news sources to verify the information. \\n* **Context is crucial:** The statement \"إسرائيل تتعامل بالقوة المتكافئة مع المعارضين على حدود غزة\" (Israel deals with opponents on the Gaza border with equal force) is highly charged politically. Determining its truthfulness requires understanding the complex geopolitical situation in the region, which is beyond my capabilities.\\n\\n**To get an accurate assessment, you would need to:**\\n\\n1. **Consult reputable news sources:** Look for reporting from organizations known for their factual accuracy and impartiality.\\n2. **Consider multiple perspectives:** Read accounts from both Israeli and Palestinian sources to gain a more balanced understanding.\\n3. **Be aware of potential bias:** Recognize that all sources may have some degree of bias, so critically evaluate the information presented. \\n\\n\\nLet me know if you have any other questions that don\\'t require real-world knowledge!'}, 'done_reason': 'stop', 'done': True, 'total_duration': 15587332125, 'load_duration': 21242167, 'prompt_eval_count': 160, 'prompt_eval_duration': 441562000, 'eval_count': 225, 'eval_duration': 15122031000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:35:21.739864Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 624945292, 'load_duration': 19970875, 'prompt_eval_count': 157, 'prompt_eval_duration': 413250000, 'eval_count': 4, 'eval_duration': 189538000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:35:26.804365Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe text you provided translates to \"Oil continues its decline and talk of a possible increase in OPEC production.\" This statement is plausible and aligns with recent trends in the global oil market.  Therefore, it\\'s likely real. \\n\\n\\nLet me know if you have any other text you\\'d like me to analyze!'}, 'done_reason': 'stop', 'done': True, 'total_duration': 5061086167, 'load_duration': 19596000, 'prompt_eval_count': 159, 'prompt_eval_duration': 389985000, 'eval_count': 72, 'eval_duration': 4649462000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:35:27.499529Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 685623167, 'load_duration': 20734459, 'prompt_eval_count': 162, 'prompt_eval_duration': 457986000, 'eval_count': 4, 'eval_duration': 204471000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:35:28.121432Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 616755958, 'load_duration': 20225292, 'prompt_eval_count': 158, 'prompt_eval_duration': 406828000, 'eval_count': 4, 'eval_duration': 187583000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:35:33.511489Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement \"باراغواي تعيد سفارتها لدى إسرائيل إلى تل أبيب\" translates to \"Paraguay reopens its embassy in Israel in Tel Aviv\".  This event did indeed occur. Paraguay reopened its embassy in Israel in May 2023. \\n\\n\\nLet me know if you\\'d like me to analyze another statement!'}, 'done_reason': 'stop', 'done': True, 'total_duration': 5383728583, 'load_duration': 20045958, 'prompt_eval_count': 158, 'prompt_eval_duration': 376892000, 'eval_count': 78, 'eval_duration': 4984670000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:35:34.548199Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 1028347625, 'load_duration': 20360375, 'prompt_eval_count': 168, 'prompt_eval_duration': 796123000, 'eval_count': 4, 'eval_duration': 209557000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:35:41.65737Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement \"أثيوبيا تؤكد حرصها على حصة مصر بالنيل\" translates to \"Ethiopia affirms its commitment to Egypt\\'s share of the Nile.\" This is a plausible statement given the ongoing discussions and negotiations between Ethiopia, Egypt, and Sudan regarding the Grand Ethiopian Renaissance Dam (GERD) and water sharing from the Nile River. \\n\\nTherefore, based on content verification and logical consistency, the text appears to be real. \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 7102963917, 'load_duration': 19987417, 'prompt_eval_count': 157, 'prompt_eval_duration': 406317000, 'eval_count': 100, 'eval_duration': 6674401000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:35:42.311745Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 646808125, 'load_duration': 20653125, 'prompt_eval_count': 155, 'prompt_eval_duration': 431372000, 'eval_count': 4, 'eval_duration': 192600000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:35:42.906858Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 591048458, 'load_duration': 19918458, 'prompt_eval_count': 158, 'prompt_eval_duration': 384519000, 'eval_count': 4, 'eval_duration': 184206000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:35:43.47158Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 558095750, 'load_duration': 19832125, 'prompt_eval_count': 155, 'prompt_eval_duration': 357175000, 'eval_count': 4, 'eval_duration': 178648000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:35:44.009568Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 530750542, 'load_duration': 20501250, 'prompt_eval_count': 158, 'prompt_eval_duration': 334545000, 'eval_count': 4, 'eval_duration': 173327000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:35:44.525753Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 511691833, 'load_duration': 20255333, 'prompt_eval_count': 164, 'prompt_eval_duration': 319386000, 'eval_count': 4, 'eval_duration': 169961000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:35:53.365467Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement translates to \"Protests in Jordan continue despite the resignation of Prime Minister Hani Mulki.\" This type of statement is commonly found in news reports and reflects real-world events.  \\n\\n* **Content Verification:** News sources often report on protests and political changes in countries like Jordan. \\n* **Logical Consistency:** The statement is logically consistent. Resignations of leaders sometimes do not immediately quell public unrest, especially if underlying issues remain unresolved.\\n\\n\\nTherefore, based on the likelihood of such events being reported and the logical connection between resignation and continued protests, the statement appears authentic.'}, 'done_reason': 'stop', 'done': True, 'total_duration': 8833840209, 'load_duration': 20963125, 'prompt_eval_count': 160, 'prompt_eval_duration': 306573000, 'eval_count': 127, 'eval_duration': 8503526000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:35:53.976404Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 604601125, 'load_duration': 20094750, 'prompt_eval_count': 160, 'prompt_eval_duration': 393192000, 'eval_count': 4, 'eval_duration': 188829000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:35:54.576841Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 596579791, 'load_duration': 20230708, 'prompt_eval_count': 157, 'prompt_eval_duration': 386559000, 'eval_count': 4, 'eval_duration': 187486000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:35:55.164681Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 582024625, 'load_duration': 20304416, 'prompt_eval_count': 157, 'prompt_eval_duration': 376645000, 'eval_count': 4, 'eval_duration': 182843000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:35:55.736457Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 568197250, 'load_duration': 20542209, 'prompt_eval_count': 161, 'prompt_eval_duration': 364167000, 'eval_count': 4, 'eval_duration': 180898000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:35:56.296874Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 554440916, 'load_duration': 19830291, 'prompt_eval_count': 157, 'prompt_eval_duration': 353484000, 'eval_count': 4, 'eval_duration': 178964000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:35:56.840691Z', 'message': {'role': 'assistant', 'content': '0 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 538189083, 'load_duration': 20364250, 'prompt_eval_count': 152, 'prompt_eval_duration': 339434000, 'eval_count': 4, 'eval_duration': 176051000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:36:04.646358Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement translates to \"The Egyptian House of Representatives approves the Electronic Crime Combating Law.\" This type of news is plausible and frequently occurs.  \\n\\n* **Content Verification:** While I cannot directly verify the law\\'s passage, a quick search reveals numerous credible news sources reporting on Egypt\\'s efforts to combat cybercrime. \\n* **Logical Consistency:** The statement is logically consistent. Governments often enact laws to address societal issues like cybercrime.\\n\\n\\nTherefore, based on these factors, the statement appears authentic.'}, 'done_reason': 'stop', 'done': True, 'total_duration': 7800039125, 'load_duration': 20432292, 'prompt_eval_count': 158, 'prompt_eval_duration': 332071000, 'eval_count': 111, 'eval_duration': 7445313000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:36:05.253596Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 602986458, 'load_duration': 20380208, 'prompt_eval_count': 164, 'prompt_eval_duration': 393308000, 'eval_count': 4, 'eval_duration': 187013000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:36:06.067568Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 807099042, 'load_duration': 20270834, 'prompt_eval_count': 147, 'prompt_eval_duration': 591751000, 'eval_count': 4, 'eval_duration': 192712000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:36:06.682253Z', 'message': {'role': 'assistant', 'content': '0 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 608417500, 'load_duration': 20176708, 'prompt_eval_count': 158, 'prompt_eval_duration': 396139000, 'eval_count': 4, 'eval_duration': 189563000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:36:07.529724Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 841358167, 'load_duration': 20384667, 'prompt_eval_count': 170, 'prompt_eval_duration': 631301000, 'eval_count': 4, 'eval_duration': 187435000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:36:19.628746Z', 'message': {'role': 'assistant', 'content': 'It\\'s impossible for me to definitively determine the authenticity of that statement. I am a text-based AI and lack access to real-time information or the ability to verify news sources. \\n\\nTo assess the statement\\'s authenticity, you would need to:\\n\\n1. **Translate the Text:** The text is in Arabic. You\\'ll need an accurate translation to understand its meaning.\\n2. **Consult Reputable News Sources:** Check if major news organizations are reporting on this development regarding Syrian opposition groups in Idlib. Look for corroboration from multiple sources.\\n3. **Consider the Source:** If you encountered this text on a specific website or platform, research its reputation for accuracy and potential biases.\\n\\n**Remember:** I cannot provide a definitive \"0\" (real) or \"1\" (fake) answer without further investigation. \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 12093069250, 'load_duration': 20234667, 'prompt_eval_count': 164, 'prompt_eval_duration': 381162000, 'eval_count': 174, 'eval_duration': 11689146000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:36:20.290361Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 652903417, 'load_duration': 19973292, 'prompt_eval_count': 157, 'prompt_eval_duration': 432142000, 'eval_count': 4, 'eval_duration': 198135000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:36:20.905169Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 607412875, 'load_duration': 20071583, 'prompt_eval_count': 155, 'prompt_eval_duration': 396952000, 'eval_count': 4, 'eval_duration': 188198000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:36:32.860342Z', 'message': {'role': 'assistant', 'content': 'It\\'s impossible to definitively say whether the statement \"عملة ليبرا في أعلى مستوياتها في 6 أسابيع\" (Libra coin at its highest levels in 6 weeks) is real or fake without access to real-time financial data.  \\n\\n**Here\\'s why:**\\n\\n* **Content Verification:** To verify this, you would need to check the price history of Libra (or a cryptocurrency with that name) over the past six weeks from a reliable source like a cryptocurrency exchange or market tracker.\\n* **Logical Consistency:** The statement itself is logically consistent. It claims a specific outcome (Libra reaching its highest point) within a defined timeframe (6 weeks).\\n\\n**Therefore, I cannot provide an output of 0 or 1.** You would need to consult financial data to determine the accuracy of the statement. \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 11947677291, 'load_duration': 20139083, 'prompt_eval_count': 158, 'prompt_eval_duration': 377889000, 'eval_count': 172, 'eval_duration': 11547093000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:36:33.519944Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 654362042, 'load_duration': 19473459, 'prompt_eval_count': 159, 'prompt_eval_duration': 435373000, 'eval_count': 4, 'eval_duration': 197411000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:36:34.138464Z', 'message': {'role': 'assistant', 'content': '0 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 612700583, 'load_duration': 19758458, 'prompt_eval_count': 160, 'prompt_eval_duration': 401573000, 'eval_count': 4, 'eval_duration': 187629000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:36:44.959847Z', 'message': {'role': 'assistant', 'content': \"0 \\n\\n**Explanation:**\\n\\nThe statement appears to be a real news headline.  Here's why:\\n\\n* **Content Verification:** The text mentions the Egyptian Public Prosecution and a prominent political figure, Abdel Moneim Aboul Fotouh. These are recognizable entities in Egyptian politics. A quick search online would likely reveal news articles confirming this type of action.\\n* **Logical Consistency:** The statement is logically consistent. It reports an action (seizure of assets) taken by a legal authority (the Public Prosecution) against a specific individual (Abdel Moneim Aboul Fotouh). This type of scenario is plausible within the context of political and legal developments in Egypt. \\n\\n\\nLet me know if you'd like me to analyze another statement!\"}, 'done_reason': 'stop', 'done': True, 'total_duration': 10815284958, 'load_duration': 20058208, 'prompt_eval_count': 166, 'prompt_eval_duration': 371927000, 'eval_count': 156, 'eval_duration': 10420659000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:36:45.632794Z', 'message': {'role': 'assistant', 'content': '0 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 663504875, 'load_duration': 20336167, 'prompt_eval_count': 158, 'prompt_eval_duration': 438063000, 'eval_count': 4, 'eval_duration': 202534000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:37:00.176419Z', 'message': {'role': 'assistant', 'content': 'It\\'s impossible for me to definitively determine the authenticity of that statement without access to external information sources.  \\n\\nHere\\'s why:\\n\\n* **I lack real-time knowledge:** I am a language model and don\\'t have access to the internet to verify news or political statements. \\n* **Nuance and Context are Crucial:** Determining if a statement is \"real\" or \"fake\" often requires understanding complex geopolitical situations, historical context, and potentially even cultural nuances.\\n\\n**To get an accurate answer, you would need to:**\\n\\n1. **Consult reputable news sources:** Look for reporting on Turkish citizenship policies from well-established news organizations.\\n2. **Check official government websites:** See if the Turkish government has published any statements regarding citizenship for descendants of Sultan Abdul Hamid II. \\n3. **Consider expert analysis:** Seek out opinions from political analysts or historians who specialize in Turkey and its legal framework. \\n\\n\\nLet me know if you have other questions that don\\'t require external fact-checking!'}, 'done_reason': 'stop', 'done': True, 'total_duration': 14537922750, 'load_duration': 19699167, 'prompt_eval_count': 162, 'prompt_eval_duration': 412234000, 'eval_count': 209, 'eval_duration': 14103678000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:37:08.125766Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement translates to \"Russia\\'s military operation in Eastern Ghouta is still in its early stages.\"  This type of statement, while potentially controversial, is within the realm of plausible geopolitical commentary. It doesn\\'t contain inherently illogical claims. \\n\\nTo definitively determine its authenticity, one would need to cross-reference it with news reports and analyses from reputable sources covering the Syrian conflict. However, based on the provided information alone, there\\'s no clear indication that the statement is demonstrably false. \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 7939041875, 'load_duration': 20448375, 'prompt_eval_count': 159, 'prompt_eval_duration': 427982000, 'eval_count': 112, 'eval_duration': 7487551000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:37:09.025172Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 891417584, 'load_duration': 20164959, 'prompt_eval_count': 169, 'prompt_eval_duration': 677066000, 'eval_count': 4, 'eval_duration': 192010000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:37:13.942118Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement translates to \"Avengers: Infinity War achieves unprecedented box office revenue.\" This is a plausible claim, as Avengers: Infinity War was a highly successful and popular film.  \\n\\nWhile I cannot independently verify the exact box office figures, the statement aligns with general knowledge about the film\\'s commercial success. \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 4911579042, 'load_duration': 20516708, 'prompt_eval_count': 165, 'prompt_eval_duration': 393929000, 'eval_count': 71, 'eval_duration': 4494848000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:37:14.67239Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 724759334, 'load_duration': 20559417, 'prompt_eval_count': 165, 'prompt_eval_duration': 485986000, 'eval_count': 4, 'eval_duration': 215877000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:37:15.33Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 646886333, 'load_duration': 21441333, 'prompt_eval_count': 159, 'prompt_eval_duration': 431558000, 'eval_count': 4, 'eval_duration': 191715000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:37:15.92578Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 592124833, 'load_duration': 20643375, 'prompt_eval_count': 154, 'prompt_eval_duration': 383551000, 'eval_count': 4, 'eval_duration': 185406000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:37:16.494456Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 562790416, 'load_duration': 19716000, 'prompt_eval_count': 152, 'prompt_eval_duration': 361342000, 'eval_count': 4, 'eval_duration': 179407000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:37:17.041235Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 542221375, 'load_duration': 19592959, 'prompt_eval_count': 161, 'prompt_eval_duration': 345298000, 'eval_count': 4, 'eval_duration': 174984000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:37:17.573832Z', 'message': {'role': 'assistant', 'content': '0 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 526449667, 'load_duration': 20246458, 'prompt_eval_count': 164, 'prompt_eval_duration': 331570000, 'eval_count': 4, 'eval_duration': 172452000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:37:22.674626Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement translates to \"Departure of the famous Icelandic composer Jóhann Jóhannsson.\" This is a factual statement. Jóhann Jóhannsson, a renowned Icelandic composer, passed away in 2018.  \\n\\n\\nLet me know if you\\'d like me to analyze another statement!'}, 'done_reason': 'stop', 'done': True, 'total_duration': 5095506542, 'load_duration': 20100042, 'prompt_eval_count': 162, 'prompt_eval_duration': 319593000, 'eval_count': 71, 'eval_duration': 4753619000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:37:23.412932Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 729500875, 'load_duration': 20523958, 'prompt_eval_count': 160, 'prompt_eval_duration': 496475000, 'eval_count': 4, 'eval_duration': 209898000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:37:32.802076Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement translates to \"Gold remains stable despite the dollar\\'s decline.\" This is a plausible economic statement.  \\n\\n* **Content Verification:** While I can\\'t access real-time market data, the relationship between gold prices and the US dollar is well-documented. Gold is often seen as a safe haven asset, and its price tends to rise when the dollar weakens.\\n* **Logical Consistency:** The statement is logically consistent. A decline in the dollar could lead investors to seek alternative assets like gold, thus stabilizing or even increasing its price. \\n\\n\\nTherefore, based on general economic principles, the statement appears authentic.'}, 'done_reason': 'stop', 'done': True, 'total_duration': 9384263625, 'load_duration': 20106791, 'prompt_eval_count': 156, 'prompt_eval_duration': 404804000, 'eval_count': 134, 'eval_duration': 8957077000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:37:33.422893Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 611356000, 'load_duration': 21071250, 'prompt_eval_count': 150, 'prompt_eval_duration': 397458000, 'eval_count': 4, 'eval_duration': 190387000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:37:34.026699Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 598227125, 'load_duration': 20215125, 'prompt_eval_count': 153, 'prompt_eval_duration': 388464000, 'eval_count': 4, 'eval_duration': 187034000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:37:34.616082Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 582942625, 'load_duration': 19916292, 'prompt_eval_count': 156, 'prompt_eval_duration': 376801000, 'eval_count': 4, 'eval_duration': 184167000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:37:43.202025Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement translates to \"The United States condemns Israeli calm after a fatality in Gaza.\" This type of statement is consistent with geopolitical events and reporting.  \\n\\n* **Content Verification:** While I cannot independently verify the specific incident, statements condemning violence and calling for peace are common from the US government in such situations.\\n* **Logical Consistency:** The statement is logically sound. It expresses a position (condemnation) in response to an event (a fatality). \\n\\n\\nTherefore, based on these factors, the text appears to be a plausible and potentially real news headline.'}, 'done_reason': 'stop', 'done': True, 'total_duration': 8576625125, 'load_duration': 20922792, 'prompt_eval_count': 161, 'prompt_eval_duration': 363052000, 'eval_count': 122, 'eval_duration': 8190253000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:37:43.817496Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 606041083, 'load_duration': 20715500, 'prompt_eval_count': 156, 'prompt_eval_duration': 394270000, 'eval_count': 4, 'eval_duration': 188140000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:37:54.67996Z', 'message': {'role': 'assistant', 'content': \"It's impossible for me to definitively determine the authenticity of that statement. I am a text-based AI and lack access to real-time information or the ability to verify news sources.  \\n\\nTo assess the statement's authenticity, you would need to:\\n\\n* **Consult reputable news sources:** Check if major Jordanian or international news outlets are reporting on this event.\\n* **Look for official statements:** See if the Jordanian government or security forces have issued any press releases confirming the incident. \\n* **Consider the source:**  If the statement came from a social media post or an unknown website, be extra cautious as these sources can be unreliable.\\n\\n\\nLet me know if you have any other text-based tasks I can help with! \\n\"}, 'done_reason': 'stop', 'done': True, 'total_duration': 10854721583, 'load_duration': 20326417, 'prompt_eval_count': 166, 'prompt_eval_duration': 379086000, 'eval_count': 154, 'eval_duration': 10453032000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:38:01.408712Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement translates to \"Sadr Coalition wins parliamentary elections in Iraq.\"  This type of statement is inherently verifiable. News sources would report on election results, and official bodies would release data confirming the winner.  \\n\\nTherefore, without delving into specific details about the Iraqi election in question, we can assume that the statement\\'s authenticity can be determined through fact-checking against reliable news sources and official election records. \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 6722956583, 'load_duration': 20874458, 'prompt_eval_count': 157, 'prompt_eval_duration': 432624000, 'eval_count': 93, 'eval_duration': 6266823000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:38:10.245054Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe text \"إيران تحدد قائمة شروطها للالتزام بالاتفاق النووي\" translates to \"Iran sets a list of conditions for its commitment to the nuclear agreement.\" This is a plausible statement reflecting ongoing geopolitical discussions.  \\n\\n* **Content Verification:** News sources frequently report on negotiations and demands related to the Iran nuclear deal. \\n* **Logical Consistency:** The statement aligns with the complex nature of international agreements, where parties often have specific conditions they seek to meet.\\n\\n\\nTherefore, based on these factors, the text appears to be a real statement.'}, 'done_reason': 'stop', 'done': True, 'total_duration': 8826706125, 'load_duration': 21016958, 'prompt_eval_count': 159, 'prompt_eval_duration': 429376000, 'eval_count': 124, 'eval_duration': 8373678000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:38:10.873532Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 620507125, 'load_duration': 19818292, 'prompt_eval_count': 157, 'prompt_eval_duration': 408001000, 'eval_count': 4, 'eval_duration': 190511000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:38:11.478497Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 597013667, 'load_duration': 20039792, 'prompt_eval_count': 150, 'prompt_eval_duration': 386796000, 'eval_count': 4, 'eval_duration': 187695000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:38:26.361226Z', 'message': {'role': 'assistant', 'content': \"It's impossible for me to definitively determine the authenticity of that statement without access to external information and fact-checking resources.  \\n\\nHere's why:\\n\\n* **Language Barrier:** The text is in Arabic, which I don't understand. To analyze its content and logical consistency, I need a translation.\\n* **Context is Crucial:** Even with a translation, understanding the context surrounding this statement is vital. Who said it? When? What was the situation? This information helps assess credibility.\\n\\n**To get an accurate answer, you would need to:**\\n\\n1. **Translate the text:** Get a reliable translation of the Arabic statement into English (or your preferred language).\\n2. **Research the source:** Find out who made this statement and what their reputation is for accuracy.\\n3. **Cross-reference information:** See if other credible news sources are reporting on a similar event or statement. \\n\\n\\nLet me know if you have an English translation of the text, and I can help you analyze it further! \\n\"}, 'done_reason': 'stop', 'done': True, 'total_duration': 14877190458, 'load_duration': 20115041, 'prompt_eval_count': 160, 'prompt_eval_duration': 374110000, 'eval_count': 212, 'eval_duration': 14480030000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:38:31.927886Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe text translates to \"A powerful earthquake shakes the Iran-Iraq border\" in Arabic.  This type of statement is plausible and frequently reported. To confirm its authenticity, one would need to cross-reference it with news sources or seismic activity reports. However, based on the content alone, it appears to be a potentially real statement. \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 5559862583, 'load_duration': 20516791, 'prompt_eval_count': 156, 'prompt_eval_duration': 416276000, 'eval_count': 77, 'eval_duration': 5119571000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:38:32.603292Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 669269125, 'load_duration': 20311875, 'prompt_eval_count': 164, 'prompt_eval_duration': 446281000, 'eval_count': 4, 'eval_duration': 200001000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:38:33.231123Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 619029875, 'load_duration': 20641083, 'prompt_eval_count': 164, 'prompt_eval_duration': 407062000, 'eval_count': 4, 'eval_duration': 189048000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:38:33.825737Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 586554583, 'load_duration': 20983000, 'prompt_eval_count': 160, 'prompt_eval_duration': 378499000, 'eval_count': 4, 'eval_duration': 184195000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:38:34.396746Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 561087958, 'load_duration': 21060791, 'prompt_eval_count': 161, 'prompt_eval_duration': 357829000, 'eval_count': 4, 'eval_duration': 179663000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:38:34.937231Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 535204250, 'load_duration': 20422833, 'prompt_eval_count': 156, 'prompt_eval_duration': 336962000, 'eval_count': 4, 'eval_duration': 175240000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:38:35.457754Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 514810625, 'load_duration': 20209750, 'prompt_eval_count': 157, 'prompt_eval_duration': 321496000, 'eval_count': 4, 'eval_duration': 170697000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:38:35.971075Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 507945250, 'load_duration': 20663792, 'prompt_eval_count': 151, 'prompt_eval_duration': 312301000, 'eval_count': 4, 'eval_duration': 172526000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:38:36.485935Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 511578875, 'load_duration': 20754791, 'prompt_eval_count': 164, 'prompt_eval_duration': 317238000, 'eval_count': 4, 'eval_duration': 171182000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:38:49.352353Z', 'message': {'role': 'assistant', 'content': \"It's impossible for me to definitively determine the authenticity of that statement.  Here's why:\\n\\n* **I lack real-time information access:** I am a language model and cannot browse the internet or access news sources to verify the claim. \\n* **Translation and Context:** While the text appears to be Arabic, I need context to understand its full meaning and implications. A direct translation might not capture all the nuances.\\n\\n**To determine if the statement is real or fake, you would need to:**\\n\\n1. **Translate the text accurately.**\\n2. **Consult reliable news sources:** Look for reports from reputable organizations about military activity in the Sinai region.\\n3. **Cross-reference information:** Compare details from different sources to see if they align. \\n\\n\\nLet me know if you have any other questions that don't require real-time information access!\"}, 'done_reason': 'stop', 'done': True, 'total_duration': 12863000000, 'load_duration': 20339417, 'prompt_eval_count': 161, 'prompt_eval_duration': 319427000, 'eval_count': 180, 'eval_duration': 12518356000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:38:49.998895Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 637930791, 'load_duration': 21026666, 'prompt_eval_count': 159, 'prompt_eval_duration': 421285000, 'eval_count': 4, 'eval_duration': 193175000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:38:50.604066Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 595027167, 'load_duration': 19792667, 'prompt_eval_count': 150, 'prompt_eval_duration': 385778000, 'eval_count': 4, 'eval_duration': 186932000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:38:51.192202Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 581421542, 'load_duration': 20692375, 'prompt_eval_count': 164, 'prompt_eval_duration': 377322000, 'eval_count': 4, 'eval_duration': 180806000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:38:51.754351Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 557979083, 'load_duration': 20507916, 'prompt_eval_count': 162, 'prompt_eval_duration': 356752000, 'eval_count': 4, 'eval_duration': 178105000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:38:52.308671Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 548160625, 'load_duration': 20361666, 'prompt_eval_count': 165, 'prompt_eval_duration': 347518000, 'eval_count': 4, 'eval_duration': 177906000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:38:57.660543Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement \"كوكاكولا تشتري سلسلة مقاهي كوستا\" translates to \"Coca-Cola buys the Costa coffee chain\". This event actually happened in 2019.  Therefore, the statement is real. \\n\\n\\nLet me know if you\\'d like me to analyze another statement!'}, 'done_reason': 'stop', 'done': True, 'total_duration': 5343801291, 'load_duration': 20149666, 'prompt_eval_count': 157, 'prompt_eval_duration': 333666000, 'eval_count': 73, 'eval_duration': 4987118000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:38:58.372956Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 702144125, 'load_duration': 20735250, 'prompt_eval_count': 162, 'prompt_eval_duration': 473980000, 'eval_count': 4, 'eval_duration': 205055000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:38:58.993185Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 613649000, 'load_duration': 20103125, 'prompt_eval_count': 166, 'prompt_eval_duration': 404071000, 'eval_count': 4, 'eval_duration': 187603000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:38:59.568197Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 571301250, 'load_duration': 20056958, 'prompt_eval_count': 156, 'prompt_eval_duration': 367274000, 'eval_count': 4, 'eval_duration': 181954000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:39:10.041256Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe text \"ألمانيا تحذر من سياسات ترامب على اقتصاد العالم\" translates to \"Germany warns of Trump\\'s policies on the world economy.\"  This type of statement is plausible and aligns with real-world political discourse. \\n\\n* **Content Verification:** While I cannot verify specific sources, it is common for countries to express concerns about the economic impact of another country\\'s policies.\\n* **Logical Consistency:** The statement is logically consistent. It expresses a concern (Germany\\'s warning) about a specific issue (Trump\\'s policies) and their potential effect (on the world economy). \\n\\n\\nTherefore, based on these factors, the text appears to be a realistic statement.'}, 'done_reason': 'stop', 'done': True, 'total_duration': 10467234667, 'load_duration': 19868708, 'prompt_eval_count': 154, 'prompt_eval_duration': 341223000, 'eval_count': 148, 'eval_duration': 10103324000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:39:10.733074Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 683691208, 'load_duration': 20652708, 'prompt_eval_count': 162, 'prompt_eval_duration': 453223000, 'eval_count': 4, 'eval_duration': 207316000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:39:11.378765Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 638810375, 'load_duration': 20463916, 'prompt_eval_count': 162, 'prompt_eval_duration': 423526000, 'eval_count': 4, 'eval_duration': 192634000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:39:11.990875Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 600573458, 'load_duration': 21329458, 'prompt_eval_count': 158, 'prompt_eval_duration': 389800000, 'eval_count': 4, 'eval_duration': 186637000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:39:12.574703Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 573957459, 'load_duration': 20539917, 'prompt_eval_count': 162, 'prompt_eval_duration': 369241000, 'eval_count': 4, 'eval_duration': 181949000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:39:13.125022Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 545719750, 'load_duration': 19548584, 'prompt_eval_count': 154, 'prompt_eval_duration': 345119000, 'eval_count': 4, 'eval_duration': 178485000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:39:13.66451Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 532415458, 'load_duration': 20264292, 'prompt_eval_count': 163, 'prompt_eval_duration': 333996000, 'eval_count': 4, 'eval_duration': 175549000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:39:22.787392Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement translates to \"Protests continue in Jordan despite the resignation of Prime Minister Hani Mulki.\" This type of news event is plausible and verifiable.  \\n\\n* **Content Verification:** News sources often report on political protests and resignations. A quick search would likely confirm if protests are indeed ongoing in Jordan and if there was a recent prime ministerial resignation.\\n* **Logical Consistency:** The statement is logically consistent. Protests can continue even after a leader resigns, especially if the underlying grievances remain unaddressed. \\n\\n\\nLet me know if you\\'d like me to analyze another statement!'}, 'done_reason': 'stop', 'done': True, 'total_duration': 9115138167, 'load_duration': 20777875, 'prompt_eval_count': 165, 'prompt_eval_duration': 325702000, 'eval_count': 128, 'eval_duration': 8765963000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:39:23.428512Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 631764208, 'load_duration': 20416792, 'prompt_eval_count': 154, 'prompt_eval_duration': 413275000, 'eval_count': 4, 'eval_duration': 195781000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:39:24.059562Z', 'message': {'role': 'assistant', 'content': '0 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 625975625, 'load_duration': 20102916, 'prompt_eval_count': 165, 'prompt_eval_duration': 411435000, 'eval_count': 4, 'eval_duration': 191542000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:39:30.181581Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe text appears to be a credible news headline in Arabic. It translates to \"BBC refuses to discuss with Egyptian authorities after complaints about a documentary on human rights.\"  This type of statement aligns with real-world events and potential tensions between media organizations and governments regarding sensitive topics like human rights. \\n\\n\\nLet me know if you\\'d like me to analyze another statement!'}, 'done_reason': 'stop', 'done': True, 'total_duration': 6115460375, 'load_duration': 20446625, 'prompt_eval_count': 167, 'prompt_eval_duration': 644252000, 'eval_count': 82, 'eval_duration': 5448469000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:39:30.882616Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 691956708, 'load_duration': 20639875, 'prompt_eval_count': 156, 'prompt_eval_duration': 461694000, 'eval_count': 4, 'eval_duration': 207221000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:39:44.301063Z', 'message': {'role': 'assistant', 'content': 'It\\'s impossible to definitively determine the authenticity of the statement \"جنازة صغيرة للممثلة السورية مي سكاف بفرنسا\" (A small funeral for the Syrian actress Mai Skaf in France) without further investigation. \\n\\nHere\\'s why:\\n\\n* **Language Barrier:** While I can process the text, I don\\'t have access to real-time information or the ability to verify news sources in Arabic.\\n* **Need for Context:**  The statement lacks context. To assess its authenticity, I would need to know:\\n    * When was this funeral supposed to have taken place?\\n    * Are there any reputable news sources reporting on Mai Skaf\\'s passing?\\n\\n**Therefore, I cannot provide a definitive 0 (real) or 1 (fake) answer.**  You would need to consult reliable Arabic-language news sources or fact-checking websites to verify this information. \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 13413144041, 'load_duration': 20446791, 'prompt_eval_count': 157, 'prompt_eval_duration': 409529000, 'eval_count': 189, 'eval_duration': 12980404000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:39:53.588147Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement translates to \"Israel allowed the passage of fuel to Gaza.\" This type of event is not uncommon and has happened in the past.  \\n\\n* **Content Verification:** News sources frequently report on developments regarding the movement of goods into Gaza, including fuel. A quick search would likely reveal reports confirming or denying this specific instance.\\n* **Logical Consistency:** The statement itself is logically consistent. There\\'s no inherent contradiction in Israel allowing fuel to pass into Gaza. \\n\\n\\nTherefore, based on the likelihood of such events occurring and the lack of immediate logical inconsistencies, the statement appears potentially real.  \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 9282553292, 'load_duration': 20113959, 'prompt_eval_count': 156, 'prompt_eval_duration': 426728000, 'eval_count': 130, 'eval_duration': 8833167000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:39:54.228068Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 630826917, 'load_duration': 20805250, 'prompt_eval_count': 155, 'prompt_eval_duration': 414033000, 'eval_count': 4, 'eval_duration': 193679000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:39:54.829352Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 597516792, 'load_duration': 20707334, 'prompt_eval_count': 166, 'prompt_eval_duration': 386510000, 'eval_count': 4, 'eval_duration': 188058000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:39:55.662173Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 826698583, 'load_duration': 21556500, 'prompt_eval_count': 168, 'prompt_eval_duration': 617273000, 'eval_count': 4, 'eval_duration': 184376000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:39:56.236603Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 570620792, 'load_duration': 19383459, 'prompt_eval_count': 157, 'prompt_eval_duration': 366850000, 'eval_count': 4, 'eval_duration': 182146000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:40:03.997963Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement translates to \"Avengers: Infinity War breaks box office records.\" This is a plausible claim and was indeed true when the movie was released.  \\n\\n* **Content Verification:** The claim can be verified through numerous sources like news articles, box office reports, and film industry websites.\\n* **Logical Consistency:** The statement is logically consistent. A popular superhero movie breaking box office records is a common occurrence. \\n\\n\\nLet me know if you\\'d like to test another statement!'}, 'done_reason': 'stop', 'done': True, 'total_duration': 7753483500, 'load_duration': 20202584, 'prompt_eval_count': 167, 'prompt_eval_duration': 571296000, 'eval_count': 105, 'eval_duration': 7159460000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:40:04.610668Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 605314541, 'load_duration': 20554416, 'prompt_eval_count': 153, 'prompt_eval_duration': 394469000, 'eval_count': 4, 'eval_duration': 187810000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:40:05.209651Z', 'message': {'role': 'assistant', 'content': '0 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 588030042, 'load_duration': 21808000, 'prompt_eval_count': 155, 'prompt_eval_duration': 378809000, 'eval_count': 4, 'eval_duration': 184587000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:40:05.788485Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 568514916, 'load_duration': 20510791, 'prompt_eval_count': 159, 'prompt_eval_duration': 364683000, 'eval_count': 4, 'eval_duration': 181124000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:40:13.131883Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe text translates to \"Gary Oldman wins Best Actor and Cate Blanchett Best Actress at the Cannes Film Festival awards.\" This statement is plausible and aligns with real-world events.  Both actors are highly acclaimed, and the Cannes Film Festival is a prestigious event known for recognizing cinematic excellence. \\n\\n\\nWhile I cannot independently verify the specific year this award was given, the content itself is logically consistent and reflects typical information shared about film festivals. \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 7336347250, 'load_duration': 20346792, 'prompt_eval_count': 171, 'prompt_eval_duration': 572072000, 'eval_count': 98, 'eval_duration': 6741897000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:40:14.026138Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 887443042, 'load_duration': 20321792, 'prompt_eval_count': 167, 'prompt_eval_duration': 675293000, 'eval_count': 4, 'eval_duration': 189508000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:40:14.621049Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 589082291, 'load_duration': 19833208, 'prompt_eval_count': 154, 'prompt_eval_duration': 381835000, 'eval_count': 4, 'eval_duration': 185003000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:40:20.010693Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe text translates to \"Sisi took the constitutional oath as president for a second term.\" This statement is factually accurate. Abdel Fattah el-Sisi was re-elected as President of Egypt in 2018 for a second term.  \\n\\n\\nLet me know if you\\'d like me to analyze another statement!'}, 'done_reason': 'stop', 'done': True, 'total_duration': 5377428958, 'load_duration': 21163833, 'prompt_eval_count': 165, 'prompt_eval_duration': 365540000, 'eval_count': 75, 'eval_duration': 4988397000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:40:29.769644Z', 'message': {'role': 'assistant', 'content': '0 \\n\\n**Explanation:**\\n\\nThe statement \"مصر ترحب بعودة السوداني الصادق المهدي\" translates to \"Egypt welcomes the return of Sudanese Sadiq al-Mahdi.\"  \\n\\n* **Content Verification:** This statement aligns with known political events. Sadiq al-Mahdi is a prominent Sudanese politician who has been in exile. Egypt has historically had close ties with Sudan. \\n* **Logical Consistency:** The statement is logically consistent. It expresses a welcoming sentiment from one country towards the return of a political figure from another.\\n\\n\\nTherefore, based on content verification and logical consistency, the statement appears to be real. \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 9749259167, 'load_duration': 21153625, 'prompt_eval_count': 157, 'prompt_eval_duration': 506461000, 'eval_count': 135, 'eval_duration': 9219231000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:40:30.411565Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 635309500, 'load_duration': 20213083, 'prompt_eval_count': 154, 'prompt_eval_duration': 417404000, 'eval_count': 4, 'eval_duration': 195683000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:40:31.026615Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 611210166, 'load_duration': 20297583, 'prompt_eval_count': 163, 'prompt_eval_duration': 400468000, 'eval_count': 4, 'eval_duration': 188438000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:40:31.616031Z', 'message': {'role': 'assistant', 'content': '0 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 585146417, 'load_duration': 19751833, 'prompt_eval_count': 153, 'prompt_eval_duration': 378293000, 'eval_count': 4, 'eval_duration': 185128000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:40:32.423192Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 799780208, 'load_duration': 20457750, 'prompt_eval_count': 170, 'prompt_eval_duration': 594634000, 'eval_count': 4, 'eval_duration': 182553000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:40:32.984701Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 558152166, 'load_duration': 19595458, 'prompt_eval_count': 158, 'prompt_eval_duration': 355973000, 'eval_count': 4, 'eval_duration': 180682000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:40:33.533344Z', 'message': {'role': 'assistant', 'content': '0 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 540547583, 'load_duration': 19965125, 'prompt_eval_count': 156, 'prompt_eval_duration': 341946000, 'eval_count': 4, 'eval_duration': 176669000}\n",
      "0\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:40:34.074149Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 534139417, 'load_duration': 20902917, 'prompt_eval_count': 162, 'prompt_eval_duration': 336403000, 'eval_count': 4, 'eval_duration': 174867000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:40:34.613659Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 532351708, 'load_duration': 20576458, 'prompt_eval_count': 162, 'prompt_eval_duration': 333235000, 'eval_count': 4, 'eval_duration': 176252000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:40:35.14714Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 526956250, 'load_duration': 20580625, 'prompt_eval_count': 153, 'prompt_eval_duration': 328267000, 'eval_count': 4, 'eval_duration': 175836000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:40:53.013999Z', 'message': {'role': 'assistant', 'content': 'It\\'s impossible to definitively determine the authenticity of the Arabic text \"المبعوث الدولي يرفض التدخل بين تل أبيب وحماس\"  (The international envoy refuses to intervene between Tel Aviv and Hamas) without further context and analysis. \\n\\nHere\\'s why:\\n\\n* **Translation Ambiguity:** While the translation seems plausible, nuances in Arabic could alter the meaning significantly.\\n* **Source Unknown:** We don\\'t know where this text originated. Is it from a reputable news source, social media, or an unknown website? The source heavily influences credibility.\\n* **Political Sensitivity:**  The topic involves a complex geopolitical situation. Claims about international envoys and negotiations require careful verification.\\n\\n**Therefore, I cannot provide a definitive 0 (real) or 1 (fake).** To make an accurate assessment, you would need to:\\n\\n1. **Identify the source of the text.**\\n2. **Cross-reference the information with reliable news sources in Arabic and other languages.**\\n3. **Consider the political context and potential biases involved.** \\n\\n\\nLet me know if you have more information about the source, and I might be able to provide a more helpful analysis. \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 17863334541, 'load_duration': 19525916, 'prompt_eval_count': 158, 'prompt_eval_duration': 332379000, 'eval_count': 247, 'eval_duration': 17509134000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:40:53.684349Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 664263291, 'load_duration': 20361666, 'prompt_eval_count': 161, 'prompt_eval_duration': 440933000, 'eval_count': 4, 'eval_duration': 200827000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:40:54.308191Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 613964125, 'load_duration': 20851250, 'prompt_eval_count': 156, 'prompt_eval_duration': 401463000, 'eval_count': 4, 'eval_duration': 189127000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:40:54.900585Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 587996042, 'load_duration': 20171833, 'prompt_eval_count': 155, 'prompt_eval_duration': 380262000, 'eval_count': 4, 'eval_duration': 184893000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:40:55.471727Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 565187667, 'load_duration': 20668459, 'prompt_eval_count': 155, 'prompt_eval_duration': 361408000, 'eval_count': 4, 'eval_duration': 180756000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:40:56.023496Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 545466375, 'load_duration': 20032000, 'prompt_eval_count': 156, 'prompt_eval_duration': 344594000, 'eval_count': 4, 'eval_duration': 178227000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:40:56.561366Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 530217000, 'load_duration': 21165875, 'prompt_eval_count': 160, 'prompt_eval_duration': 332773000, 'eval_count': 4, 'eval_duration': 174082000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:40:57.082262Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 516999292, 'load_duration': 20173833, 'prompt_eval_count': 156, 'prompt_eval_duration': 322745000, 'eval_count': 4, 'eval_duration': 171735000}\n",
      "1\n",
      "{'model': 'gemma2:27b', 'created_at': '2024-07-28T20:40:57.606273Z', 'message': {'role': 'assistant', 'content': '1 \\n'}, 'done_reason': 'stop', 'done': True, 'total_duration': 518016000, 'load_duration': 20266375, 'prompt_eval_count': 165, 'prompt_eval_duration': 323398000, 'eval_count': 4, 'eval_duration': 172132000}\n",
      "1\n",
      "Accuracy: 0.43956043956043955\n",
      "Precision: 0.34226190476190477\n",
      "Recall: 0.7718120805369127\n",
      "F1 Score: 0.4742268041237113\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "accuracy, precision, recall, f1, predicted_ans_zs_cot = calculate_metrics(df_ans_zs_cot, params)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UqFTHoAut2C3",
    "outputId": "4bf1c3da-d0d2-4d47-c861-79f3dbc86087"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_ans_zs_cot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "VPaLYD-Ut7GQ"
   },
   "outputs": [],
   "source": [
    "predicted_ans_zs_cot = [1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BZjxOsyVwxJS"
   },
   "source": [
    "### Few Shots Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "YiR6OWMNxYwh"
   },
   "outputs": [],
   "source": [
    "df_ans_fs = pd.read_csv('./datasets/ANS/train.csv')\n",
    "\n",
    "# Initialize a list to store the prompts\n",
    "prompts = []\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in df_ans_fs.iterrows():\n",
    "    sentence = row['claim_s']\n",
    "    fake_flag = row['fake_flag']\n",
    "\n",
    "    # Generate prompt based on each row\n",
    "    prompt = f\"\"\"Text: {sentence}\n",
    "\n",
    "Answer: {fake_flag}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    # Append the prompt along with sentence and fake flag to the list\n",
    "    prompts.append((sentence, fake_flag, prompt))\n",
    "\n",
    "# Convert the list of prompts into a new DataFrame\n",
    "prompts_df_ans_fs = pd.DataFrame(prompts, columns=['Sentence', 'Fake Flag', 'Prompt'])\n",
    "\n",
    "# Save the prompts DataFrame to a new CSV file\n",
    "prompts_df_ans_fs.to_csv('prompts_df_ans_fs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "nGo7yppizZEO",
    "outputId": "43ce1fc8-0f16-4693-ffe9-dcf29a06062f"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Fake Flag</th>\n",
       "      <th>Prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>تراجع التضخم النصف سنوي في الجزائر</td>\n",
       "      <td>1</td>\n",
       "      <td>Text: تراجع التضخم النصف سنوي في الجزائر\\n\\nAn...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>صكوك من الكويت بملياري دولار</td>\n",
       "      <td>1</td>\n",
       "      <td>Text: صكوك من الكويت بملياري دولار\\n\\nAnswer: ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>الحرب في سوريا: قافلة الإغاثة المرتقبة لن تتمك...</td>\n",
       "      <td>0</td>\n",
       "      <td>Text: الحرب في سوريا: قافلة الإغاثة المرتقبة ل...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>الأساطير المحيطة بالممثلين المجوس في مصر تتحطم...</td>\n",
       "      <td>1</td>\n",
       "      <td>Text: الأساطير المحيطة بالممثلين المجوس في مصر...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>مصر: مجلس النواب يقر حصانة قضائية لضباط كبار ب...</td>\n",
       "      <td>0</td>\n",
       "      <td>Text: مصر: مجلس النواب يقر حصانة قضائية لضباط ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3180</th>\n",
       "      <td>رسّامة جزائرية: لا أرسم خيالا، بل حقيقة</td>\n",
       "      <td>0</td>\n",
       "      <td>Text: رسّامة جزائرية: لا أرسم خيالا، بل حقيقة\\...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3181</th>\n",
       "      <td>مصر.. ارتفاع قياسي جديد للاحتياطي الأجنبي</td>\n",
       "      <td>0</td>\n",
       "      <td>Text: مصر.. ارتفاع قياسي جديد للاحتياطي الأجنب...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3182</th>\n",
       "      <td>السعودية تُسارع بشراء  إيرباص</td>\n",
       "      <td>1</td>\n",
       "      <td>Text: السعودية تُسارع بشراء  إيرباص\\n\\nAnswer:...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3183</th>\n",
       "      <td>الأسهم الخليجية ترتفع</td>\n",
       "      <td>0</td>\n",
       "      <td>Text: الأسهم الخليجية ترتفع\\n\\nAnswer: 0\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3184</th>\n",
       "      <td>السغودية: بدء تشغيل قطار الحرمين</td>\n",
       "      <td>0</td>\n",
       "      <td>Text: السغودية: بدء تشغيل قطار الحرمين\\n\\nAnsw...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3185 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence  Fake Flag  \\\n",
       "0                    تراجع التضخم النصف سنوي في الجزائر          1   \n",
       "1                          صكوك من الكويت بملياري دولار          1   \n",
       "2     الحرب في سوريا: قافلة الإغاثة المرتقبة لن تتمك...          0   \n",
       "3     الأساطير المحيطة بالممثلين المجوس في مصر تتحطم...          1   \n",
       "4     مصر: مجلس النواب يقر حصانة قضائية لضباط كبار ب...          0   \n",
       "...                                                 ...        ...   \n",
       "3180            رسّامة جزائرية: لا أرسم خيالا، بل حقيقة          0   \n",
       "3181          مصر.. ارتفاع قياسي جديد للاحتياطي الأجنبي          0   \n",
       "3182                      السعودية تُسارع بشراء  إيرباص          1   \n",
       "3183                              الأسهم الخليجية ترتفع          0   \n",
       "3184                   السغودية: بدء تشغيل قطار الحرمين          0   \n",
       "\n",
       "                                                 Prompt  \n",
       "0     Text: تراجع التضخم النصف سنوي في الجزائر\\n\\nAn...  \n",
       "1     Text: صكوك من الكويت بملياري دولار\\n\\nAnswer: ...  \n",
       "2     Text: الحرب في سوريا: قافلة الإغاثة المرتقبة ل...  \n",
       "3     Text: الأساطير المحيطة بالممثلين المجوس في مصر...  \n",
       "4     Text: مصر: مجلس النواب يقر حصانة قضائية لضباط ...  \n",
       "...                                                 ...  \n",
       "3180  Text: رسّامة جزائرية: لا أرسم خيالا، بل حقيقة\\...  \n",
       "3181  Text: مصر.. ارتفاع قياسي جديد للاحتياطي الأجنب...  \n",
       "3182  Text: السعودية تُسارع بشراء  إيرباص\\n\\nAnswer:...  \n",
       "3183       Text: الأسهم الخليجية ترتفع\\n\\nAnswer: 0\\n\\n  \n",
       "3184  Text: السغودية: بدء تشغيل قطار الحرمين\\n\\nAnsw...  \n",
       "\n",
       "[3185 rows x 3 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts_df_ans_fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WCD8_L291Pdb"
   },
   "source": [
    "#### 8 Shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RmtfzEBV3Waw",
    "outputId": "24c98d14-32e3-4cc4-ff6c-454c222dc190"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: تراجع التضخم النصف سنوي في الجزائر\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: صكوك من الكويت بملياري دولار\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: الحرب في سوريا: قافلة الإغاثة المرتقبة لن تتمكن من دخول الغوطة الشرقية\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: الأساطير المحيطة بالممثلين المجوس في مصر تتحطم على يد المؤرخ السينمائي أشرف غريب\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: مصر: مجلس النواب يقر حصانة قضائية لضباط كبار بالجيش بعد عزل مرسي\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: بتكوين تخسر مجدداً\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: الليرة التركية تنحدر مجدداً\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: هل استطاع الموساد اختراق أسرار إيران النووية؟\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shots_8 = '\\n'.join(prompts_df_ans_fs.iloc[:8, 2].astype(str))\n",
    "print(shots_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "3x1F6158xD3b"
   },
   "outputs": [],
   "source": [
    "# Define function to calculate metrics\n",
    "def calculate_metrics(test_set, params):\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    passed = 0\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in test_set.iterrows():\n",
    "        sentence = row[\"claim_s\"]\n",
    "        actual_label = row[\"fake_flag\"]\n",
    "\n",
    "        # Generate prompt based on each row\n",
    "        prompt = f\"\"\"Determine whether the following text is real or fake. if real then output = 0 and if fake then output = 1. Output must be integer 0 or 1 alone. No text.\n",
    "\n",
    "{shots_8}\n",
    "\n",
    "Text: {sentence}\n",
    "\n",
    "Answer:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "        # Call the get_completion function with prompt and params\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        response = get_completion(params, messages)\n",
    "        content = response.get(\"message\").get(\"content\")\n",
    "        predicted_label = get_prediction(content)\n",
    "        none_count = 0\n",
    "        \n",
    "        if predicted_label is not None:\n",
    "            true_labels.append(actual_label)\n",
    "            predicted_labels.append(predicted_label)\n",
    "        else:\n",
    "            none_count += 1 \n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels)\n",
    "    recall = recall_score(true_labels, predicted_labels)\n",
    "    f1 = f1_score(true_labels, predicted_labels)\n",
    "\n",
    "    return accuracy, precision, recall, f1, predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ljiQndG806MK",
    "outputId": "28cc46e3-a763-4b38-905f-37cce9111a83"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6118421052631579\n",
      "Precision: 0.4435146443514644\n",
      "Recall: 0.7066666666666667\n",
      "F1 Score: 0.5449871465295629\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "accuracy, precision, recall, f1, predicted_ans_fs_8 = calculate_metrics(df_ans_zs, params)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_ans_fs_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ans_fs_8 = [0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LOSyELDH1eVT"
   },
   "source": [
    "#### 16 Shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9phvaGGU2ASB",
    "outputId": "5c2e317f-1c76-4da7-dc1c-588d4e5efdb6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: تراجع التضخم النصف سنوي في الجزائر\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: صكوك من الكويت بملياري دولار\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: الحرب في سوريا: قافلة الإغاثة المرتقبة لن تتمكن من دخول الغوطة الشرقية\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: الأساطير المحيطة بالممثلين المجوس في مصر تتحطم على يد المؤرخ السينمائي أشرف غريب\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: مصر: مجلس النواب يقر حصانة قضائية لضباط كبار بالجيش بعد عزل مرسي\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: بتكوين تخسر مجدداً\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: الليرة التركية تنحدر مجدداً\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: هل استطاع الموساد اختراق أسرار إيران النووية؟\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: أسواق إيران توقف إضرابها\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: مفتشو منظمة حظر الأسلحة الكيمياوية في دوما السورية\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: انفجار في مصنع للكيماويات قرب مطار القاهرة بالعاصمة المصرية\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: الوكالة الكورية للغاز توقع مذكرة تفاهم مع شركة إماراتية\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: أوسكار تضيف جائزة جديدة لأفضل فيلم جماهيري\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: أسواق النفط تتفادى المونديال\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: محطة تلفزيون تتهم مسؤولا يابانيا كبيرا بالتحرش بإحدى صحفياتها\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: افتتاح مهرجان لندن السينمائي من قبل بناتستيف ماكوين\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shots_16 = '\\n'.join(prompts_df_ans_fs.iloc[:16, 2].astype(str))\n",
    "print(shots_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "y9djJ5gd1dhr"
   },
   "outputs": [],
   "source": [
    "# Define function to calculate metrics\n",
    "def calculate_metrics(test_set, params):\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    passed = 0\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in test_set.iterrows():\n",
    "        sentence = row[\"claim_s\"]\n",
    "        actual_label = row[\"fake_flag\"]\n",
    "\n",
    "        # Generate prompt based on each row\n",
    "        prompt = f\"\"\"Determine whether the following text is real or fake. if real then output = 0 and if fake then output = 1. Output must be integer 0 or 1 alone. No text.\n",
    "\n",
    "{shots_16}\n",
    "\n",
    "Text: {sentence}\n",
    "\n",
    "Answer:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "        # Call the get_completion function with prompt and params\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        response = get_completion(params, messages)\n",
    "        content = response.get(\"message\").get(\"content\")\n",
    "        predicted_label = get_prediction(content)\n",
    "        none_count = 0\n",
    "        \n",
    "        if predicted_label is not None:\n",
    "            true_labels.append(actual_label)\n",
    "            predicted_labels.append(predicted_label)\n",
    "        else:\n",
    "            none_count += 1 \n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels)\n",
    "    recall = recall_score(true_labels, predicted_labels)\n",
    "    f1 = f1_score(true_labels, predicted_labels)\n",
    "\n",
    "    return accuracy, precision, recall, f1, predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0YuXN7Lg1lvD",
    "outputId": "aac18190-93da-4de7-f891-213de6fcb09b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6798245614035088\n",
      "Precision: 0.5196078431372549\n",
      "Recall: 0.35333333333333333\n",
      "F1 Score: 0.42063492063492064\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "accuracy, precision, recall, f1, predicted_ans_fs_16 = calculate_metrics(df_ans_zs, params)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_ans_fs_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ans_fs_16 = [0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uGppidLd1n_b"
   },
   "source": [
    "#### 32 Shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SC6kE4Ma1niR",
    "outputId": "14efaeb8-bef3-4dc3-9a08-f43d82842202"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: تراجع التضخم النصف سنوي في الجزائر\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: صكوك من الكويت بملياري دولار\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: الحرب في سوريا: قافلة الإغاثة المرتقبة لن تتمكن من دخول الغوطة الشرقية\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: الأساطير المحيطة بالممثلين المجوس في مصر تتحطم على يد المؤرخ السينمائي أشرف غريب\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: مصر: مجلس النواب يقر حصانة قضائية لضباط كبار بالجيش بعد عزل مرسي\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: بتكوين تخسر مجدداً\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: الليرة التركية تنحدر مجدداً\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: هل استطاع الموساد اختراق أسرار إيران النووية؟\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: أسواق إيران توقف إضرابها\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: مفتشو منظمة حظر الأسلحة الكيمياوية في دوما السورية\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: انفجار في مصنع للكيماويات قرب مطار القاهرة بالعاصمة المصرية\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: الوكالة الكورية للغاز توقع مذكرة تفاهم مع شركة إماراتية\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: أوسكار تضيف جائزة جديدة لأفضل فيلم جماهيري\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: أسواق النفط تتفادى المونديال\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: محطة تلفزيون تتهم مسؤولا يابانيا كبيرا بالتحرش بإحدى صحفياتها\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: افتتاح مهرجان لندن السينمائي من قبل بناتستيف ماكوين\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: مكاسب في وول ستريت في الاسابيع الستة الاخيرة\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: السيطرة على عفرين الكردية عن طريق الحكومة السورية\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: بريطانيا تخرج من الاتحاد الجمركي الأوروبي\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: استهداف مطار في طرابلس بهجوم صاورخى و اجبار ليبيا على تغيير مسار الرحلات الجوية\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: تنديد فلسطيني بالإفراج عن جندي إسرائيلي قتل جريحا\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: اقتنصت المخابرات التركية مهاجم ريحانلى\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: صعود لليرة قبل محاكمة برونسون\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: إثر إضراب النقابات في الأردن.. الملك يأمر بتجميد زيادات أسعار الوقود\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: إيران تفرج عن مواطنة بعد اتهامها بخلع حجابها\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: ما سر اعتراف إسرائيل فى هذا الوقت بتدمير المفاعل النووي السوري؟\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: تظاهر الآلاف في المغرب تنديدا بسجن قادة الحراك الشعبي\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: زوجة نتنياهو متهم بالاحتيال وإهدار المال العام\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: جيرار ديبارديو الممثل الفرنسي الشهير يُتهم باغتصاب ممثلة شابة\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: 250 ألف جنيه إسترليني مقابل الصور الجديدة للبيتلز\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: فشل أزمة إيران في تحفيز المشتريات يؤدي إلى انخفاض الذهب\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: المسلسل الأمريكي الكوميديروزان يتوقف بعد تغريدة عن مساعدة أوباما\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shots_all = '\\n'.join(prompts_df_ans_fs.iloc[:32, 2].astype(str))\n",
    "print(shots_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "atU6KlR55o3r"
   },
   "outputs": [],
   "source": [
    "# Define function to calculate metrics\n",
    "def calculate_metrics(test_set, params):\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "    passed = 0\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in test_set.iterrows():\n",
    "        sentence = row[\"claim_s\"]\n",
    "        actual_label = row[\"fake_flag\"]\n",
    "\n",
    "        # Generate prompt based on each row\n",
    "        prompt = f\"\"\"Determine whether the following text is real or fake. if real then output = 0 and if fake then output = 1. Output must be integer 0 or 1 alone. No text.\n",
    "\n",
    "{shots_all}\n",
    "\n",
    "Text: {sentence}\n",
    "\n",
    "Answer:\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "        # Call the get_completion function with prompt and params\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        response = get_completion(params, messages)\n",
    "        content = response.get(\"message\").get(\"content\")\n",
    "        predicted_label = get_prediction(content)\n",
    "        none_count = 0\n",
    "        \n",
    "        if predicted_label is not None:\n",
    "            true_labels.append(actual_label)\n",
    "            predicted_labels.append(predicted_label)\n",
    "        else:\n",
    "            none_count += 1 \n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels)\n",
    "    recall = recall_score(true_labels, predicted_labels)\n",
    "    f1 = f1_score(true_labels, predicted_labels)\n",
    "\n",
    "    return accuracy, precision, recall, f1, predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qFhSgxW85tbV",
    "outputId": "8ac81d76-1d06-43b6-e951-7586ba8c78d8"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6710526315789473\n",
      "Precision: 0.5\n",
      "Recall: 0.5866666666666667\n",
      "F1 Score: 0.5398773006134969\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "accuracy, precision, recall, f1, predicted_ans_fs_32 = calculate_metrics(df_ans_zs, params)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_ans_fs_32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ans_fs_32 = [0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PSvzwiSgqjIQ"
   },
   "source": [
    "# Gemma2 (ArAiEval Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "8h6fPST3qjIb"
   },
   "outputs": [],
   "source": [
    "def set_llama_params(model=\"gemma2:27b\"):  # update model to your preference\n",
    "    \"\"\" set llama parameters\"\"\"\n",
    "    model_response = ollama.chat(\n",
    "        model=model,\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are a gemma assistant that talks like a gemma, starting every word with 'll'.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Hi, happy gemma day!\"},\n",
    "        ],\n",
    "        stream=False\n",
    "    )\n",
    "    return {\"model\": model_response.get(\"model\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "WWZUiGHFqjIb"
   },
   "outputs": [],
   "source": [
    "def get_completion(params, messages):\n",
    "    \"\"\" GET completion from llama model\"\"\"\n",
    "    response = None\n",
    "    payload = {\n",
    "        \"model\": params[\"model\"],\n",
    "        \"tools\": [\n",
    "            {\"functions\": [\n",
    "                {'name': 'fake_news_detection',\n",
    "                'description': 'Detect whether a given news is fake or not.',\n",
    "                'parameters': {\n",
    "                    'type': 'object',\n",
    "                    'properties': {\n",
    "                        'sentiment': {\n",
    "                            'title': 'sentiment',\n",
    "                            'type': 'string',\n",
    "                            'description': 'the sentiment encountered in the passage'\n",
    "                        },\n",
    "                        'is_fake': {\n",
    "                            'title': 'is fake',\n",
    "                            'type': 'integer',\n",
    "                            'description': 'Determine whether the text is real or fake. if real then output = 0 and if fake then output = 1. Output must be integer 0 or 1 alone.'\n",
    "                        },\n",
    "                        'language': {\n",
    "                            'title': 'language',\n",
    "                            'type': 'string',\n",
    "                            'description': 'the language of the passage'\n",
    "                        }\n",
    "                      },\n",
    "                      'required': ['sentiment', 'is_fake', 'language']\n",
    "                    },\n",
    "                    \"function_call\": {\"name\": \"fake_news_detection\"},\n",
    "                }\n",
    "            ],}\n",
    "        ],\n",
    "        \"stream\": False,\n",
    "        \"options\": {\n",
    "            \"max_tokens\": 1,\n",
    "            \"temperature\": 0.1,\n",
    "        },\n",
    "    }\n",
    "    payload[\"messages\"] = messages\n",
    "\n",
    "    model_response = ollama.chat(\n",
    "        model=payload[\"model\"],\n",
    "        messages=payload[\"messages\"],\n",
    "        #tools=payload[\"tools\"], # track this PR: https://github.com/ollama/ollama-python/pull/213\n",
    "        options=payload[\"options\"],\n",
    "        stream=False\n",
    "    )\n",
    "\n",
    "    return model_response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "S6qmN4GXqjIb",
    "outputId": "574773b8-b323-4ba6-b5df-6818b15c2806"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model': 'gemma2:27b'}\n"
     ]
    }
   ],
   "source": [
    "params = set_llama_params()\n",
    "\n",
    "if not params:\n",
    "  raise Exception(\"gemma exception\")\n",
    "\n",
    "print(params)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xQIQ6tMeqjIb"
   },
   "source": [
    "## ArAiEval"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DiLn7UgjqjIc"
   },
   "source": [
    "### Zero Shot Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "oX1WI9d1qjIc"
   },
   "outputs": [],
   "source": [
    "df_ans_zs = pd.read_excel('./datasets/ArAiEval23Excel/ArAiEval23_disinfo_subtask2A_test.xlsx')\n",
    "\n",
    "# Initialize a list to store the prompts\n",
    "prompts = []\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in df_ans_zs.iterrows():\n",
    "    sentence = row['claim_s']\n",
    "    fake_flag = row['fake_flag']\n",
    "\n",
    "    # Generate prompt based on each row\n",
    "    prompt = f\"\"\"Determine whether the following text is real or fake. If real, then output 0. If fake, then output 1. Respond with only the integer 0 or 1 and nothing else.\n",
    "\n",
    "Text: {sentence}\"\"\"\n",
    "\n",
    "    # Append the prompt along with sentence and fake flag to the list\n",
    "    prompts.append((sentence, fake_flag, prompt))\n",
    "\n",
    "# Convert the list of prompts into a new DataFrame\n",
    "prompts_df_ans_zs = pd.DataFrame(prompts, columns=['Sentence', 'Fake Flag', 'Prompt'])\n",
    "\n",
    "# Save the prompts DataFrame to a new CSV file\n",
    "prompts_df_ans_zs.to_csv('prompts_df_ans_zs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "Ze-o8JuXqjIc",
    "outputId": "075bd32c-257a-4c8d-9d7e-b9846f7d4c78"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Fake Flag</th>\n",
       "      <th>Prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>أ.د.عبدالله الفوزان : “ التباعد المؤقت بين الز...</td>\n",
       "      <td>0</td>\n",
       "      <td>Determine whether the following text is real o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>الدكتور / طلال عيسى السحل الفدعاني العنزي أحد ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Determine whether the following text is real o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#حديث_مسؤول  معالي الرئيس العام لشؤون المسجد ا...</td>\n",
       "      <td>0</td>\n",
       "      <td>Determine whether the following text is real o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#ممكن_بدايه_الحر_ينتهي_كورونا _تفريج كربه_  .....</td>\n",
       "      <td>0</td>\n",
       "      <td>Determine whether the following text is real o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#ممكن_بدايه_الحر_ينتهي_كورونا ﴿وأنفقوا من ما ر...</td>\n",
       "      <td>0</td>\n",
       "      <td>Determine whether the following text is real o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3724</th>\n",
       "      <td>يا بغلونة الصحة مسؤولية ذاتية مكانش على بالو ه...</td>\n",
       "      <td>1</td>\n",
       "      <td>Determine whether the following text is real o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3725</th>\n",
       "      <td>RT @USER التعليم الخاص، و الطب الخاص، و المهند...</td>\n",
       "      <td>0</td>\n",
       "      <td>Determine whether the following text is real o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3726</th>\n",
       "      <td>استخدم الان نون Less20💎 Luck64 Luck65 Luck66 💢...</td>\n",
       "      <td>1</td>\n",
       "      <td>Determine whether the following text is real o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3727</th>\n",
       "      <td>RT @USER ماذا تعلمت من فيروس #كورونا؟ LINK</td>\n",
       "      <td>0</td>\n",
       "      <td>Determine whether the following text is real o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3728</th>\n",
       "      <td>كورونا (كوفيد-19) يكتسح أوروبا ويواصل حصد أروا...</td>\n",
       "      <td>0</td>\n",
       "      <td>Determine whether the following text is real o...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3729 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence  Fake Flag  \\\n",
       "0     أ.د.عبدالله الفوزان : “ التباعد المؤقت بين الز...          0   \n",
       "1     الدكتور / طلال عيسى السحل الفدعاني العنزي أحد ...          0   \n",
       "2     #حديث_مسؤول  معالي الرئيس العام لشؤون المسجد ا...          0   \n",
       "3     #ممكن_بدايه_الحر_ينتهي_كورونا _تفريج كربه_  .....          0   \n",
       "4     #ممكن_بدايه_الحر_ينتهي_كورونا ﴿وأنفقوا من ما ر...          0   \n",
       "...                                                 ...        ...   \n",
       "3724  يا بغلونة الصحة مسؤولية ذاتية مكانش على بالو ه...          1   \n",
       "3725  RT @USER التعليم الخاص، و الطب الخاص، و المهند...          0   \n",
       "3726  استخدم الان نون Less20💎 Luck64 Luck65 Luck66 💢...          1   \n",
       "3727         RT @USER ماذا تعلمت من فيروس #كورونا؟ LINK          0   \n",
       "3728  كورونا (كوفيد-19) يكتسح أوروبا ويواصل حصد أروا...          0   \n",
       "\n",
       "                                                 Prompt  \n",
       "0     Determine whether the following text is real o...  \n",
       "1     Determine whether the following text is real o...  \n",
       "2     Determine whether the following text is real o...  \n",
       "3     Determine whether the following text is real o...  \n",
       "4     Determine whether the following text is real o...  \n",
       "...                                                 ...  \n",
       "3724  Determine whether the following text is real o...  \n",
       "3725  Determine whether the following text is real o...  \n",
       "3726  Determine whether the following text is real o...  \n",
       "3727  Determine whether the following text is real o...  \n",
       "3728  Determine whether the following text is real o...  \n",
       "\n",
       "[3729 rows x 3 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts_df_ans_zs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "IDoGy9PdqjIc"
   },
   "outputs": [],
   "source": [
    "# Define function to calculate metrics\n",
    "def calculate_metrics(test_set, params):\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in test_set.iterrows():\n",
    "        #sentence = row[\"claim_s\"]\n",
    "        sentence = re.sub(r'[\\W_]+', ' ', row[\"claim_s\"])\n",
    "        actual_label = row[\"fake_flag\"]\n",
    "\n",
    "        # Generate prompt based on each row\n",
    "        prompt = f\"\"\"Determine whether the following text is real or fake. if real then output = 0 and if fake then output = 1. Output must be integer 0 or 1 alone. No text.\n",
    "\n",
    "Text: {sentence}\"\"\"\n",
    "\n",
    "        # Call the get_completion function with prompt and params\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        response = get_completion(params, messages)\n",
    "        content = response.get(\"message\").get(\"content\")\n",
    "        predicted_label = get_prediction(content)\n",
    "        none_count = 0\n",
    "        \n",
    "        if predicted_label is not None:\n",
    "            true_labels.append(actual_label)\n",
    "            predicted_labels.append(predicted_label)\n",
    "        else:\n",
    "            none_count += 1 \n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels)\n",
    "    recall = recall_score(true_labels, predicted_labels)\n",
    "    f1 = f1_score(true_labels, predicted_labels)\n",
    "\n",
    "    return accuracy, precision, recall, f1, predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gNDhOwhbqjIc",
    "outputId": "b1aac761-9fcc-44d0-d5e2-8ef67c44be9d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3721491816474376\n",
      "Precision: 0.2664966528530443\n",
      "Recall: 0.9554285714285714\n",
      "F1 Score: 0.4167497507477567\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "accuracy_zs, precision_zs, recall_zs, f1_zs, predicted_ara_zs = calculate_metrics(df_ans_zs, params)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_zs)\n",
    "print(\"Precision:\", precision_zs)\n",
    "print(\"Recall:\", recall_zs)\n",
    "print(\"F1 Score:\", f1_zs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_ara_zs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ara_zs = [0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Yfo7dITORp-H"
   },
   "source": [
    "### Zero Shot CoT Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "id": "DJwi5uy3Rp-R"
   },
   "outputs": [],
   "source": [
    "df_ara_zs_cot = pd.read_excel('./datasets/ArAiEval23Excel/ArAiEval23_disinfo_subtask2A_test.xlsx')\n",
    "\n",
    "# Initialize a list to store the prompts\n",
    "prompts = []\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in df_ara_zs_cot.iterrows():\n",
    "    sentence = row['claim_s']\n",
    "    fake_flag = row['fake_flag']\n",
    "\n",
    "    # Generate prompt based on each row (CoT)\n",
    "    prompt = f\"\"\"Analyze the following statement to determine its authenticity by considering these steps:\n",
    "              1. Content Verification: Check if the claims made in the content can be independently verified with other credible information available.\n",
    "              2. Logical Consistency: Assess whether the statement is logically consistent and whether it contains contradictions or implausible assertions.\n",
    "\n",
    "              After carefully considering these points, conclude whether the statement is more likely true or false. If you determine the statement is true, output '0'. If you determine it is false, output '1'. Provide the output as a single integer, without additional explanation.\n",
    "\n",
    "              Text: {sentence}\n",
    "\n",
    "              Answer:\"\"\"\n",
    "\n",
    "    # Append the prompt along with sentence and fake flag to the list\n",
    "    prompts.append((sentence, fake_flag, prompt))\n",
    "\n",
    "# Convert the list of prompts into a new DataFrame\n",
    "prompts_df_ara_zs_cot = pd.DataFrame(prompts, columns=['Sentence', 'Fake Flag', 'Prompt'])\n",
    "\n",
    "# Save the prompts DataFrame to a new CSV file\n",
    "prompts_df_ara_zs_cot.to_csv('prompts_df_ara_zs_cot.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "349Bdkw-Rp-S",
    "outputId": "c6a11613-6594-4598-f4da-2aa6ae212746"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Fake Flag</th>\n",
       "      <th>Prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>أ.د.عبدالله الفوزان : “ التباعد المؤقت بين الز...</td>\n",
       "      <td>0</td>\n",
       "      <td>Analyze the following statement to determine i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>الدكتور / طلال عيسى السحل الفدعاني العنزي أحد ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Analyze the following statement to determine i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>#حديث_مسؤول  معالي الرئيس العام لشؤون المسجد ا...</td>\n",
       "      <td>0</td>\n",
       "      <td>Analyze the following statement to determine i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>#ممكن_بدايه_الحر_ينتهي_كورونا _تفريج كربه_  .....</td>\n",
       "      <td>0</td>\n",
       "      <td>Analyze the following statement to determine i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>#ممكن_بدايه_الحر_ينتهي_كورونا ﴿وأنفقوا من ما ر...</td>\n",
       "      <td>0</td>\n",
       "      <td>Analyze the following statement to determine i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3724</th>\n",
       "      <td>يا بغلونة الصحة مسؤولية ذاتية مكانش على بالو ه...</td>\n",
       "      <td>1</td>\n",
       "      <td>Analyze the following statement to determine i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3725</th>\n",
       "      <td>RT @USER التعليم الخاص، و الطب الخاص، و المهند...</td>\n",
       "      <td>0</td>\n",
       "      <td>Analyze the following statement to determine i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3726</th>\n",
       "      <td>استخدم الان نون Less20💎 Luck64 Luck65 Luck66 💢...</td>\n",
       "      <td>1</td>\n",
       "      <td>Analyze the following statement to determine i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3727</th>\n",
       "      <td>RT @USER ماذا تعلمت من فيروس #كورونا؟ LINK</td>\n",
       "      <td>0</td>\n",
       "      <td>Analyze the following statement to determine i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3728</th>\n",
       "      <td>كورونا (كوفيد-19) يكتسح أوروبا ويواصل حصد أروا...</td>\n",
       "      <td>0</td>\n",
       "      <td>Analyze the following statement to determine i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3729 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Sentence  Fake Flag  \\\n",
       "0     أ.د.عبدالله الفوزان : “ التباعد المؤقت بين الز...          0   \n",
       "1     الدكتور / طلال عيسى السحل الفدعاني العنزي أحد ...          0   \n",
       "2     #حديث_مسؤول  معالي الرئيس العام لشؤون المسجد ا...          0   \n",
       "3     #ممكن_بدايه_الحر_ينتهي_كورونا _تفريج كربه_  .....          0   \n",
       "4     #ممكن_بدايه_الحر_ينتهي_كورونا ﴿وأنفقوا من ما ر...          0   \n",
       "...                                                 ...        ...   \n",
       "3724  يا بغلونة الصحة مسؤولية ذاتية مكانش على بالو ه...          1   \n",
       "3725  RT @USER التعليم الخاص، و الطب الخاص، و المهند...          0   \n",
       "3726  استخدم الان نون Less20💎 Luck64 Luck65 Luck66 💢...          1   \n",
       "3727         RT @USER ماذا تعلمت من فيروس #كورونا؟ LINK          0   \n",
       "3728  كورونا (كوفيد-19) يكتسح أوروبا ويواصل حصد أروا...          0   \n",
       "\n",
       "                                                 Prompt  \n",
       "0     Analyze the following statement to determine i...  \n",
       "1     Analyze the following statement to determine i...  \n",
       "2     Analyze the following statement to determine i...  \n",
       "3     Analyze the following statement to determine i...  \n",
       "4     Analyze the following statement to determine i...  \n",
       "...                                                 ...  \n",
       "3724  Analyze the following statement to determine i...  \n",
       "3725  Analyze the following statement to determine i...  \n",
       "3726  Analyze the following statement to determine i...  \n",
       "3727  Analyze the following statement to determine i...  \n",
       "3728  Analyze the following statement to determine i...  \n",
       "\n",
       "[3729 rows x 3 columns]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts_df_ara_zs_cot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "se-vuYT6Rp-S"
   },
   "outputs": [],
   "source": [
    "# Define function to calculate metrics\n",
    "def calculate_metrics(test_set, params):\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in test_set.iterrows():\n",
    "        sentence = re.sub(r'[\\W_]+', ' ', row[\"claim_s\"])\n",
    "        actual_label = row[\"fake_flag\"]\n",
    "\n",
    "        # Generate prompt based on each row (CoT)\n",
    "        prompt = f\"\"\"The output of this prompt must at length 1 with two possible values 0 or 1:\n",
    "        \n",
    "        \n",
    "                  Analyze the following statement to determine its authenticity by considering these steps:\n",
    "                  1. Content Verification: Check if the claims made in the content can be independently verified with other credible information available.\n",
    "                  2. Logical Consistency: Assess whether the statement is logically consistent and whether it contains contradictions or implausible assertions.\n",
    "                  \n",
    "                  After carefully considering these points, determine whether the following text is real or fake. if real then output = 0 and if fake then output = 1\n",
    "                  \n",
    "                  Text: {sentence}\n",
    "\n",
    "                  Answer:\"\"\"\n",
    "\n",
    "        # Call the get_completion function with prompt and params\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        response = get_completion(params, messages)\n",
    "        content = response.get(\"message\").get(\"content\")\n",
    "        predicted_label = get_prediction(content)\n",
    "        none_count = 0\n",
    "        \n",
    "        if predicted_label is not None:\n",
    "            true_labels.append(actual_label)\n",
    "            predicted_labels.append(predicted_label)\n",
    "        else:\n",
    "            none_count += 1 \n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels)\n",
    "    recall = recall_score(true_labels, predicted_labels)\n",
    "    f1 = f1_score(true_labels, predicted_labels)\n",
    "\n",
    "    return accuracy, precision, recall, f1, predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HbsCMxy_Rp-T",
    "outputId": "f47479e9-90a3-4308-9504-1acc93c773e7",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3116116921426656\n",
      "Precision: 0.25313868613138685\n",
      "Recall: 0.9897260273972602\n",
      "F1 Score: 0.4031620553359684\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "accuracy_ara_zh_cot, precision_ara_zh_cot, recall_ara_zh_cot, f1_ara_zh_cot, predicted_ara_zh_cot = calculate_metrics(df_ara_zs_cot, params)\n",
    "\n",
    "print(\"Accuracy:\", accuracy_ara_zh_cot)\n",
    "print(\"Precision:\", precision_ara_zh_cot)\n",
    "print(\"Recall:\", recall_ara_zh_cot)\n",
    "print(\"F1 Score:\", f1_ara_zh_cot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_ara_zh_cot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ara_zh_cot = [1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Few Shots Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read the files with encoding: utf-8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_81/366100206.py:28: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_train['fake_flag'] = df_train['fake_flag'].replace({'disinfo': 1, 'no-disinfo': 0})\n",
      "/tmp/ipykernel_81/366100206.py:29: FutureWarning: Downcasting behavior in `replace` is deprecated and will be removed in a future version. To retain the old behavior, explicitly call `result.infer_objects(copy=False)`. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  df_test['fake_flag'] = df_test['fake_flag'].replace({'disinfo': 1, 'no-disinfo': 0})\n"
     ]
    }
   ],
   "source": [
    "# File paths\n",
    "train_file_path = './datasets/ArAiEval23Json/ArAiEval23_disinfo_subtask2A_train.jsonl'\n",
    "test_file_path = './datasets/ArAiEval23Json/ArAiEval23_disinfo_subtask2A_test.jsonl'\n",
    "\n",
    "# Try reading the file with different encodings\n",
    "encodings = ['utf-8', 'utf-16', 'cp1256']\n",
    "\n",
    "for encoding in encodings:\n",
    "    try:\n",
    "        df_train = pd.read_json(train_file_path, lines=True, encoding=encoding)\n",
    "        df_test = pd.read_json(test_file_path, lines=True, encoding=encoding)\n",
    "        print(f\"Successfully read the files with encoding: {encoding}\")\n",
    "        break\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"Failed to read the files with encoding {encoding}: {e}\")\n",
    "\n",
    "# Remove the 'id' column if the DataFrames were successfully read\n",
    "if 'df_train' in locals() and 'df_test' in locals():\n",
    "    # Remove the 'id' column\n",
    "    df_train = df_train.drop(columns=['id'])\n",
    "    df_test = df_test.drop(columns=['id'])\n",
    "\n",
    "    # Rename columns\n",
    "    df_train = df_train.rename(columns={'text': 'claim_s', 'label': 'fake_flag'})\n",
    "    df_test = df_test.rename(columns={'text': 'claim_s', 'label': 'fake_flag'})\n",
    "\n",
    "    # Replace values in the 'fake_flag' column\n",
    "    df_train['fake_flag'] = df_train['fake_flag'].replace({'disinfo': 1, 'no-disinfo': 0})\n",
    "    df_test['fake_flag'] = df_test['fake_flag'].replace({'disinfo': 1, 'no-disinfo': 0})\n",
    "\n",
    "else:\n",
    "    print(\"Failed to read the files with all attempted encodings.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ara_fs = df_train.copy()\n",
    "df_ara_zs = df_test.copy()\n",
    "\n",
    "# Initialize a list to store the prompts\n",
    "prompts = []\n",
    "\n",
    "# Iterate over each row in the DataFrame\n",
    "for index, row in df_ara_fs.iterrows():\n",
    "    sentence = row['claim_s']\n",
    "    fake_flag = row['fake_flag']\n",
    "\n",
    "    # Generate prompt based on each row\n",
    "    prompt = f\"\"\"Text: {sentence}\n",
    "\n",
    "Answer: {fake_flag}\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "    # Append the prompt along with sentence and fake flag to the list\n",
    "    prompts.append((sentence, fake_flag, prompt))\n",
    "\n",
    "# Convert the list of prompts into a new DataFrame\n",
    "prompts_df_ara_fs = pd.DataFrame(prompts, columns=['Sentence', 'Fake Flag', 'Prompt'])\n",
    "\n",
    "# Save the prompts DataFrame to a new CSV file\n",
    "prompts_df_ara_fs.to_csv('prompts_df_ara_fs.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Sentence</th>\n",
       "      <th>Fake Flag</th>\n",
       "      <th>Prompt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>والناس بتقولك أنتم بتلعنوا في الصين ليه ؟ دي ب...</td>\n",
       "      <td>1</td>\n",
       "      <td>Text: والناس بتقولك أنتم بتلعنوا في الصين ليه ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>عندما ضرب #فيروس_كورونا الصين قالوا عنه عقوبه ...</td>\n",
       "      <td>1</td>\n",
       "      <td>Text: عندما ضرب #فيروس_كورونا الصين قالوا عنه ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>عاجل | إيقاف الدوري السويسري لأجل غير مسمى ، ب...</td>\n",
       "      <td>0</td>\n",
       "      <td>Text: عاجل | إيقاف الدوري السويسري لأجل غير مس...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RT @USER #نزل_وزنك_اثناء_العزل_من_كورونا ايه ط...</td>\n",
       "      <td>0</td>\n",
       "      <td>Text: RT @USER #نزل_وزنك_اثناء_العزل_من_كورونا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>RT @USER من أجل سلامتكم ننصح بتأجيل المواعيد و...</td>\n",
       "      <td>0</td>\n",
       "      <td>Text: RT @USER من أجل سلامتكم ننصح بتأجيل المو...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14142</th>\n",
       "      <td>@USER بس كورونا فيه عدوه</td>\n",
       "      <td>0</td>\n",
       "      <td>Text: @USER بس كورونا فيه عدوه\\n\\nAnswer: 0\\n\\n</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14143</th>\n",
       "      <td>( وَمَا تَشَاءُونَ إِلَّا أَن يَشَاءَ الله ) م...</td>\n",
       "      <td>0</td>\n",
       "      <td>Text: ( وَمَا تَشَاءُونَ إِلَّا أَن يَشَاءَ ال...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14144</th>\n",
       "      <td>RT @USER #هند_القحطاني #فايروس_كورونا #جراح_ال...</td>\n",
       "      <td>1</td>\n",
       "      <td>Text: RT @USER #هند_القحطاني #فايروس_كورونا #ج...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14145</th>\n",
       "      <td>@USER قله كورونا الي قبله كان من ألابل اصلا</td>\n",
       "      <td>0</td>\n",
       "      <td>Text: @USER قله كورونا الي قبله كان من ألابل ا...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14146</th>\n",
       "      <td>قال ابن القـيم رحمه الله: «ومن أَعظم علاجات ال...</td>\n",
       "      <td>0</td>\n",
       "      <td>Text: قال ابن القـيم رحمه الله: «ومن أَعظم علا...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>14147 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Sentence  Fake Flag  \\\n",
       "0      والناس بتقولك أنتم بتلعنوا في الصين ليه ؟ دي ب...          1   \n",
       "1      عندما ضرب #فيروس_كورونا الصين قالوا عنه عقوبه ...          1   \n",
       "2      عاجل | إيقاف الدوري السويسري لأجل غير مسمى ، ب...          0   \n",
       "3      RT @USER #نزل_وزنك_اثناء_العزل_من_كورونا ايه ط...          0   \n",
       "4      RT @USER من أجل سلامتكم ننصح بتأجيل المواعيد و...          0   \n",
       "...                                                  ...        ...   \n",
       "14142                           @USER بس كورونا فيه عدوه          0   \n",
       "14143  ( وَمَا تَشَاءُونَ إِلَّا أَن يَشَاءَ الله ) م...          0   \n",
       "14144  RT @USER #هند_القحطاني #فايروس_كورونا #جراح_ال...          1   \n",
       "14145        @USER قله كورونا الي قبله كان من ألابل اصلا          0   \n",
       "14146  قال ابن القـيم رحمه الله: «ومن أَعظم علاجات ال...          0   \n",
       "\n",
       "                                                  Prompt  \n",
       "0      Text: والناس بتقولك أنتم بتلعنوا في الصين ليه ...  \n",
       "1      Text: عندما ضرب #فيروس_كورونا الصين قالوا عنه ...  \n",
       "2      Text: عاجل | إيقاف الدوري السويسري لأجل غير مس...  \n",
       "3      Text: RT @USER #نزل_وزنك_اثناء_العزل_من_كورونا...  \n",
       "4      Text: RT @USER من أجل سلامتكم ننصح بتأجيل المو...  \n",
       "...                                                  ...  \n",
       "14142    Text: @USER بس كورونا فيه عدوه\\n\\nAnswer: 0\\n\\n  \n",
       "14143  Text: ( وَمَا تَشَاءُونَ إِلَّا أَن يَشَاءَ ال...  \n",
       "14144  Text: RT @USER #هند_القحطاني #فايروس_كورونا #ج...  \n",
       "14145  Text: @USER قله كورونا الي قبله كان من ألابل ا...  \n",
       "14146  Text: قال ابن القـيم رحمه الله: «ومن أَعظم علا...  \n",
       "\n",
       "[14147 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts_df_ara_fs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 8 Shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 4 samples with Fake Flag = 0\n",
    "samples_0 = prompts_df_ara_fs[prompts_df_ara_fs['Fake Flag'] == 0].sample(n=4, random_state=1)\n",
    "\n",
    "# Select 4 samples with Fake Flag = 1\n",
    "samples_1 = prompts_df_ara_fs[prompts_df_ara_fs['Fake Flag'] == 1].sample(n=4, random_state=1)\n",
    "\n",
    "# Concatenate the two samples\n",
    "sampled_df_8 = pd.concat([samples_0, samples_1])\n",
    "\n",
    "# Shuffle the resulting DataFrame to mix 0s and 1s\n",
    "sampled_df_8 = sampled_df_8.sample(frac=1, random_state=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: والناس بتقولك أنتم بتلعنوا في الصين ليه ؟ دي بلد كيوت و حطوا صور الدكاترة على المباني و عملولهم التحية و مبقاش عندهم كورونا أنا اسف يا جماعة بس أي حد بشوفه بيقول الكلام ده عن الصين بحس إنه مُغيب و ببقى عاوز ألطشه بالقلم LINK\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: عندما ضرب #فيروس_كورونا الصين قالوا عنه عقوبه ربانية لانها دولة كافرة(حوبه المسلمين)... وعندما وصل بلاد المسلمين قالوا خطة أمريكيه وأرتفع سعر الكمامات والتعقيم اضعاف مضاعفة ودولة الصين الكافرة توزعها على مواطنيها مجانا (مات أبا جهل فاصبح الجهل يتيماً فتبناه العرب) #فيروس_كورونا LINK\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: عاجل | إيقاف الدوري السويسري لأجل غير مسمى ، بسبب فيروس كورونا . LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: RT @USER #نزل_وزنك_اثناء_العزل_من_كورونا ايه طيب LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: RT @USER من أجل سلامتكم ننصح بتأجيل المواعيد والإجراءات الطبية غير الملحة. #الوقاية_من_كورونا LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: بعد نجاح المنشآت #السعودية في تطويق «#كورونا البعارين» الدور على «المستجد» #عكاظ #أن_تكون_أولاً LINK LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: يا #كورونا إني اعلمك كلمات : ما من مسلمٍ تصيبه فيشفى منك الا وقد حطّ الله عنه سيئات ورفعه درجات ، وما من مسلمٍ تصيبه فيموت إلاّ كان ذلك شهادةً له يوم القيامة . . فمالك ولنا ، هلاّ غادرت غير مأسوفٍ عليك ؟\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: إن صح ما يشاع عن عقار الملاريا .. فالدول الأفريقيه هي الگثر إستخداماً له وهو مايفسر عدم إنتشار #كوفيد19 فيها #كورونا LINK\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shots_8 = '\\n'.join(prompts_df_ara_fs.iloc[:8, 2].astype(str))\n",
    "print(shots_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to calculate metrics\n",
    "def calculate_metrics(test_set, params):\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in test_set.iterrows():\n",
    "        sentence = row[\"claim_s\"]\n",
    "        actual_label = row[\"fake_flag\"]\n",
    "\n",
    "        # Generate prompt based on each row\n",
    "        prompt = f\"\"\"Determine whether the following text is real or fake. If real, then output 0. If fake, then output 1. Respond with only the integer 0 or 1 and nothing else.\n",
    "\n",
    "{shots_8}\n",
    "\n",
    "Text: {sentence}\n",
    "\n",
    "Answer:\n",
    "\n",
    "\"\"\"\n",
    "        # Call the get_completion function with prompt and params\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        response = get_completion(params, messages)\n",
    "        content = response.get(\"message\").get(\"content\")\n",
    "        predicted_label = get_prediction(content)\n",
    "        none_count = 0\n",
    "        \n",
    "        if predicted_label is not None:\n",
    "            true_labels.append(actual_label)\n",
    "            predicted_labels.append(predicted_label)\n",
    "        else:\n",
    "            none_count += 1\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels)\n",
    "    recall = recall_score(true_labels, predicted_labels)\n",
    "    f1 = f1_score(true_labels, predicted_labels)\n",
    "\n",
    "    return accuracy, precision, recall, f1, predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8114776079377849\n",
      "Precision: 0.5756780402449694\n",
      "Recall: 0.7511415525114156\n",
      "F1 Score: 0.6518078256562655\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "accuracy, precision, recall, f1 , predicted_ara_8s_4o = calculate_metrics(df_ara_zs, params)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_ara_8s_4o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ara_8s_4o = [0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 16 Shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 8 samples with Fake Flag = 0\n",
    "samples_0 = prompts_df_ara_fs[prompts_df_ara_fs['Fake Flag'] == 0].sample(n=8, random_state=1)\n",
    "\n",
    "# Select 8 samples with Fake Flag = 1\n",
    "samples_1 = prompts_df_ara_fs[prompts_df_ara_fs['Fake Flag'] == 1].sample(n=8, random_state=1)\n",
    "\n",
    "# Concatenate the two samples\n",
    "sampled_df_16 = pd.concat([samples_0, samples_1])\n",
    "\n",
    "# Shuffle the resulting DataFrame to mix 0s and 1s\n",
    "sampled_df_16 = sampled_df_16.sample(frac=1, random_state=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: والناس بتقولك أنتم بتلعنوا في الصين ليه ؟ دي بلد كيوت و حطوا صور الدكاترة على المباني و عملولهم التحية و مبقاش عندهم كورونا أنا اسف يا جماعة بس أي حد بشوفه بيقول الكلام ده عن الصين بحس إنه مُغيب و ببقى عاوز ألطشه بالقلم LINK\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: عندما ضرب #فيروس_كورونا الصين قالوا عنه عقوبه ربانية لانها دولة كافرة(حوبه المسلمين)... وعندما وصل بلاد المسلمين قالوا خطة أمريكيه وأرتفع سعر الكمامات والتعقيم اضعاف مضاعفة ودولة الصين الكافرة توزعها على مواطنيها مجانا (مات أبا جهل فاصبح الجهل يتيماً فتبناه العرب) #فيروس_كورونا LINK\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: عاجل | إيقاف الدوري السويسري لأجل غير مسمى ، بسبب فيروس كورونا . LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: RT @USER #نزل_وزنك_اثناء_العزل_من_كورونا ايه طيب LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: RT @USER من أجل سلامتكم ننصح بتأجيل المواعيد والإجراءات الطبية غير الملحة. #الوقاية_من_كورونا LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: بعد نجاح المنشآت #السعودية في تطويق «#كورونا البعارين» الدور على «المستجد» #عكاظ #أن_تكون_أولاً LINK LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: يا #كورونا إني اعلمك كلمات : ما من مسلمٍ تصيبه فيشفى منك الا وقد حطّ الله عنه سيئات ورفعه درجات ، وما من مسلمٍ تصيبه فيموت إلاّ كان ذلك شهادةً له يوم القيامة . . فمالك ولنا ، هلاّ غادرت غير مأسوفٍ عليك ؟\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: إن صح ما يشاع عن عقار الملاريا .. فالدول الأفريقيه هي الگثر إستخداماً له وهو مايفسر عدم إنتشار #كوفيد19 فيها #كورونا LINK\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: مطلوب صديق مايسولف عن كورونا ولاياذينا باشاعات الوتساب LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: ايران الغنية بالموارد كالنفط والغاز..تأتيها المستلزمات الطبية(اغاثة) ولا تستطيع توفيرها لمواطنيها لمواجهه كورونا وليس لديها حتى منشأت طبية مؤهلة، لدرجة ان المصاب بالفايروس يذهب للمستشفى لينتظر الموت..فلا علاج ولا حتى رعاية طبية -هذا هو نموذج الثورة الحقيقي التي تريد تصديره للعرب\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: لازم كلنا نتجمع ونكتب عن أخوتنا المعتقلين في السجون ياترى دول هيعملوا ايه لو واحد بس لا قدر الله أصيب ب #فيروس_كورونا في عنبر مليان معتقلين هيقدروا ازاي يسيطروا على العدد ده ده هيبقى بؤرة لإنتشار الفيروس لكل البلد كمان كل سجان بيتعامل معاهم هيتصاب وينقل الفيروس😊 #خرجوا_المعتقلين\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: #فيروس_كورونا تحصنّا بذي العزة واعتصمنا برب الملكوت وتوكلنا على الحي الذي لا يموت ،اللهم اصرف عننا هذا الوباء وقنا شر الداء ونجنا من الطعن والطاعون والبلاء بلطفك يا لطيف إنك على كل شيء قدير..\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: RT @USER #كلنا_مسؤول البقاء في المنزل سلاحنا الأقوى بإذن الله لمواجهة #فايروس_كورونا\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: #شركة_تنظيف_مجالس_بالرياض من المعروف ان شركة تنظيف مجالس الرياض هي من أحسن الشركات على مستوى كل الشركات الموجودة في مجال التنظيف #رش_ضد_فيروس_كورونا خدماتنا : غسيل كنب نظافة موكيت تنظيف سجاد تنظيف الاستراحات تنظيف بيوت شعر نظافة خيام تنظيف فرش فرشات جوال 0501545009 0508011776 LINK\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: نشكر قيادتنا الرشيدة على قرارها الإحترازي الوقائي الرشيد بتعليق العمرة مؤقتاً بسبب التحرز من من انتقال فايروس كورونا حرصاً على سلامة رواد الحرم المكي من المواطنين والمقيمين وماهي إلا فترة محدودة إن شاء الله LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: RT @USER #كورونا LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shots_16 = '\\n'.join(prompts_df_ara_fs.iloc[:16, 2].astype(str))\n",
    "print(shots_16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to calculate metrics\n",
    "def calculate_metrics(test_set, params):\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in test_set.iterrows():\n",
    "        sentence = row[\"claim_s\"]\n",
    "        actual_label = row[\"fake_flag\"]\n",
    "\n",
    "        # Generate prompt based on each row\n",
    "        prompt = f\"\"\"Determine whether the following text is real or fake. If real, then output 0. If fake, then output 1. Respond with only the integer 0 or 1 and nothing else.\n",
    "\n",
    "{shots_16}\n",
    "\n",
    "Text: {sentence}\n",
    "\n",
    "Answer:\n",
    "\n",
    "\"\"\"\n",
    "        # Call the get_completion function with prompt and params\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        response = get_completion(params, messages)\n",
    "        content = response.get(\"message\").get(\"content\")\n",
    "        predicted_label = get_prediction(content)\n",
    "        none_count = 0\n",
    "        \n",
    "        if predicted_label is not None:\n",
    "            true_labels.append(actual_label)\n",
    "            predicted_labels.append(predicted_label)\n",
    "        else:\n",
    "            none_count += 1\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels)\n",
    "    recall = recall_score(true_labels, predicted_labels)\n",
    "    f1 = f1_score(true_labels, predicted_labels)\n",
    "\n",
    "    return accuracy, precision, recall, f1, predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7878787878787878\n",
      "Precision: 0.533022533022533\n",
      "Recall: 0.7831050228310502\n",
      "F1 Score: 0.6343042071197411\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "accuracy, precision, recall, f1, predicted_ara_16s_4o = calculate_metrics(df_ara_zs, params)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_ara_16s_4o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ara_16s_4o = [0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 32 Shots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select 16 samples with Fake Flag = 0\n",
    "samples_0 = prompts_df_ara_fs[prompts_df_ara_fs['Fake Flag'] == 0].sample(n=16, random_state=1)\n",
    "\n",
    "# Select 16 samples with Fake Flag = 1\n",
    "samples_1 = prompts_df_ara_fs[prompts_df_ara_fs['Fake Flag'] == 1].sample(n=16, random_state=1)\n",
    "\n",
    "# Concatenate the two samples\n",
    "sampled_df_32 = pd.concat([samples_0, samples_1])\n",
    "\n",
    "# Shuffle the resulting DataFrame to mix 0s and 1s\n",
    "sampled_df_32 = sampled_df_32.sample(frac=1, random_state=1).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: والناس بتقولك أنتم بتلعنوا في الصين ليه ؟ دي بلد كيوت و حطوا صور الدكاترة على المباني و عملولهم التحية و مبقاش عندهم كورونا أنا اسف يا جماعة بس أي حد بشوفه بيقول الكلام ده عن الصين بحس إنه مُغيب و ببقى عاوز ألطشه بالقلم LINK\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: عندما ضرب #فيروس_كورونا الصين قالوا عنه عقوبه ربانية لانها دولة كافرة(حوبه المسلمين)... وعندما وصل بلاد المسلمين قالوا خطة أمريكيه وأرتفع سعر الكمامات والتعقيم اضعاف مضاعفة ودولة الصين الكافرة توزعها على مواطنيها مجانا (مات أبا جهل فاصبح الجهل يتيماً فتبناه العرب) #فيروس_كورونا LINK\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: عاجل | إيقاف الدوري السويسري لأجل غير مسمى ، بسبب فيروس كورونا . LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: RT @USER #نزل_وزنك_اثناء_العزل_من_كورونا ايه طيب LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: RT @USER من أجل سلامتكم ننصح بتأجيل المواعيد والإجراءات الطبية غير الملحة. #الوقاية_من_كورونا LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: بعد نجاح المنشآت #السعودية في تطويق «#كورونا البعارين» الدور على «المستجد» #عكاظ #أن_تكون_أولاً LINK LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: يا #كورونا إني اعلمك كلمات : ما من مسلمٍ تصيبه فيشفى منك الا وقد حطّ الله عنه سيئات ورفعه درجات ، وما من مسلمٍ تصيبه فيموت إلاّ كان ذلك شهادةً له يوم القيامة . . فمالك ولنا ، هلاّ غادرت غير مأسوفٍ عليك ؟\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: إن صح ما يشاع عن عقار الملاريا .. فالدول الأفريقيه هي الگثر إستخداماً له وهو مايفسر عدم إنتشار #كوفيد19 فيها #كورونا LINK\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: مطلوب صديق مايسولف عن كورونا ولاياذينا باشاعات الوتساب LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: ايران الغنية بالموارد كالنفط والغاز..تأتيها المستلزمات الطبية(اغاثة) ولا تستطيع توفيرها لمواطنيها لمواجهه كورونا وليس لديها حتى منشأت طبية مؤهلة، لدرجة ان المصاب بالفايروس يذهب للمستشفى لينتظر الموت..فلا علاج ولا حتى رعاية طبية -هذا هو نموذج الثورة الحقيقي التي تريد تصديره للعرب\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: لازم كلنا نتجمع ونكتب عن أخوتنا المعتقلين في السجون ياترى دول هيعملوا ايه لو واحد بس لا قدر الله أصيب ب #فيروس_كورونا في عنبر مليان معتقلين هيقدروا ازاي يسيطروا على العدد ده ده هيبقى بؤرة لإنتشار الفيروس لكل البلد كمان كل سجان بيتعامل معاهم هيتصاب وينقل الفيروس😊 #خرجوا_المعتقلين\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: #فيروس_كورونا تحصنّا بذي العزة واعتصمنا برب الملكوت وتوكلنا على الحي الذي لا يموت ،اللهم اصرف عننا هذا الوباء وقنا شر الداء ونجنا من الطعن والطاعون والبلاء بلطفك يا لطيف إنك على كل شيء قدير..\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: RT @USER #كلنا_مسؤول البقاء في المنزل سلاحنا الأقوى بإذن الله لمواجهة #فايروس_كورونا\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: #شركة_تنظيف_مجالس_بالرياض من المعروف ان شركة تنظيف مجالس الرياض هي من أحسن الشركات على مستوى كل الشركات الموجودة في مجال التنظيف #رش_ضد_فيروس_كورونا خدماتنا : غسيل كنب نظافة موكيت تنظيف سجاد تنظيف الاستراحات تنظيف بيوت شعر نظافة خيام تنظيف فرش فرشات جوال 0501545009 0508011776 LINK\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: نشكر قيادتنا الرشيدة على قرارها الإحترازي الوقائي الرشيد بتعليق العمرة مؤقتاً بسبب التحرز من من انتقال فايروس كورونا حرصاً على سلامة رواد الحرم المكي من المواطنين والمقيمين وماهي إلا فترة محدودة إن شاء الله LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: RT @USER #كورونا LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: RT @USER عيناها ك فيروس كورونا و قلبى صيني لا يتحمل 😕💔 LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: أزمة #كورونا جعلتني اشاهد المشهد بتأملات جديده و انطباعات جديده و صدمت بسياسات دول كنت أظن فيها أنها تهتم بالإنسان أكثر من المال كل التحيه لدول الخليج اللذين سخروا الأموال لخدمه الأنسان (في هذه الأزمة)\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: فيروس كورونا 😱😱😱 الصين : مافي خروج من المنزل الكويت : مافي دراسة السعودية : مافي عمره وربما الحج  الامارات : مافي دراسة البحرين : مافي دراسة اليمن : مافي داعي للقلق شكراً حكومتنا الموقره نحن شعب مايهزه ريح  😂😂😂😂😂🌚💔✋🏻\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: RT @USER يامن تعلمون الناس الدجل والشعوذة اين انتم من تفعيل وتطوير الجانب الصحي !!! #ولايه_الفقيه_ظلم_وانتقام #كورونا_كشف_القناع\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: الصحة البريطانيه تقول للبريطانيين \" اذا حسيت بـ اعراض كورونا لاتتصل علينا وعالج نفسك بنفسك عشان تخفف العبء على خدماتنا الصحية !! وزارة الصحة السعودية تقول اذا حسيت بشي اتصل بنا وحنا نخدمك وامانة الرياض تصنع معقمات وتوزعها مجاناً وطننا عظيم ياجماعة 💚🙏🏻 LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: RT @USER مليت من كثرة النصايح في #كورونا؟ عندك حاجتين حافظ عليهم: ✅ نظافة يدينك ✅ مسافة متر من الناس في الأماكن العامة فقط🤷🏻\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: @USER @USER @USER يوم تعطلون المدارس كان لسى ماجانا كورونا ! تسلل ياححححكممم\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: _ بيقولوا الناس نزلت مظاهرات ليلية ضد اللى ما يتسماش = والله كنت متأكد إن الشعب هيفوق ويعمل ثورة على النظام! _ نظام أيه يابنى دول نازلين ضد فيروس كورونا\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: تواصل #أمانة_منطقة_الرياض توزيع معقمها مجانًا للسكان في أكثر من ٢٥ موقعًا ضمن جهودها الوقائية لمنع انتشار فيروس #كورونا المستجد.. LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: فيديوجرافيك 🎥 | أسئلة شائعة حول #كورونا.. هل يجب ارتداء كمامة للوقاية منه؟  LINK LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: احمى نفسك وغيرك من فيروس كورونا واشترى اونلاين ☺ واحصل على الخصم الاكيد مع كوبونات الخصومات ومن اكتر من متجر 👏 جميع احتياجات عندنا انسخ الكوبون واحصل على الخصم المضمون🏆 كوبون نون:Less17💨LUck41 Sprii:S12 اناس:  Star5 نمشى: star8 سنتربوينت : CPC197 كل: hi30 السعوديه LINK\n",
      "\n",
      "Answer: 1\n",
      "\n",
      "\n",
      "Text: يارب يخلص يومي وم أسمع كلمة كورونا.\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: أتمنئ ان لا يصل كورونا الئ (اليمن ) شعب ماعد به طافة يتحمل خلاص الموضوع مش سهل او عباطة هذه اكبر أزمة في العالم في القرن الحديث متخيل بس ماعد بش تخازين وأسواق قات وتخزن لوحدك بالبيت صح في مداعة وشمة لكن برضوا مافيش مزح نحتاج الئ أجهزة فحص طبية وحجر بالموانئ والمطارات المفتوحة LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: بالأرقام .. خسائر قطاع #السياحة_العربية والعالمية جراء #فيروس_كورونا #COVID-19 😷 حتى الآن 👇🏻 اهمها قد يتعرض أكثر من 50 مليون موظف يعمل في القطاع السياحي للإيقاف. المصدر: فريق إدارة الأزمات بـ#المنظمة_العربية_للسياحة اللهم أحفظ الأمة العربية والإسلامية والعالم من هذا الوباء LINK\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: @USER @USER @USER كلارك ❤️❤️❤️❤️😏الا كلارك ولا اهد العالم فوق تحت بروح أستراليا ماعندهم كورونا 🌚❤️\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n",
      "Text: فيني صداع قوي مدري من البخور أو كورونا 💔\n",
      "\n",
      "Answer: 0\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "shots_all = '\\n'.join(prompts_df_ara_fs.iloc[:32, 2].astype(str))\n",
    "print(shots_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define function to calculate metrics\n",
    "def calculate_metrics(test_set, params):\n",
    "    true_labels = []\n",
    "    predicted_labels = []\n",
    "\n",
    "    # Iterate over each row in the DataFrame\n",
    "    for index, row in test_set.iterrows():\n",
    "        sentence = row[\"claim_s\"]\n",
    "        actual_label = row[\"fake_flag\"]\n",
    "\n",
    "        # Generate prompt based on each row\n",
    "        prompt = f\"\"\"Determine whether the following text is real or fake. If real, then output 0. If fake, then output 1. Respond with only the integer 0 or 1 and nothing else.\n",
    "\n",
    "{shots_all}\n",
    "\n",
    "Text: {sentence}\n",
    "\n",
    "Answer:\n",
    "\n",
    "\"\"\"\n",
    "        # Call the get_completion function with prompt and params\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"user\",\n",
    "                \"content\": prompt\n",
    "            }\n",
    "        ]\n",
    "\n",
    "        response = get_completion(params, messages)\n",
    "        content = response.get(\"message\").get(\"content\")\n",
    "        predicted_label = get_prediction(content)\n",
    "        print(\"index\", index, \"predicted_label\", predicted_label)\n",
    "        none_count = 0\n",
    "        \n",
    "        if predicted_label is not None:\n",
    "            true_labels.append(actual_label)\n",
    "            predicted_labels.append(predicted_label)\n",
    "        else:\n",
    "            none_count += 1\n",
    "\n",
    "    # Calculate metrics\n",
    "    print(\"none_count\", none_count)\n",
    "    accuracy = accuracy_score(true_labels, predicted_labels)\n",
    "    precision = precision_score(true_labels, predicted_labels)\n",
    "    recall = recall_score(true_labels, predicted_labels)\n",
    "    f1 = f1_score(true_labels, predicted_labels)\n",
    "\n",
    "    return accuracy, precision, recall, f1, predicted_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "index 0 predicted_label 0\n",
      "index 1 predicted_label 0\n",
      "index 2 predicted_label 1\n",
      "index 3 predicted_label 1\n",
      "index 4 predicted_label 1\n",
      "index 5 predicted_label 0\n",
      "index 6 predicted_label 1\n",
      "index 7 predicted_label 1\n",
      "index 8 predicted_label 1\n",
      "index 9 predicted_label 1\n",
      "index 10 predicted_label 1\n",
      "index 11 predicted_label 1\n",
      "index 12 predicted_label 1\n",
      "index 13 predicted_label 1\n",
      "index 14 predicted_label 1\n",
      "index 15 predicted_label 1\n",
      "index 16 predicted_label 1\n",
      "index 17 predicted_label 1\n",
      "index 18 predicted_label 1\n",
      "index 19 predicted_label 1\n",
      "index 20 predicted_label 1\n",
      "index 21 predicted_label 1\n",
      "index 22 predicted_label 1\n",
      "index 23 predicted_label 1\n",
      "index 24 predicted_label 1\n",
      "index 25 predicted_label 1\n",
      "index 26 predicted_label 1\n",
      "index 27 predicted_label 0\n",
      "index 28 predicted_label 1\n",
      "index 29 predicted_label 1\n",
      "index 30 predicted_label 1\n",
      "index 31 predicted_label 1\n",
      "index 32 predicted_label 1\n",
      "index 33 predicted_label 1\n",
      "index 34 predicted_label 1\n",
      "index 35 predicted_label 1\n",
      "index 36 predicted_label 1\n",
      "index 37 predicted_label 1\n",
      "index 38 predicted_label None\n",
      "index 39 predicted_label None\n",
      "index 40 predicted_label 1\n",
      "index 41 predicted_label None\n",
      "index 42 predicted_label 1\n",
      "index 43 predicted_label 1\n",
      "index 44 predicted_label 1\n",
      "index 45 predicted_label 1\n",
      "index 46 predicted_label 1\n",
      "index 47 predicted_label 1\n",
      "index 48 predicted_label 1\n",
      "index 49 predicted_label 1\n",
      "index 50 predicted_label 1\n",
      "index 51 predicted_label 1\n",
      "index 52 predicted_label 1\n",
      "index 53 predicted_label None\n",
      "index 54 predicted_label 1\n",
      "index 55 predicted_label None\n",
      "index 56 predicted_label 0\n",
      "index 57 predicted_label 0\n",
      "index 58 predicted_label 1\n",
      "index 59 predicted_label None\n",
      "index 60 predicted_label None\n",
      "index 61 predicted_label 1\n",
      "index 62 predicted_label 1\n",
      "index 63 predicted_label 1\n",
      "index 64 predicted_label 1\n",
      "index 65 predicted_label 1\n",
      "index 66 predicted_label 1\n",
      "index 67 predicted_label 1\n",
      "index 68 predicted_label 1\n",
      "index 69 predicted_label 1\n",
      "index 70 predicted_label 1\n",
      "index 71 predicted_label 1\n",
      "index 72 predicted_label 1\n",
      "index 73 predicted_label 1\n",
      "index 74 predicted_label 1\n",
      "index 75 predicted_label 1\n",
      "index 76 predicted_label 0\n",
      "index 77 predicted_label 1\n",
      "index 78 predicted_label 0\n",
      "index 79 predicted_label 1\n",
      "index 80 predicted_label None\n",
      "index 81 predicted_label 0\n",
      "index 82 predicted_label 0\n",
      "index 83 predicted_label 1\n",
      "index 84 predicted_label 1\n",
      "index 85 predicted_label 1\n",
      "index 86 predicted_label None\n",
      "index 87 predicted_label 1\n",
      "index 88 predicted_label 1\n",
      "index 89 predicted_label 1\n",
      "index 90 predicted_label 1\n",
      "index 91 predicted_label 1\n",
      "index 92 predicted_label 1\n",
      "index 93 predicted_label None\n",
      "index 94 predicted_label 1\n",
      "index 95 predicted_label 1\n",
      "index 96 predicted_label 0\n",
      "index 97 predicted_label 1\n",
      "index 98 predicted_label 1\n",
      "index 99 predicted_label 1\n",
      "index 100 predicted_label 0\n",
      "index 101 predicted_label 0\n",
      "index 102 predicted_label 1\n",
      "index 103 predicted_label 1\n",
      "index 104 predicted_label 1\n",
      "index 105 predicted_label 0\n",
      "index 106 predicted_label 1\n",
      "index 107 predicted_label 1\n",
      "index 108 predicted_label 1\n",
      "index 109 predicted_label 1\n",
      "index 110 predicted_label 0\n",
      "index 111 predicted_label 1\n",
      "index 112 predicted_label 1\n",
      "index 113 predicted_label None\n",
      "index 114 predicted_label 1\n",
      "index 115 predicted_label 0\n",
      "index 116 predicted_label 1\n",
      "index 117 predicted_label 1\n",
      "index 118 predicted_label 1\n",
      "index 119 predicted_label None\n",
      "index 120 predicted_label 1\n",
      "index 121 predicted_label None\n",
      "index 122 predicted_label 1\n",
      "index 123 predicted_label 0\n",
      "index 124 predicted_label 1\n",
      "index 125 predicted_label 1\n",
      "index 126 predicted_label None\n",
      "index 127 predicted_label 0\n",
      "index 128 predicted_label 1\n",
      "index 129 predicted_label 0\n",
      "index 130 predicted_label 1\n",
      "index 131 predicted_label 0\n",
      "index 132 predicted_label 1\n",
      "index 133 predicted_label 1\n",
      "index 134 predicted_label 1\n",
      "index 135 predicted_label None\n",
      "index 136 predicted_label None\n",
      "index 137 predicted_label 1\n",
      "index 138 predicted_label 0\n",
      "index 139 predicted_label 1\n",
      "index 140 predicted_label 1\n",
      "index 141 predicted_label 1\n",
      "index 142 predicted_label 1\n",
      "index 143 predicted_label 0\n",
      "index 144 predicted_label 1\n",
      "index 145 predicted_label 1\n",
      "index 146 predicted_label 1\n",
      "index 147 predicted_label 1\n",
      "index 148 predicted_label 1\n",
      "index 149 predicted_label None\n",
      "index 150 predicted_label 1\n",
      "index 151 predicted_label 1\n",
      "index 152 predicted_label 1\n",
      "index 153 predicted_label 1\n",
      "index 154 predicted_label 1\n",
      "index 155 predicted_label 0\n",
      "index 156 predicted_label 1\n",
      "index 157 predicted_label 1\n",
      "index 158 predicted_label 1\n",
      "index 159 predicted_label None\n",
      "index 160 predicted_label None\n",
      "index 161 predicted_label 1\n",
      "index 162 predicted_label 1\n",
      "index 163 predicted_label 0\n",
      "index 164 predicted_label 1\n",
      "index 165 predicted_label 1\n",
      "index 166 predicted_label 0\n",
      "index 167 predicted_label 1\n",
      "index 168 predicted_label 1\n",
      "index 169 predicted_label 0\n",
      "index 170 predicted_label None\n",
      "index 171 predicted_label 1\n",
      "index 172 predicted_label 1\n",
      "index 173 predicted_label 0\n",
      "index 174 predicted_label None\n",
      "index 175 predicted_label 1\n",
      "index 176 predicted_label None\n",
      "index 177 predicted_label 1\n",
      "index 178 predicted_label None\n",
      "index 179 predicted_label 1\n",
      "index 180 predicted_label 1\n",
      "index 181 predicted_label 1\n",
      "index 182 predicted_label 1\n",
      "index 183 predicted_label 1\n",
      "index 184 predicted_label 1\n",
      "index 185 predicted_label 1\n",
      "index 186 predicted_label 1\n",
      "index 187 predicted_label None\n",
      "index 188 predicted_label None\n",
      "index 189 predicted_label 1\n",
      "index 190 predicted_label 1\n",
      "index 191 predicted_label 1\n",
      "index 192 predicted_label 1\n",
      "index 193 predicted_label None\n",
      "index 194 predicted_label 1\n",
      "index 195 predicted_label 0\n",
      "index 196 predicted_label 1\n",
      "index 197 predicted_label 1\n",
      "index 198 predicted_label 1\n",
      "index 199 predicted_label 1\n",
      "index 200 predicted_label 1\n",
      "index 201 predicted_label 1\n",
      "index 202 predicted_label 1\n",
      "index 203 predicted_label 1\n",
      "index 204 predicted_label 0\n",
      "index 205 predicted_label None\n",
      "index 206 predicted_label 0\n",
      "index 207 predicted_label 1\n",
      "index 208 predicted_label 1\n",
      "index 209 predicted_label 0\n",
      "index 210 predicted_label 1\n",
      "index 211 predicted_label 1\n",
      "index 212 predicted_label 1\n",
      "index 213 predicted_label 0\n",
      "index 214 predicted_label None\n",
      "index 215 predicted_label 1\n",
      "index 216 predicted_label 1\n",
      "index 217 predicted_label 1\n",
      "index 218 predicted_label 1\n",
      "index 219 predicted_label 1\n",
      "index 220 predicted_label 1\n",
      "index 221 predicted_label None\n",
      "index 222 predicted_label 1\n",
      "index 223 predicted_label 1\n",
      "index 224 predicted_label 1\n",
      "index 225 predicted_label 1\n",
      "index 226 predicted_label 1\n",
      "index 227 predicted_label 1\n",
      "index 228 predicted_label 1\n",
      "index 229 predicted_label 0\n",
      "index 230 predicted_label 1\n",
      "index 231 predicted_label 0\n",
      "index 232 predicted_label 1\n",
      "index 233 predicted_label 0\n",
      "index 234 predicted_label 1\n",
      "index 235 predicted_label 1\n",
      "index 236 predicted_label 1\n",
      "index 237 predicted_label 0\n",
      "index 238 predicted_label 1\n",
      "index 239 predicted_label 1\n",
      "index 240 predicted_label None\n",
      "index 241 predicted_label 1\n",
      "index 242 predicted_label 0\n",
      "index 243 predicted_label 0\n",
      "index 244 predicted_label 1\n",
      "index 245 predicted_label 0\n",
      "index 246 predicted_label 1\n",
      "index 247 predicted_label 1\n",
      "index 248 predicted_label 1\n",
      "index 249 predicted_label 1\n",
      "index 250 predicted_label 1\n",
      "index 251 predicted_label 0\n",
      "index 252 predicted_label 1\n",
      "index 253 predicted_label 1\n",
      "index 254 predicted_label 0\n",
      "index 255 predicted_label 0\n",
      "index 256 predicted_label 1\n",
      "index 257 predicted_label 0\n",
      "index 258 predicted_label None\n",
      "index 259 predicted_label None\n",
      "index 260 predicted_label 1\n",
      "index 261 predicted_label 1\n",
      "index 262 predicted_label 1\n",
      "index 263 predicted_label None\n",
      "index 264 predicted_label 1\n",
      "index 265 predicted_label 1\n",
      "index 266 predicted_label 1\n",
      "index 267 predicted_label None\n",
      "index 268 predicted_label None\n",
      "index 269 predicted_label 1\n",
      "index 270 predicted_label 1\n",
      "index 271 predicted_label 1\n",
      "index 272 predicted_label 1\n",
      "index 273 predicted_label 1\n",
      "index 274 predicted_label 1\n",
      "index 275 predicted_label 1\n",
      "index 276 predicted_label 1\n",
      "index 277 predicted_label 1\n",
      "index 278 predicted_label None\n",
      "index 279 predicted_label 0\n",
      "index 280 predicted_label None\n",
      "index 281 predicted_label None\n",
      "index 282 predicted_label None\n",
      "index 283 predicted_label 1\n",
      "index 284 predicted_label None\n",
      "index 285 predicted_label 1\n",
      "index 286 predicted_label 1\n",
      "index 287 predicted_label None\n",
      "index 288 predicted_label 1\n",
      "index 289 predicted_label 0\n",
      "index 290 predicted_label 1\n",
      "index 291 predicted_label 1\n",
      "index 292 predicted_label 0\n",
      "index 293 predicted_label None\n",
      "index 294 predicted_label None\n",
      "index 295 predicted_label 1\n",
      "index 296 predicted_label 1\n",
      "index 297 predicted_label 1\n",
      "index 298 predicted_label 1\n",
      "index 299 predicted_label None\n",
      "index 300 predicted_label 1\n",
      "index 301 predicted_label 1\n",
      "index 302 predicted_label 1\n",
      "index 303 predicted_label 0\n",
      "index 304 predicted_label 0\n",
      "index 305 predicted_label 1\n",
      "index 306 predicted_label 0\n",
      "index 307 predicted_label 0\n",
      "index 308 predicted_label 1\n",
      "index 309 predicted_label None\n",
      "index 310 predicted_label 1\n",
      "index 311 predicted_label 1\n",
      "index 312 predicted_label 0\n",
      "index 313 predicted_label None\n",
      "index 314 predicted_label 1\n",
      "index 315 predicted_label 1\n",
      "index 316 predicted_label 1\n",
      "index 317 predicted_label 1\n",
      "index 318 predicted_label 0\n",
      "index 319 predicted_label 1\n",
      "index 320 predicted_label 1\n",
      "index 321 predicted_label 1\n",
      "index 322 predicted_label 1\n",
      "index 323 predicted_label 1\n",
      "index 324 predicted_label None\n",
      "index 325 predicted_label 1\n",
      "index 326 predicted_label 1\n",
      "index 327 predicted_label 1\n",
      "index 328 predicted_label 1\n",
      "index 329 predicted_label 1\n",
      "index 330 predicted_label 0\n",
      "index 331 predicted_label 1\n",
      "index 332 predicted_label 1\n",
      "index 333 predicted_label 1\n",
      "index 334 predicted_label 0\n",
      "index 335 predicted_label 1\n",
      "index 336 predicted_label 1\n",
      "index 337 predicted_label 0\n",
      "index 338 predicted_label 1\n",
      "index 339 predicted_label 1\n",
      "index 340 predicted_label 1\n",
      "index 341 predicted_label 1\n",
      "index 342 predicted_label 0\n",
      "index 343 predicted_label 1\n",
      "index 344 predicted_label 0\n",
      "index 345 predicted_label 1\n",
      "index 346 predicted_label 1\n",
      "index 347 predicted_label 0\n",
      "index 348 predicted_label 1\n",
      "index 349 predicted_label 1\n",
      "index 350 predicted_label None\n",
      "index 351 predicted_label 1\n",
      "index 352 predicted_label 0\n",
      "index 353 predicted_label 1\n",
      "index 354 predicted_label 0\n",
      "index 355 predicted_label 1\n",
      "index 356 predicted_label 1\n",
      "index 357 predicted_label 1\n",
      "index 358 predicted_label 1\n",
      "index 359 predicted_label 0\n",
      "index 360 predicted_label 1\n",
      "index 361 predicted_label 1\n",
      "index 362 predicted_label 1\n",
      "index 363 predicted_label 0\n",
      "index 364 predicted_label 1\n",
      "index 365 predicted_label 1\n",
      "index 366 predicted_label 1\n",
      "index 367 predicted_label None\n",
      "index 368 predicted_label 0\n",
      "index 369 predicted_label 0\n",
      "index 370 predicted_label 0\n",
      "index 371 predicted_label 1\n",
      "index 372 predicted_label None\n",
      "index 373 predicted_label None\n",
      "index 374 predicted_label 0\n",
      "index 375 predicted_label 1\n",
      "index 376 predicted_label 1\n",
      "index 377 predicted_label 1\n",
      "index 378 predicted_label 1\n",
      "index 379 predicted_label 1\n",
      "index 380 predicted_label 1\n",
      "index 381 predicted_label 1\n",
      "index 382 predicted_label 1\n",
      "index 383 predicted_label 1\n",
      "index 384 predicted_label 0\n",
      "index 385 predicted_label None\n",
      "index 386 predicted_label 1\n",
      "index 387 predicted_label 1\n",
      "index 388 predicted_label 0\n",
      "index 389 predicted_label 1\n",
      "index 390 predicted_label None\n",
      "index 391 predicted_label 1\n",
      "index 392 predicted_label 1\n",
      "index 393 predicted_label 1\n",
      "index 394 predicted_label 1\n",
      "index 395 predicted_label 1\n",
      "index 396 predicted_label 1\n",
      "index 397 predicted_label None\n",
      "index 398 predicted_label 0\n",
      "index 399 predicted_label 1\n",
      "index 400 predicted_label 1\n",
      "index 401 predicted_label 1\n",
      "index 402 predicted_label 1\n",
      "index 403 predicted_label 0\n",
      "index 404 predicted_label 1\n",
      "index 405 predicted_label 1\n",
      "index 406 predicted_label 1\n",
      "index 407 predicted_label 0\n",
      "index 408 predicted_label 1\n",
      "index 409 predicted_label 1\n",
      "index 410 predicted_label 1\n",
      "index 411 predicted_label 1\n",
      "index 412 predicted_label 0\n",
      "index 413 predicted_label None\n",
      "index 414 predicted_label 1\n",
      "index 415 predicted_label 1\n",
      "index 416 predicted_label 1\n",
      "index 417 predicted_label 1\n",
      "index 418 predicted_label 1\n",
      "index 419 predicted_label 1\n",
      "index 420 predicted_label 0\n",
      "index 421 predicted_label 1\n",
      "index 422 predicted_label None\n",
      "index 423 predicted_label 0\n",
      "index 424 predicted_label 1\n",
      "index 425 predicted_label 1\n",
      "index 426 predicted_label 1\n",
      "index 427 predicted_label 1\n",
      "index 428 predicted_label 1\n",
      "index 429 predicted_label 1\n",
      "index 430 predicted_label None\n",
      "index 431 predicted_label 0\n",
      "index 432 predicted_label 0\n",
      "index 433 predicted_label 1\n",
      "index 434 predicted_label 1\n",
      "index 435 predicted_label 0\n",
      "index 436 predicted_label 1\n",
      "index 437 predicted_label 1\n",
      "index 438 predicted_label 1\n",
      "index 439 predicted_label 0\n",
      "index 440 predicted_label 1\n",
      "index 441 predicted_label 1\n",
      "index 442 predicted_label 1\n",
      "index 443 predicted_label 1\n",
      "index 444 predicted_label 0\n",
      "index 445 predicted_label 1\n",
      "index 446 predicted_label 1\n",
      "index 447 predicted_label 1\n",
      "index 448 predicted_label 0\n",
      "index 449 predicted_label 1\n",
      "index 450 predicted_label 1\n",
      "index 451 predicted_label 1\n",
      "index 452 predicted_label 0\n",
      "index 453 predicted_label 1\n",
      "index 454 predicted_label 1\n",
      "index 455 predicted_label 0\n",
      "index 456 predicted_label 1\n",
      "index 457 predicted_label 1\n",
      "index 458 predicted_label None\n",
      "index 459 predicted_label 1\n"
     ]
    }
   ],
   "source": [
    "# Calculate metrics\n",
    "accuracy, precision, recall, f1, predicted_ara_32s_4o = calculate_metrics(df_ara_zs, params)\n",
    "\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.43409915356711004\n",
      "Precision: 0.28421052631578947\n",
      "Recall: 0.9529411764705882\n",
      "F1 Score: 0.43783783783783786\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Precision:\", precision)\n",
    "print(\"Recall:\", recall)\n",
    "print(\"F1 Score:\", f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "print(predicted_ara_32s_4o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "predicted_ara_32s_4o = [0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 0, 0, 0, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 0, 1, 0, 1, 1, 1, 0, 1, 1, 1, 1, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 1, 1, 0, 1, 1, 1, 1, 1, 0, 0]"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [
    "LOSyELDH1eVT",
    "uGppidLd1n_b"
   ],
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "f38e0373277d6f71ee44ee8fea5f1d408ad6999fda15d538a69a99a1665a839d"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
